simulation:
  data:
    dataset_name: CIFAR100
    batch_size: 64
    preprocess_fn: |
      def preprocess_fn(element):
        return {
          "x": element["img"],
          "y": element["fine_label"]
        }
  federation:
    client_count: 100
    fraction_fit: 0.1
    local_rounds: 4
  model:
    optimizer_name: FedAdam
    model_name: ResNet34
    criterion_name: CrossEntropyLoss
    optimizer_parameters:
      local:
        lr: 0.01
      global:
        lr: 0.01
        betas:
          - 0.9
          - 0.99
        eps: 0.0001
    model_architecture:
      repo_or_dir: 'pytorch/vision:v0.10.0'
      model: 'resnet34'
      pretrained: False
      out_features: 100
attack:
  data_access:
    steps:
      - 1.0
      - 0.01
      - 1.0
      - 0.01
  message_access: server
  aggregate_access: 1
  repetitions: 1
  attack_simulation:
    batch_size:
      steps:
        - 512
        - 512
        - 32
        - 32
    optimizer_name: Adam
    optimizer_parameters:
      eps: 0.0001
    model_architecture:
      components:
        steps:
        - label: True
          loss: True
          activation: False
          gradient: False
          metrics: False
        - label: True
          loss: True
          activation: False
          gradient: False
          metrics: False
        - label: True
          loss: True
          activation: True
          gradient: True
          metrics: True
        - label: True
          loss: True
          activation: True
          gradient: True
          metrics: True
      gradient_component:
        - type: Dropout
          p: 0.2
        - type: Conv2d
          out_channels: 1000
          kernel_size:
          stride: 1
        - type: ReLU
      fcn_component:
        - type: Dropout
          p: 0.2
        - type: Linear
          out_features: 128
        - type: ReLU
        - type: Dropout
          p: 0.2
        - type: Linear
          in_features: 128
          out_features: 64
        - type: ReLU
      encoder_component:
        - type: Dropout
          p: 0.2
        - type: Linear
          out_features: 256
        - type: ReLU
        - type: Dropout
          p: 0.2
        - type: Linear
          in_features: 256
          out_features: 128
        - type: ReLU
        - type: Dropout
          p: 0.2
        - type: Linear
          in_features: 128
          out_features: 64
        - type: ReLU
        - type: Dropout
          p: 0.2
        - type: Linear
          in_features: 64
          out_features: 1
        - type: ReLU
