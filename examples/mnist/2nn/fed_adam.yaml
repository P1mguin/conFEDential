# Optimal 0.9409
simulation:
  data:
    dataset_name: MNIST
    batch_size: 16
    preprocess_fn: |
      def preprocess_fn(element):
        return {
          "x": element["image"].reshape(784) / 255.,
          "y": element["label"]
        }
  federation:
    client_count: 100
    fraction_fit: 0.1
    global_rounds: 10
    local_rounds: 20
  model:
    optimizer_name: FedAdam
    model_name: 2NN
    criterion_name: CrossEntropyLoss
    optimizer_parameters:
      local:
        lr: 0.25
      global:
        lr: 0.1
        betas:
          - 0.9
          - 0.999
        eps: 0.00000001
        weight_decay: 0.9999
    model_architecture:
      - type: Linear
        in_features: 784
        out_features: 200
      - type: ReLU
      - type: Linear
        in_features: 200
        out_features: 200
      - type: ReLU
      - type: Linear
        in_features: 200
        out_features: 200
      - type: ReLU
      - type: Linear
        in_features: 200
        out_features: 10
      - type: Softmax
        dim: -1
attack:
  data_access: 1.0
  message_access: server
  repetitions: 10
  attack_simulation:
    batch_size: 64
    optimizer_name: FedAvg
    optimizer_parameters:
      lr: 0.1
    model_architecture:
      gradient_component:
        - type: Dropout
          p: 0.2
        - type: Conv2d
          out_channels: 1000
          kernel_size:
          stride: 1
        - type: ReLU
      fcn_component:
        - type: Dropout
          p: 0.2
        - type: Linear
          out_features: 128
        - type: ReLU
        - type: Dropout
          p: 0.2
        - type: Linear
          in_features: 128
          out_features: 64
        - type: ReLU
      encoder_component:
        - type: Dropout
          p: 0.2
        - type: Linear
          out_features: 256
        - type: ReLU
        - type: Dropout
          p: 0.2
        - type: Linear
          in_features: 256
          out_features: 128
        - type: ReLU
        - type: Dropout
          p: 0.2
        - type: Linear
          in_features: 128
          out_features: 64
        - type: ReLU
        - type: Dropout
          p: 0.2
        - type: Linear
          in_features: 64
          out_features: 1
        - type: ReLU
        - type: Sigmoid
