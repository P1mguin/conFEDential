simulation:
  batch_size:
    values: [ 2, 4, 8 ] # Empirical, Self chosen (Partially Yang et al.)
  client_count: 100
  fraction_fit: 0.1
  global_rounds: 10
  local_rounds: 50 #Self chosen
  optimizer:
    optimizer_name: FedNAG
    lr:
      values: [0.001, 0.005, 0.01] #Self chosen
    momentum: 0.85 #Yang 2022 Federated Learning with Nesterov accelerated gradient
dataset:
  name: MNIST
  splitter:
    alpha: 1
    percent_non_iid: 25
  preprocess_fn: |
    def preprocess_fn(element):
      return {
        "x": element["image"].reshape(784) / 255.,
        "y": element["label"]
      }
model:
  name: 2NN
  criterion: CrossEntropyLoss
  layers:
    - type: Linear
      in_features: 784
      out_features: 200
    - type: ReLU
    - type: Linear
      in_features: 200
      out_features: 200
    - type: ReLU
    - type: Linear
      in_features: 200
      out_features: 200
    - type: ReLU
    - type: Linear
      in_features: 200
      out_features: 10
    - type: Softmax
      dim: -1