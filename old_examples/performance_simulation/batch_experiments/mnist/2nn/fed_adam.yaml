simulation:
  batch_size:
    values: [ 8, 16, 32 ] #Self chosen
  client_count: 100
  fraction_fit: 0.1
  global_rounds: 10
  local_rounds:
    values: [ 20, 50 ] #Self chosen
  optimizer:
    optimizer_name: FedAdam
    local:
      lr:
        values: [ 0.25, 0.3, 0.4 ] #Self chosen
    global:
      lr: 0.01 #Empirical, Kuo 2023 On noisy evaluation in federated hyperparameter tuning
      betas:
        - 0.9  #Reddi 2021 Adaptive federated optimization
        - 0.99 #Reddi 2021 Adaptive federated optimization
      eps: 0.000000001 #Self chosen
      weight_decay: 0.9999 #Kuo 2023 On noisy evaluation in federated hyperparameter tuning
dataset:
  name: MNIST
  preprocess_fn: |
    def preprocess_fn(element):
      return {
        "x": element["image"].reshape(784) / 255.,
        "y": element["label"]
      }
model:
  name: 2NN
  criterion: CrossEntropyLoss
  layers:
    - type: Linear
      in_features: 784
      out_features: 200
    - type: ReLU
    - type: Linear
      in_features: 200
      out_features: 200
    - type: ReLU
    - type: Linear
      in_features: 200
      out_features: 200
    - type: ReLU
    - type: Linear
      in_features: 200
      out_features: 10
    - type: Softmax
      dim: -1
