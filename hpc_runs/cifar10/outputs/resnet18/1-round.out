ctit080
2024-05-20 01:42:07,861	INFO usage_lib.py:412 -- Usage stats collection is enabled. To disable this, add `--disable-usage-stats` to the command that starts the cluster, or run the following command: `ray disable-usage-stats` before starting the cluster. See https://docs.ray.io/en/master/cluster/usage-stats.html for more details.
2024-05-20 01:42:07,862	INFO scripts.py:722 -- Local node IP: 10.20.240.10
2024-05-20 01:42:27,696	SUCC scripts.py:759 -- --------------------
2024-05-20 01:42:27,696	SUCC scripts.py:760 -- Ray runtime started.
2024-05-20 01:42:27,697	SUCC scripts.py:761 -- --------------------
2024-05-20 01:42:27,697	INFO scripts.py:763 -- Next steps
2024-05-20 01:42:27,697	INFO scripts.py:766 -- To add another node to this Ray cluster, run
2024-05-20 01:42:27,697	INFO scripts.py:769 --   ray start --address='10.20.240.10:6379'
2024-05-20 01:42:27,697	INFO scripts.py:778 -- To connect to this Ray cluster:
2024-05-20 01:42:27,697	INFO scripts.py:780 -- import ray
2024-05-20 01:42:27,697	INFO scripts.py:781 -- ray.init()
2024-05-20 01:42:27,697	INFO scripts.py:812 -- To terminate the Ray runtime, run
2024-05-20 01:42:27,697	INFO scripts.py:813 --   ray stop
2024-05-20 01:42:27,698	INFO scripts.py:816 -- To view the status of the cluster, use
2024-05-20 01:42:27,698	INFO scripts.py:817 --   ray status
2024-05-20 01:42:54.425996: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-20 01:42:57.071499: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
INFO flwr 2024-05-20 01:43:08,080 | Data.py:31 | Preprocessing the federated learning dataset
INFO flwr 2024-05-20 01:43:08,081 | Data.py:107 | Found preprocessed data for the given preprocess function, returning
INFO flwr 2024-05-20 01:43:13,186 | Simulation.py:37 | Preparing datasets for federated learning simulation
INFO flwr 2024-05-20 01:43:13,186 | Simulation.py:255 | Found previously split dataloaders, loading them
INFO flwr 2024-05-20 01:43:17,902 | main.py:103 | Loaded 1 configs with name CIFAR10-RESNET18-FEDADAM, running...
INFO flwr 2024-05-20 01:43:17,902 | main.py:105 | Config:
	Simulation:
		Data:
			dataset_name: cifar10
			batch_size: 32
			preprocess_fn:
				def preprocess_fn(element):
				  return {
				    "x": (element["img"] / 255.).transpose(2, 0, 1),
				    "y": element["label"]
				  }
		Federation:
			client_count: 100
			fraction_fit: 0.1
			global_rounds: 1
			local_rounds: 1
		Model:
			optimizer_name: FedAdam
			model_name: ResNet18
			criterion_name: CrossEntropyLoss
			optimizer_parameters: 
				local: {'lr': 0.01}
				global: {'lr': 0.1, 'betas': [0.9, 0.999], 'eps': 1e-09, 'weight_decay': 0.9999}
			model_architecture:
				repo_or_dir: pytorch/vision:v0.10.0
					model: resnet18
					pretrained: False
					out_features: 10
	Attack:
		data_access: all
		message_access: server
		repetitions: 10
		Attack Simulation:
			batch_size: 64
			optimizer_name: FedAvg
			optimizer_parameters:
				lr: 0.1
			ModelArchitecture:
				gradient_component:
					type: Dropout
						p: 0.2
					type: Conv3d
						out_channels: 1000
						kernel_size: [1, 1]
						stride: 1
					type: ReLU
				fcn_component:
					type: Dropout
						p: 0.2
					type: Linear
						out_features: 128
					type: ReLU
					type: Dropout
						p: 0.2
					type: Linear
						in_features: 128
						out_features: 64
					type: ReLU
				encoder_component:
					type: Dropout
						p: 0.2
					type: Linear
						out_features: 256
					type: ReLU
					type: Dropout
						p: 0.2
					type: Linear
						in_features: 256
						out_features: 128
					type: ReLU
					type: Dropout
						p: 0.2
					type: Linear
						in_features: 128
						out_features: 64
					type: ReLU
					type: Dropout
						p: 0.2
					type: Linear
						in_features: 64
						out_features: 1
					type: ReLU
					type: Sigmoid
INFO flwr 2024-05-20 01:43:17,902 | Config.py:68 | Starting conFEDential simulation
INFO flwr 2024-05-20 01:43:17,904 | Config.py:72 | No previous federated learning simulation found, starting training simulation...
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-05-20 01:43:29,987 | Simulation.py:395 | Created 2 clients with resources 8 CPUs, 0.5 GPUs, and 8.0GB for the total available 16 CPUs, 1 GPUs and 16.0GB.
INFO flwr 2024-05-20 01:43:29,987 | Simulation.py:160 | Starting federated learning simulation
2024-05-20 01:43:30,048	INFO worker.py:1431 -- Connecting to existing Ray cluster at address: 10.20.240.10:6379...
2024-05-20 01:43:30,062	INFO worker.py:1621 -- Connected to Ray cluster.
INFO flwr 2024-05-20 01:43:50,396 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=1, round_timeout=None)
2024-05-20 01:43:50,670	INFO worker.py:1453 -- Calling ray.init() again after it has already been called.
INFO flwr 2024-05-20 01:43:50,671 | app.py:213 | Flower VCE: Ray initialized with resources: {'object_store_memory': 160021735833.0, 'CPU': 16.0, 'node:10.20.240.10': 1.0, 'memory': 17179869184.0, 'node:__internal_head__': 1.0, 'GPU': 1.0, 'accelerator_type:P100': 1.0}
INFO flwr 2024-05-20 01:43:50,671 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-05-20 01:43:50,671 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.5, 'memory': 8589934592}
INFO flwr 2024-05-20 01:43:50,681 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 2 actors
INFO flwr 2024-05-20 01:43:50,681 | server.py:89 | Initializing global parameters
INFO flwr 2024-05-20 01:43:50,681 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-05-20 01:43:50,682 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-05-20 01:43:54,251 | server.py:94 | initial parameters (loss, other metrics): 0.0002507773160934448, {'accuracy': 0.0943, 'data_size': 10000}
INFO flwr 2024-05-20 01:43:54,251 | server.py:104 | FL starting
DEBUG flwr 2024-05-20 01:43:54,251 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=2147565)[0m 2024-05-20 01:43:59.978790: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=2147565)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=2147564)[0m 2024-05-20 01:44:02.440994: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=2147564)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=2147564)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=2147564)[0m 2024-05-20 01:43:59.988564: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=2147564)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=2147565)[0m 2024-05-20 01:44:02.441684: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
DEBUG flwr 2024-05-20 01:44:27,056 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-05-20 01:46:00,541 | server.py:125 | fit progress: (1, 0.008312761688232423, {'accuracy': 0.1044, 'data_size': 10000}, 126.28952082898468)
INFO flwr 2024-05-20 01:46:00,541 | server.py:171 | evaluate_round 1: no clients selected, cancel
INFO flwr 2024-05-20 01:46:00,542 | server.py:153 | FL finished in 126.29116778215393
INFO flwr 2024-05-20 01:46:00,553 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-05-20 01:46:00,553 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-05-20 01:46:00,553 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-05-20 01:46:00,553 | app.py:229 | app_fit: losses_centralized [(0, 0.0002507773160934448), (1, 0.008312761688232423)]
INFO flwr 2024-05-20 01:46:00,553 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0943), (1, 0.1044)], 'data_size': [(0, 10000), (1, 10000)]}
[2m[36m(DefaultActor pid=2147565)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=2147565)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
wandb: 
wandb: Run summary:
wandb: accuracy 0.1044
wandb:     loss 0.00831
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240520_014329-hz8sbb0x
wandb: Find logs at: ./wandb/offline-run-20240520_014329-hz8sbb0x/logs
2024-05-20 01:47:37.553272: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-20 01:47:40.037653: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
INFO flwr 2024-05-20 01:47:50,152 | Data.py:31 | Preprocessing the federated learning dataset
INFO flwr 2024-05-20 01:47:50,153 | Data.py:107 | Found preprocessed data for the given preprocess function, returning
INFO flwr 2024-05-20 01:47:51,969 | Simulation.py:37 | Preparing datasets for federated learning simulation
INFO flwr 2024-05-20 01:47:51,970 | Simulation.py:255 | Found previously split dataloaders, loading them
INFO flwr 2024-05-20 01:47:52,893 | main.py:103 | Loaded 1 configs with name CIFAR10-RESNET18-FEDAVG, running...
INFO flwr 2024-05-20 01:47:52,893 | main.py:105 | Config:
	Simulation:
		Data:
			dataset_name: cifar10
			batch_size: 32
			preprocess_fn:
				def preprocess_fn(element):
				  return {
				    "x": (element["img"] / 255.).transpose(2, 0, 1),
				    "y": element["label"]
				  }
		Federation:
			client_count: 100
			fraction_fit: 0.1
			global_rounds: 1
			local_rounds: 1
		Model:
			optimizer_name: FedAvg
			model_name: ResNet18
			criterion_name: CrossEntropyLoss
			optimizer_parameters: 
				lr: 0.01
			model_architecture:
				repo_or_dir: pytorch/vision:v0.10.0
					model: resnet18
					pretrained: False
					out_features: 10
	Attack:
		data_access: all
		message_access: server
		repetitions: 10
		Attack Simulation:
			batch_size: 64
			optimizer_name: FedAvg
			optimizer_parameters:
				lr: 0.1
			ModelArchitecture:
				gradient_component:
					type: Dropout
						p: 0.2
					type: Conv3d
						out_channels: 1000
						kernel_size: [1, 1]
						stride: 1
					type: ReLU
				fcn_component:
					type: Dropout
						p: 0.2
					type: Linear
						out_features: 128
					type: ReLU
					type: Dropout
						p: 0.2
					type: Linear
						in_features: 128
						out_features: 64
					type: ReLU
				encoder_component:
					type: Dropout
						p: 0.2
					type: Linear
						out_features: 256
					type: ReLU
					type: Dropout
						p: 0.2
					type: Linear
						in_features: 256
						out_features: 128
					type: ReLU
					type: Dropout
						p: 0.2
					type: Linear
						in_features: 128
						out_features: 64
					type: ReLU
					type: Dropout
						p: 0.2
					type: Linear
						in_features: 64
						out_features: 1
					type: ReLU
					type: Sigmoid
INFO flwr 2024-05-20 01:47:52,894 | Config.py:68 | Starting conFEDential simulation
INFO flwr 2024-05-20 01:47:52,911 | Config.py:72 | No previous federated learning simulation found, starting training simulation...
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-05-20 01:48:04,692 | Simulation.py:395 | Created 2 clients with resources 8 CPUs, 0.5 GPUs, and 8.0GB for the total available 16 CPUs, 1 GPUs and 16.0GB.
INFO flwr 2024-05-20 01:48:04,693 | Simulation.py:160 | Starting federated learning simulation
2024-05-20 01:48:04,757	INFO worker.py:1431 -- Connecting to existing Ray cluster at address: 10.20.240.10:6379...
2024-05-20 01:48:04,770	INFO worker.py:1621 -- Connected to Ray cluster.
INFO flwr 2024-05-20 01:48:04,787 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=1, round_timeout=None)
2024-05-20 01:48:04,867	INFO worker.py:1453 -- Calling ray.init() again after it has already been called.
INFO flwr 2024-05-20 01:48:04,868 | app.py:213 | Flower VCE: Ray initialized with resources: {'accelerator_type:P100': 1.0, 'CPU': 16.0, 'object_store_memory': 160021735833.0, 'node:__internal_head__': 1.0, 'GPU': 1.0, 'memory': 17179869184.0, 'node:10.20.240.10': 1.0}
INFO flwr 2024-05-20 01:48:04,868 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-05-20 01:48:04,868 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.5, 'memory': 8589934592}
INFO flwr 2024-05-20 01:48:04,877 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 2 actors
INFO flwr 2024-05-20 01:48:04,878 | server.py:89 | Initializing global parameters
INFO flwr 2024-05-20 01:48:04,878 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-05-20 01:48:04,878 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-05-20 01:48:06,099 | server.py:94 | initial parameters (loss, other metrics): 0.0002507773160934448, {'accuracy': 0.0943, 'data_size': 10000}
INFO flwr 2024-05-20 01:48:06,099 | server.py:104 | FL starting
DEBUG flwr 2024-05-20 01:48:06,099 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=2148287)[0m 2024-05-20 01:48:19.302719: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=2148287)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=2148287)[0m 2024-05-20 01:48:22.768408: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=2148287)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=2148287)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=2148286)[0m 2024-05-20 01:48:19.330552: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=2148286)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=2148286)[0m 2024-05-20 01:48:22.791864: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
DEBUG flwr 2024-05-20 01:48:50,566 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-05-20 01:50:26,716 | server.py:125 | fit progress: (1, 0.000226815128326416, {'accuracy': 0.1613, 'data_size': 10000}, 140.6164926448837)
INFO flwr 2024-05-20 01:50:26,716 | server.py:171 | evaluate_round 1: no clients selected, cancel
INFO flwr 2024-05-20 01:50:26,717 | server.py:153 | FL finished in 140.61805945192464
INFO flwr 2024-05-20 01:50:26,723 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-05-20 01:50:26,723 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-05-20 01:50:26,723 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-05-20 01:50:26,723 | app.py:229 | app_fit: losses_centralized [(0, 0.0002507773160934448), (1, 0.000226815128326416)]
INFO flwr 2024-05-20 01:50:26,723 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0943), (1, 0.1613)], 'data_size': [(0, 10000), (1, 10000)]}
[2m[36m(DefaultActor pid=2148286)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=2148286)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
wandb: 
wandb: Run summary:
wandb: accuracy 0.1613
wandb:     loss 0.00023
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240520_014803-pwqultot
wandb: Find logs at: ./wandb/offline-run-20240520_014803-pwqultot/logs
2024-05-20 01:51:57.789046: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-20 01:51:59.981582: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
INFO flwr 2024-05-20 01:52:10,575 | Data.py:31 | Preprocessing the federated learning dataset
INFO flwr 2024-05-20 01:52:10,575 | Data.py:107 | Found preprocessed data for the given preprocess function, returning
INFO flwr 2024-05-20 01:52:14,565 | Simulation.py:37 | Preparing datasets for federated learning simulation
INFO flwr 2024-05-20 01:52:14,566 | Simulation.py:255 | Found previously split dataloaders, loading them
INFO flwr 2024-05-20 01:52:15,476 | main.py:103 | Loaded 1 configs with name CIFAR10-RESNET18-FEDNAG, running...
INFO flwr 2024-05-20 01:52:15,476 | main.py:105 | Config:
	Simulation:
		Data:
			dataset_name: cifar10
			batch_size: 32
			preprocess_fn:
				def preprocess_fn(element):
				  return {
				    "x": (element["img"] / 255.).transpose(2, 0, 1),
				    "y": element["label"]
				  }
		Federation:
			client_count: 100
			fraction_fit: 0.1
			global_rounds: 1
			local_rounds: 1
		Model:
			optimizer_name: FedNag
			model_name: ResNet18
			criterion_name: CrossEntropyLoss
			optimizer_parameters: 
				lr: 0.01
				momentum: 0.9
			model_architecture:
				repo_or_dir: pytorch/vision:v0.10.0
					model: resnet18
					pretrained: False
					out_features: 10
	Attack:
		data_access: all
		message_access: server
		repetitions: 10
		Attack Simulation:
			batch_size: 64
			optimizer_name: FedAvg
			optimizer_parameters:
				lr: 0.1
			ModelArchitecture:
				gradient_component:
					type: Dropout
						p: 0.2
					type: Conv3d
						out_channels: 1000
						kernel_size: [1, 1]
						stride: 1
					type: ReLU
				fcn_component:
					type: Dropout
						p: 0.2
					type: Linear
						out_features: 128
					type: ReLU
					type: Dropout
						p: 0.2
					type: Linear
						in_features: 128
						out_features: 64
					type: ReLU
				encoder_component:
					type: Dropout
						p: 0.2
					type: Linear
						out_features: 256
					type: ReLU
					type: Dropout
						p: 0.2
					type: Linear
						in_features: 256
						out_features: 128
					type: ReLU
					type: Dropout
						p: 0.2
					type: Linear
						in_features: 128
						out_features: 64
					type: ReLU
					type: Dropout
						p: 0.2
					type: Linear
						in_features: 64
						out_features: 1
					type: ReLU
					type: Sigmoid
INFO flwr 2024-05-20 01:52:15,476 | Config.py:68 | Starting conFEDential simulation
INFO flwr 2024-05-20 01:52:16,803 | Config.py:72 | No previous federated learning simulation found, starting training simulation...
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-05-20 01:52:29,753 | Simulation.py:395 | Created 2 clients with resources 8 CPUs, 0.5 GPUs, and 8.0GB for the total available 16 CPUs, 1 GPUs and 16.0GB.
INFO flwr 2024-05-20 01:52:29,753 | Simulation.py:160 | Starting federated learning simulation
2024-05-20 01:52:29,814	INFO worker.py:1431 -- Connecting to existing Ray cluster at address: 10.20.240.10:6379...
2024-05-20 01:52:29,829	INFO worker.py:1621 -- Connected to Ray cluster.
INFO flwr 2024-05-20 01:52:29,846 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=1, round_timeout=None)
2024-05-20 01:52:29,911	INFO worker.py:1453 -- Calling ray.init() again after it has already been called.
INFO flwr 2024-05-20 01:52:29,911 | app.py:213 | Flower VCE: Ray initialized with resources: {'node:__internal_head__': 1.0, 'CPU': 16.0, 'GPU': 1.0, 'object_store_memory': 160021735833.0, 'accelerator_type:P100': 1.0, 'node:10.20.240.10': 1.0, 'memory': 17179869184.0}
INFO flwr 2024-05-20 01:52:29,911 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-05-20 01:52:29,912 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.5, 'memory': 8589934592}
INFO flwr 2024-05-20 01:52:29,921 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 2 actors
INFO flwr 2024-05-20 01:52:29,922 | server.py:89 | Initializing global parameters
INFO flwr 2024-05-20 01:52:29,922 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-05-20 01:52:29,922 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-05-20 01:52:31,015 | server.py:94 | initial parameters (loss, other metrics): 0.0002507773160934448, {'accuracy': 0.0943, 'data_size': 10000}
INFO flwr 2024-05-20 01:52:31,016 | server.py:104 | FL starting
DEBUG flwr 2024-05-20 01:52:31,016 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=2149065)[0m 2024-05-20 01:52:47.520292: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=2149065)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=2149065)[0m 2024-05-20 01:52:50.562103: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=2149065)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=2149065)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=2149064)[0m 2024-05-20 01:52:47.532029: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=2149064)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=2149064)[0m 2024-05-20 01:52:50.706783: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
DEBUG flwr 2024-05-20 01:53:27,484 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-05-20 01:55:50,561 | server.py:125 | fit progress: (1, 0.0002164278507232666, {'accuracy': 0.1979, 'data_size': 10000}, 199.54522604099475)
INFO flwr 2024-05-20 01:55:50,562 | server.py:171 | evaluate_round 1: no clients selected, cancel
INFO flwr 2024-05-20 01:55:50,563 | server.py:153 | FL finished in 199.54678129800595
INFO flwr 2024-05-20 01:55:50,578 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-05-20 01:55:50,578 | app.py:227 | app_fit: metrics_distributed_fit {'velocity': [(1, <generator object compute_weighted_average.<locals>.<genexpr> at 0x7fc7fb42dbd0>)]}
INFO flwr 2024-05-20 01:55:50,578 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-05-20 01:55:50,578 | app.py:229 | app_fit: losses_centralized [(0, 0.0002507773160934448), (1, 0.0002164278507232666)]
INFO flwr 2024-05-20 01:55:50,578 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0943), (1, 0.1979)], 'data_size': [(0, 10000), (1, 10000)]}
[2m[36m(DefaultActor pid=2149064)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=2149064)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
wandb: 
wandb: Run summary:
wandb: accuracy 0.1979
wandb:     loss 0.00022
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240520_015229-0g54o1z7
wandb: Find logs at: ./wandb/offline-run-20240520_015229-0g54o1z7/logs
2024-05-20 01:57:18,396	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --raylet_socket_name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/raylet --store_socket_name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/plasma_store --object_manager_port=0 --min_worker_port=10002 --max_worker_port=19999 --node_manager_port=0 --node_ip_address=10.20.240.10 --maximum_startup_concurrency=16 --static_resource_list=node:10.20.240.10,1.0,node:__internal_head__,1.0,accelerator_type:P100,1,CPU,16,GPU,1,memory,17179869184,object_store_memory,160021735833 "--python_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/default_worker.py --node-ip-address=10.20.240.10 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/plasma_store --raylet-name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/raylet --redis-address=None --temp-dir=/local/ray --metrics-agent-port=51946 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=10.20.240.10:6379 --session-name=session_2024-05-20_01-42-08_017531_2146459 --temp-dir=/local/ray --webui= RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER" "--java_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py -Dray.address=10.20.240.10:6379 -Dray.raylet.node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER -Dray.object-store.socket-name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/plasma_store -Dray.raylet.socket-name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/raylet -Dray.redis.password= -Dray.node-ip=10.20.240.10 -Dray.home=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/../.. -Dray.logging.dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459/logs -Dray.session-dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459 RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER io.ray.runtime.runner.worker.DefaultWorker" --cpp_worker_command= --native_library_path=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/cpp/lib --temp_dir=/local/ray --session_dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459 --log_dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459/logs --resource_dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459/runtime_resources --metrics-agent-port=51946 --metrics_export_port=56611 --object_store_memory=160021735833 --plasma_directory=/dev/shm --ray-debugger-external=0 --gcs-address=10.20.240.10:6379 --session-name=session_2024-05-20_01-42-08_017531_2146459 --labels= --head --num_prestart_python_workers=16 "--agent_command=/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/dashboard/agent.py --node-ip-address=10.20.240.10 --metrics-export-port=56611 --dashboard-agent-port=51946 --listen-port=52365 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/plasma_store --raylet-name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/raylet --temp-dir=/local/ray --session-dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459 --runtime-env-dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459/runtime_resources --log-dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --session-name=session_2024-05-20_01-42-08_017531_2146459 --gcs-address=10.20.240.10:6379 --minimal"` (via SIGTERM)
2024-05-20 01:57:18,399	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/autoscaler/_private/monitor.py --logs-dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=10.20.240.10:6379 --monitor-ip=10.20.240.10` (via SIGTERM)
2024-05-20 01:57:18,400	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/log_monitor.py --logs-dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459/logs --gcs-address=10.20.240.10:6379 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5` (via SIGTERM)
2024-05-20 01:57:18,402	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/bin/python -m ray.util.client.server --address=10.20.240.10:6379 --host=0.0.0.0 --port=10001 --mode=proxy --metrics-agent-port=51946` (via SIGTERM)
2024-05-20 01:57:18,406	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --raylet_socket_name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/raylet --store_socket_name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/plasma_store --object_manager_port=0 --min_worker_port=10002 --max_worker_port=19999 --node_manager_port=0 --node_ip_address=10.20.240.10 --maximum_startup_concurrency=16 --static_resource_list=node:10.20.240.10,1.0,node:__internal_head__,1.0,accelerator_type:P100,1,CPU,16,GPU,1,memory,17179869184,object_store_memory,160021735833 "--python_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/default_worker.py --node-ip-address=10.20.240.10 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/plasma_store --raylet-name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/raylet --redis-address=None --temp-dir=/local/ray --metrics-agent-port=51946 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=10.20.240.10:6379 --session-name=session_2024-05-20_01-42-08_017531_2146459 --temp-dir=/local/ray --webui= RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER" "--java_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py -Dray.address=10.20.240.10:6379 -Dray.raylet.node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER -Dray.object-store.socket-name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/plasma_store -Dray.raylet.socket-name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/raylet -Dray.redis.password= -Dray.node-ip=10.20.240.10 -Dray.home=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/../.. -Dray.logging.dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459/logs -Dray.session-dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459 RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER io.ray.runtime.runner.worker.DefaultWorker" --cpp_worker_command= --native_library_path=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/cpp/lib --temp_dir=/local/ray --session_dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459 --log_dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459/logs --resource_dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459/runtime_resources --metrics-agent-port=51946 --metrics_export_port=56611 --object_store_memory=160021735833 --plasma_directory=/dev/shm --ray-debugger-external=0 --gcs-address=10.20.240.10:6379 --session-name=session_2024-05-20_01-42-08_017531_2146459 --labels= --head --num_prestart_python_workers=16 "--agent_command=/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/dashboard/agent.py --node-ip-address=10.20.240.10 --metrics-export-port=56611 --dashboard-agent-port=51946 --listen-port=52365 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/plasma_store --raylet-name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/raylet --temp-dir=/local/ray --session-dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459 --runtime-env-dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459/runtime_resources --log-dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --session-name=session_2024-05-20_01-42-08_017531_2146459 --gcs-address=10.20.240.10:6379 --minimal"` (via SIGTERM)
2024-05-20 01:57:18,409	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --raylet_socket_name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/raylet --store_socket_name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/plasma_store --object_manager_port=0 --min_worker_port=10002 --max_worker_port=19999 --node_manager_port=0 --node_ip_address=10.20.240.10 --maximum_startup_concurrency=16 --static_resource_list=node:10.20.240.10,1.0,node:__internal_head__,1.0,accelerator_type:P100,1,CPU,16,GPU,1,memory,17179869184,object_store_memory,160021735833 "--python_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/default_worker.py --node-ip-address=10.20.240.10 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/plasma_store --raylet-name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/raylet --redis-address=None --temp-dir=/local/ray --metrics-agent-port=51946 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=10.20.240.10:6379 --session-name=session_2024-05-20_01-42-08_017531_2146459 --temp-dir=/local/ray --webui= RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER" "--java_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py -Dray.address=10.20.240.10:6379 -Dray.raylet.node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER -Dray.object-store.socket-name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/plasma_store -Dray.raylet.socket-name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/raylet -Dray.redis.password= -Dray.node-ip=10.20.240.10 -Dray.home=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/../.. -Dray.logging.dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459/logs -Dray.session-dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459 RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER io.ray.runtime.runner.worker.DefaultWorker" --cpp_worker_command= --native_library_path=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/cpp/lib --temp_dir=/local/ray --session_dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459 --log_dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459/logs --resource_dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459/runtime_resources --metrics-agent-port=51946 --metrics_export_port=56611 --object_store_memory=160021735833 --plasma_directory=/dev/shm --ray-debugger-external=0 --gcs-address=10.20.240.10:6379 --session-name=session_2024-05-20_01-42-08_017531_2146459 --labels= --head --num_prestart_python_workers=16 "--agent_command=/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/dashboard/agent.py --node-ip-address=10.20.240.10 --metrics-export-port=56611 --dashboard-agent-port=51946 --listen-port=52365 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/plasma_store --raylet-name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/raylet --temp-dir=/local/ray --session-dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459 --runtime-env-dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459/runtime_resources --log-dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --session-name=session_2024-05-20_01-42-08_017531_2146459 --gcs-address=10.20.240.10:6379 --minimal"` (via SIGTERM)
2024-05-20 01:57:18,412	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --raylet_socket_name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/raylet --store_socket_name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/plasma_store --object_manager_port=0 --min_worker_port=10002 --max_worker_port=19999 --node_manager_port=0 --node_ip_address=10.20.240.10 --maximum_startup_concurrency=16 --static_resource_list=node:10.20.240.10,1.0,node:__internal_head__,1.0,accelerator_type:P100,1,CPU,16,GPU,1,memory,17179869184,object_store_memory,160021735833 "--python_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/default_worker.py --node-ip-address=10.20.240.10 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/plasma_store --raylet-name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/raylet --redis-address=None --temp-dir=/local/ray --metrics-agent-port=51946 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=10.20.240.10:6379 --session-name=session_2024-05-20_01-42-08_017531_2146459 --temp-dir=/local/ray --webui= RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER" "--java_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py -Dray.address=10.20.240.10:6379 -Dray.raylet.node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER -Dray.object-store.socket-name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/plasma_store -Dray.raylet.socket-name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/raylet -Dray.redis.password= -Dray.node-ip=10.20.240.10 -Dray.home=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/../.. -Dray.logging.dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459/logs -Dray.session-dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459 RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER io.ray.runtime.runner.worker.DefaultWorker" --cpp_worker_command= --native_library_path=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/cpp/lib --temp_dir=/local/ray --session_dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459 --log_dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459/logs --resource_dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459/runtime_resources --metrics-agent-port=51946 --metrics_export_port=56611 --object_store_memory=160021735833 --plasma_directory=/dev/shm --ray-debugger-external=0 --gcs-address=10.20.240.10:6379 --session-name=session_2024-05-20_01-42-08_017531_2146459 --labels= --head --num_prestart_python_workers=16 "--agent_command=/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/dashboard/agent.py --node-ip-address=10.20.240.10 --metrics-export-port=56611 --dashboard-agent-port=51946 --listen-port=52365 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/plasma_store --raylet-name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/raylet --temp-dir=/local/ray --session-dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459 --runtime-env-dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459/runtime_resources --log-dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --session-name=session_2024-05-20_01-42-08_017531_2146459 --gcs-address=10.20.240.10:6379 --minimal"` (via SIGTERM)
2024-05-20 01:57:18,415	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/log_monitor.py --logs-dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459/logs --gcs-address=10.20.240.10:6379 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5` (via SIGTERM)
2024-05-20 01:57:18,421	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --raylet_socket_name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/raylet --store_socket_name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/plasma_store --object_manager_port=0 --min_worker_port=10002 --max_worker_port=19999 --node_manager_port=0 --node_ip_address=10.20.240.10 --maximum_startup_concurrency=16 --static_resource_list=node:10.20.240.10,1.0,node:__internal_head__,1.0,accelerator_type:P100,1,CPU,16,GPU,1,memory,17179869184,object_store_memory,160021735833 "--python_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/default_worker.py --node-ip-address=10.20.240.10 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/plasma_store --raylet-name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/raylet --redis-address=None --temp-dir=/local/ray --metrics-agent-port=51946 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=10.20.240.10:6379 --session-name=session_2024-05-20_01-42-08_017531_2146459 --temp-dir=/local/ray --webui= RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER" "--java_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py -Dray.address=10.20.240.10:6379 -Dray.raylet.node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER -Dray.object-store.socket-name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/plasma_store -Dray.raylet.socket-name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/raylet -Dray.redis.password= -Dray.node-ip=10.20.240.10 -Dray.home=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/../.. -Dray.logging.dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459/logs -Dray.session-dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459 RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER io.ray.runtime.runner.worker.DefaultWorker" --cpp_worker_command= --native_library_path=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/cpp/lib --temp_dir=/local/ray --session_dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459 --log_dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459/logs --resource_dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459/runtime_resources --metrics-agent-port=51946 --metrics_export_port=56611 --object_store_memory=160021735833 --plasma_directory=/dev/shm --ray-debugger-external=0 --gcs-address=10.20.240.10:6379 --session-name=session_2024-05-20_01-42-08_017531_2146459 --labels= --head --num_prestart_python_workers=16 "--agent_command=/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/dashboard/agent.py --node-ip-address=10.20.240.10 --metrics-export-port=56611 --dashboard-agent-port=51946 --listen-port=52365 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/plasma_store --raylet-name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/raylet --temp-dir=/local/ray --session-dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459 --runtime-env-dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459/runtime_resources --log-dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --session-name=session_2024-05-20_01-42-08_017531_2146459 --gcs-address=10.20.240.10:6379 --minimal"` (via SIGTERM)
2024-05-20 01:57:18,422	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/dashboard/agent.py --node-ip-address=10.20.240.10 --metrics-export-port=56611 --dashboard-agent-port=51946 --listen-port=52365 --node-manager-port=36103 --object-store-name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/plasma_store --raylet-name=/local/ray/session_2024-05-20_01-42-08_017531_2146459/sockets/raylet --temp-dir=/local/ray --session-dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459 --runtime-env-dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459/runtime_resources --log-dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --session-name=session_2024-05-20_01-42-08_017531_2146459 --gcs-address=10.20.240.10:6379 --minimal --agent-id 424238335` (via SIGTERM)
2024-05-20 01:57:18,425	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/dashboard/dashboard.py --host=127.0.0.1 --port=8265 --port-retries=0 --temp-dir=/local/ray --log-dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459/logs --session-dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=10.20.240.10:6379 --node-ip-address=10.20.240.10 --minimal` (via SIGTERM)
2024-05-20 01:57:18,430	INFO scripts.py:1098 -- 1/6 stopped.2024-05-20 01:57:18,430	INFO scripts.py:1098 -- 2/6 stopped.2024-05-20 01:57:18,436	INFO scripts.py:1098 -- 3/6 stopped.2024-05-20 01:57:18,781	INFO scripts.py:1098 -- 4/6 stopped.2024-05-20 01:57:19,033	INFO scripts.py:1098 -- 5/6 stopped.2024-05-20 01:57:19,033	INFO scripts.py:1098 -- 6/6 stopped.2024-05-20 01:57:19,226	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_dir=/local/ray/session_2024-05-20_01-42-08_017531_2146459/logs --config_list=eyJvYmplY3Rfc3BpbGxpbmdfY29uZmlnIjogIntcInR5cGVcIjogXCJmaWxlc3lzdGVtXCIsIFwicGFyYW1zXCI6IHtcImRpcmVjdG9yeV9wYXRoXCI6IFwiL2xvY2FsL3JheS9zZXNzaW9uXzIwMjQtMDUtMjBfMDEtNDItMDhfMDE3NTMxXzIxNDY0NTlcIn19IiwgImlzX2V4dGVybmFsX3N0b3JhZ2VfdHlwZV9mcyI6IHRydWV9 --gcs_server_port=6379 --metrics-agent-port=51946 --node-ip-address=10.20.240.10 --session-name=session_2024-05-20_01-42-08_017531_2146459` (via SIGTERM)
2024-05-20 01:57:19,679	INFO scripts.py:1098 -- 1/1 stopped.2024-05-20 01:57:19,679	SUCC scripts.py:1142 -- Stopped all 7 Ray processes.
