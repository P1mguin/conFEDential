ctit082
2024-04-26 17:41:31.912422: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-04-26 17:41:33.698923: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
INFO flwr 2024-04-26 17:41:43,037 | batch_run_simulation.py:80 | Loaded 18 configs with name MINST-2NN-FEDADAM, running...
INFO flwr 2024-04-26 17:41:43,038 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 8
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 20
		Optimizer: FedAdam
			local: {'lr': 0.25}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: 2NN
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=200, bias=True)
			    (1): ReLU()
			    (2): Linear(in_features=200, out_features=200, bias=True)
			    (3): ReLU()
			    (4): Linear(in_features=200, out_features=200, bias=True)
			    (5): ReLU()
			    (6): Linear(in_features=200, out_features=10, bias=True)
			    (7): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 17:41:45,287 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
2024-04-26 17:41:48,242	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 17:41:49,052	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 17:41:49,364	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 17:41:49,366	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 17:42:00,822 | app.py:213 | Flower VCE: Ray initialized with resources: {'GPU': 1.0, 'memory': 173596091392.0, 'accelerator_type:TITAN': 1.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0, 'CPU': 64.0, 'object_store_memory': 78684039168.0}
INFO flwr 2024-04-26 17:42:00,823 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 17:42:00,823 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 17:42:00,839 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 17:42:00,840 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 17:42:00,840 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 17:42:00,841 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 17:42:05,657 | server.py:94 | initial parameters (loss, other metrics): 2.302842617034912, {'accuracy': 0.0938, 'data_size': 10000}
INFO flwr 2024-04-26 17:42:05,657 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 17:42:05,658 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=52251)[0m 2024-04-26 17:42:07.171319: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=52251)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=52237)[0m 2024-04-26 17:42:09.585745: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=52248)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=52248)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=52248)[0m 2024-04-26 17:42:07.328390: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)[0m
[2m[36m(pid=52248)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=52253)[0m 2024-04-26 17:42:09.640410: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 17:42:34,323 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 17:42:35,879 | server.py:125 | fit progress: (1, 2.2322754859924316, {'accuracy': 0.5909, 'data_size': 10000}, 30.22101796000061)
INFO flwr 2024-04-26 17:42:35,879 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 17:42:35,879 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:42:50,946 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 17:42:52,207 | server.py:125 | fit progress: (2, 1.8239421844482422, {'accuracy': 0.6687, 'data_size': 10000}, 46.54934245899858)
INFO flwr 2024-04-26 17:42:52,207 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 17:42:52,208 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:43:06,014 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 17:43:07,559 | server.py:125 | fit progress: (3, 1.6664124727249146, {'accuracy': 0.7958, 'data_size': 10000}, 61.90109836999909)
INFO flwr 2024-04-26 17:43:07,559 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 17:43:07,559 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:43:21,116 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 17:43:22,592 | server.py:125 | fit progress: (4, 1.6111600399017334, {'accuracy': 0.8491, 'data_size': 10000}, 76.9342150750017)
INFO flwr 2024-04-26 17:43:22,592 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 17:43:22,592 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:43:36,954 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 17:43:38,519 | server.py:125 | fit progress: (5, 1.5747712850570679, {'accuracy': 0.8863, 'data_size': 10000}, 92.86147227800029)
INFO flwr 2024-04-26 17:43:38,519 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 17:43:38,520 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:43:51,794 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 17:43:53,123 | server.py:125 | fit progress: (6, 1.5489333868026733, {'accuracy': 0.9117, 'data_size': 10000}, 107.46542552499886)
INFO flwr 2024-04-26 17:43:53,123 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 17:43:53,124 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:44:06,554 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 17:44:07,830 | server.py:125 | fit progress: (7, 1.545853853225708, {'accuracy': 0.9148, 'data_size': 10000}, 122.17268983100075)
INFO flwr 2024-04-26 17:44:07,831 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 17:44:07,831 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:44:24,961 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 17:44:26,278 | server.py:125 | fit progress: (8, 1.5429942607879639, {'accuracy': 0.9177, 'data_size': 10000}, 140.6203816240013)
INFO flwr 2024-04-26 17:44:26,278 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 17:44:26,279 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:44:40,272 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 17:44:41,555 | server.py:125 | fit progress: (9, 1.5464026927947998, {'accuracy': 0.9147, 'data_size': 10000}, 155.89725382500183)
INFO flwr 2024-04-26 17:44:41,555 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 17:44:41,556 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:44:55,535 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 17:44:56,851 | server.py:125 | fit progress: (10, 1.5461044311523438, {'accuracy': 0.915, 'data_size': 10000}, 171.1935366430007)
INFO flwr 2024-04-26 17:44:56,852 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 17:44:56,852 | server.py:153 | FL finished in 171.19404133300122
INFO flwr 2024-04-26 17:44:56,852 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 17:44:56,853 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 17:44:56,853 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 17:44:56,853 | app.py:229 | app_fit: losses_centralized [(0, 2.302842617034912), (1, 2.2322754859924316), (2, 1.8239421844482422), (3, 1.6664124727249146), (4, 1.6111600399017334), (5, 1.5747712850570679), (6, 1.5489333868026733), (7, 1.545853853225708), (8, 1.5429942607879639), (9, 1.5464026927947998), (10, 1.5461044311523438)]
INFO flwr 2024-04-26 17:44:56,853 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0938), (1, 0.5909), (2, 0.6687), (3, 0.7958), (4, 0.8491), (5, 0.8863), (6, 0.9117), (7, 0.9148), (8, 0.9177), (9, 0.9147), (10, 0.915)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.915
wandb:     loss 1.5461
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_174144-2jxcwt7b
wandb: Find logs at: ./wandb/offline-run-20240426_174144-2jxcwt7b/logs
INFO flwr 2024-04-26 17:45:00,699 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 8
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 20
		Optimizer: FedAdam
			local: {'lr': 0.3}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: 2NN
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=200, bias=True)
			    (1): ReLU()
			    (2): Linear(in_features=200, out_features=200, bias=True)
			    (3): ReLU()
			    (4): Linear(in_features=200, out_features=200, bias=True)
			    (5): ReLU()
			    (6): Linear(in_features=200, out_features=10, bias=True)
			    (7): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 17:45:01,971 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=52241)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=52241)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 17:45:06,917	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 17:45:07,239	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 17:45:07,574	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 17:45:07,576	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 17:45:18,903 | app.py:213 | Flower VCE: Ray initialized with resources: {'object_store_memory': 75085350912.0, 'memory': 165199152128.0, 'accelerator_type:TITAN': 1.0, 'GPU': 1.0, 'CPU': 64.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0}
INFO flwr 2024-04-26 17:45:18,903 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 17:45:18,903 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 17:45:18,920 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 17:45:18,921 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 17:45:18,921 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 17:45:18,922 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 17:45:22,030 | server.py:94 | initial parameters (loss, other metrics): 2.302441120147705, {'accuracy': 0.1246, 'data_size': 10000}
INFO flwr 2024-04-26 17:45:22,031 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 17:45:22,031 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=57756)[0m 2024-04-26 17:45:25.211631: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=57756)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=57756)[0m 2024-04-26 17:45:27.676920: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=57761)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=57761)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=57761)[0m 2024-04-26 17:45:25.415158: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=57761)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=57766)[0m 2024-04-26 17:45:27.913476: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 17:45:51,686 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 17:45:53,234 | server.py:125 | fit progress: (1, 2.256650924682617, {'accuracy': 0.698, 'data_size': 10000}, 31.202918956001668)
INFO flwr 2024-04-26 17:45:53,234 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 17:45:53,234 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:46:08,696 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 17:46:10,235 | server.py:125 | fit progress: (2, 1.8038084506988525, {'accuracy': 0.7809, 'data_size': 10000}, 48.20433389699974)
INFO flwr 2024-04-26 17:46:10,235 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 17:46:10,236 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:46:23,221 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 17:46:24,789 | server.py:125 | fit progress: (3, 1.647857666015625, {'accuracy': 0.8174, 'data_size': 10000}, 62.7585097600022)
INFO flwr 2024-04-26 17:46:24,790 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 17:46:24,790 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:46:39,379 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 17:46:40,919 | server.py:125 | fit progress: (4, 1.6019333600997925, {'accuracy': 0.8586, 'data_size': 10000}, 78.88799523600028)
INFO flwr 2024-04-26 17:46:40,919 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 17:46:40,919 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:46:53,086 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 17:46:54,607 | server.py:125 | fit progress: (5, 1.5750038623809814, {'accuracy': 0.8855, 'data_size': 10000}, 92.57584196300013)
INFO flwr 2024-04-26 17:46:54,607 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 17:46:54,607 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:47:09,886 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 17:47:11,451 | server.py:125 | fit progress: (6, 1.5587170124053955, {'accuracy': 0.9017, 'data_size': 10000}, 109.42065827999977)
INFO flwr 2024-04-26 17:47:11,452 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 17:47:11,452 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:47:26,038 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 17:47:27,612 | server.py:125 | fit progress: (7, 1.5553141832351685, {'accuracy': 0.9057, 'data_size': 10000}, 125.58149233299991)
INFO flwr 2024-04-26 17:47:27,613 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 17:47:27,613 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:47:42,456 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 17:47:43,776 | server.py:125 | fit progress: (8, 1.5572408437728882, {'accuracy': 0.9033, 'data_size': 10000}, 141.745120339001)
INFO flwr 2024-04-26 17:47:43,776 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 17:47:43,776 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:47:58,491 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 17:48:00,056 | server.py:125 | fit progress: (9, 1.5559827089309692, {'accuracy': 0.9049, 'data_size': 10000}, 158.02526102100092)
INFO flwr 2024-04-26 17:48:00,056 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 17:48:00,057 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:48:13,326 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 17:48:14,845 | server.py:125 | fit progress: (10, 1.5589038133621216, {'accuracy': 0.902, 'data_size': 10000}, 172.81449269800214)
INFO flwr 2024-04-26 17:48:14,846 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 17:48:14,846 | server.py:153 | FL finished in 172.81505587900028
INFO flwr 2024-04-26 17:48:14,846 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 17:48:14,846 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 17:48:14,846 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 17:48:14,847 | app.py:229 | app_fit: losses_centralized [(0, 2.302441120147705), (1, 2.256650924682617), (2, 1.8038084506988525), (3, 1.647857666015625), (4, 1.6019333600997925), (5, 1.5750038623809814), (6, 1.5587170124053955), (7, 1.5553141832351685), (8, 1.5572408437728882), (9, 1.5559827089309692), (10, 1.5589038133621216)]
INFO flwr 2024-04-26 17:48:14,847 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.1246), (1, 0.698), (2, 0.7809), (3, 0.8174), (4, 0.8586), (5, 0.8855), (6, 0.9017), (7, 0.9057), (8, 0.9033), (9, 0.9049), (10, 0.902)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.902
wandb:     loss 1.5589
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_174501-wvcc4ghd
wandb: Find logs at: ./wandb/offline-run-20240426_174501-wvcc4ghd/logs
INFO flwr 2024-04-26 17:48:18,598 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 8
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 20
		Optimizer: FedAdam
			local: {'lr': 0.4}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: 2NN
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=200, bias=True)
			    (1): ReLU()
			    (2): Linear(in_features=200, out_features=200, bias=True)
			    (3): ReLU()
			    (4): Linear(in_features=200, out_features=200, bias=True)
			    (5): ReLU()
			    (6): Linear(in_features=200, out_features=10, bias=True)
			    (7): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 17:48:19,288 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=57759)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=57759)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 17:48:24,059	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 17:48:24,410	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 17:48:24,727	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 17:48:24,728	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 17:48:36,111 | app.py:213 | Flower VCE: Ray initialized with resources: {'object_store_memory': 75674946355.0, 'CPU': 64.0, 'node:__internal_head__': 1.0, 'node:10.20.240.12': 1.0, 'GPU': 1.0, 'accelerator_type:TITAN': 1.0, 'memory': 166574874829.0}
INFO flwr 2024-04-26 17:48:36,112 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 17:48:36,112 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 17:48:36,127 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 17:48:36,128 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 17:48:36,128 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 17:48:36,129 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 17:48:39,133 | server.py:94 | initial parameters (loss, other metrics): 2.3025121688842773, {'accuracy': 0.0851, 'data_size': 10000}
INFO flwr 2024-04-26 17:48:39,141 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 17:48:39,142 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=63929)[0m 2024-04-26 17:48:42.287514: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=63929)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=63929)[0m 2024-04-26 17:48:44.862125: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=63936)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=63936)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=63937)[0m 2024-04-26 17:48:42.774673: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=63937)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=63937)[0m 2024-04-26 17:48:45.116878: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 17:49:09,428 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 17:49:10,755 | server.py:125 | fit progress: (1, 2.2741518020629883, {'accuracy': 0.6762, 'data_size': 10000}, 31.612930040999345)
INFO flwr 2024-04-26 17:49:10,755 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 17:49:10,755 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:49:27,400 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 17:49:28,749 | server.py:125 | fit progress: (2, 1.9562458992004395, {'accuracy': 0.7794, 'data_size': 10000}, 49.607537732998026)
INFO flwr 2024-04-26 17:49:28,750 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 17:49:28,750 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:49:42,687 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 17:49:44,202 | server.py:125 | fit progress: (3, 1.6575331687927246, {'accuracy': 0.8213, 'data_size': 10000}, 65.06032405500082)
INFO flwr 2024-04-26 17:49:44,202 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 17:49:44,203 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:49:56,772 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 17:49:58,337 | server.py:125 | fit progress: (4, 1.6062465906143188, {'accuracy': 0.8553, 'data_size': 10000}, 79.1948175389989)
INFO flwr 2024-04-26 17:49:58,337 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 17:49:58,337 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:50:10,935 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 17:50:12,471 | server.py:125 | fit progress: (5, 1.5862873792648315, {'accuracy': 0.8744, 'data_size': 10000}, 93.32890843199857)
INFO flwr 2024-04-26 17:50:12,471 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 17:50:12,471 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:50:25,941 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 17:50:27,502 | server.py:125 | fit progress: (6, 1.5683449506759644, {'accuracy': 0.8923, 'data_size': 10000}, 108.3602148179998)
INFO flwr 2024-04-26 17:50:27,502 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 17:50:27,502 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:50:40,661 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 17:50:42,233 | server.py:125 | fit progress: (7, 1.5758416652679443, {'accuracy': 0.8848, 'data_size': 10000}, 123.09130777300015)
INFO flwr 2024-04-26 17:50:42,233 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 17:50:42,234 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:50:56,712 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 17:50:58,237 | server.py:125 | fit progress: (8, 1.5978888273239136, {'accuracy': 0.8634, 'data_size': 10000}, 139.09533342899886)
INFO flwr 2024-04-26 17:50:58,237 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 17:50:58,238 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:51:11,369 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 17:51:12,923 | server.py:125 | fit progress: (9, 1.5994664430618286, {'accuracy': 0.8616, 'data_size': 10000}, 153.78125600199928)
INFO flwr 2024-04-26 17:51:12,923 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 17:51:12,924 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:51:26,485 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 17:51:28,045 | server.py:125 | fit progress: (10, 1.594894528388977, {'accuracy': 0.8661, 'data_size': 10000}, 168.90356058899852)
INFO flwr 2024-04-26 17:51:28,046 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 17:51:28,046 | server.py:153 | FL finished in 168.90405392799948
INFO flwr 2024-04-26 17:51:28,046 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 17:51:28,046 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 17:51:28,046 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 17:51:28,046 | app.py:229 | app_fit: losses_centralized [(0, 2.3025121688842773), (1, 2.2741518020629883), (2, 1.9562458992004395), (3, 1.6575331687927246), (4, 1.6062465906143188), (5, 1.5862873792648315), (6, 1.5683449506759644), (7, 1.5758416652679443), (8, 1.5978888273239136), (9, 1.5994664430618286), (10, 1.594894528388977)]
INFO flwr 2024-04-26 17:51:28,047 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0851), (1, 0.6762), (2, 0.7794), (3, 0.8213), (4, 0.8553), (5, 0.8744), (6, 0.8923), (7, 0.8848), (8, 0.8634), (9, 0.8616), (10, 0.8661)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.8661
wandb:     loss 1.59489
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_174818-ywa560vv
wandb: Find logs at: ./wandb/offline-run-20240426_174818-ywa560vv/logs
INFO flwr 2024-04-26 17:51:31,628 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 8
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 50
		Optimizer: FedAdam
			local: {'lr': 0.25}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: 2NN
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=200, bias=True)
			    (1): ReLU()
			    (2): Linear(in_features=200, out_features=200, bias=True)
			    (3): ReLU()
			    (4): Linear(in_features=200, out_features=200, bias=True)
			    (5): ReLU()
			    (6): Linear(in_features=200, out_features=10, bias=True)
			    (7): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 17:51:32,362 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=63929)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=63929)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 17:51:37,269	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 17:51:37,583	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 17:51:37,896	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 17:51:37,898	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 17:51:49,287 | app.py:213 | Flower VCE: Ray initialized with resources: {'GPU': 1.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0, 'CPU': 64.0, 'accelerator_type:TITAN': 1.0, 'memory': 164584424448.0, 'object_store_memory': 74821896192.0}
INFO flwr 2024-04-26 17:51:49,287 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 17:51:49,287 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 17:51:49,303 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 17:51:49,304 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 17:51:49,305 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 17:51:49,305 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 17:51:51,997 | server.py:94 | initial parameters (loss, other metrics): 2.3025853633880615, {'accuracy': 0.0866, 'data_size': 10000}
INFO flwr 2024-04-26 17:51:51,997 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 17:51:51,998 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=67732)[0m 2024-04-26 17:51:55.560356: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=67732)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=67732)[0m 2024-04-26 17:51:57.890874: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=67733)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=67733)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=67733)[0m 2024-04-26 17:51:55.740508: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=67733)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=67733)[0m 2024-04-26 17:51:58.057241: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 17:52:33,757 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 17:52:35,123 | server.py:125 | fit progress: (1, 2.250096321105957, {'accuracy': 0.621, 'data_size': 10000}, 43.125942476999626)
INFO flwr 2024-04-26 17:52:35,124 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 17:52:35,124 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:53:04,519 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 17:53:06,123 | server.py:125 | fit progress: (2, 1.823575735092163, {'accuracy': 0.7156, 'data_size': 10000}, 74.12575485399793)
INFO flwr 2024-04-26 17:53:06,124 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 17:53:06,124 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:53:34,270 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 17:53:35,799 | server.py:125 | fit progress: (3, 1.6434252262115479, {'accuracy': 0.822, 'data_size': 10000}, 103.80122600499817)
INFO flwr 2024-04-26 17:53:35,799 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 17:53:35,799 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:54:01,784 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 17:54:03,381 | server.py:125 | fit progress: (4, 1.5716372728347778, {'accuracy': 0.8895, 'data_size': 10000}, 131.3838578399991)
INFO flwr 2024-04-26 17:54:03,382 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 17:54:03,382 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:54:29,422 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 17:54:30,972 | server.py:125 | fit progress: (5, 1.5543432235717773, {'accuracy': 0.9064, 'data_size': 10000}, 158.97411145399747)
INFO flwr 2024-04-26 17:54:30,972 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 17:54:30,972 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:54:58,185 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 17:54:59,527 | server.py:125 | fit progress: (6, 1.5577510595321655, {'accuracy': 0.9031, 'data_size': 10000}, 187.52965173899793)
INFO flwr 2024-04-26 17:54:59,527 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 17:54:59,528 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:55:23,722 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 17:55:25,263 | server.py:125 | fit progress: (7, 1.554893970489502, {'accuracy': 0.9061, 'data_size': 10000}, 213.2657445329969)
INFO flwr 2024-04-26 17:55:25,264 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 17:55:25,264 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:55:53,314 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 17:55:54,868 | server.py:125 | fit progress: (8, 1.548346757888794, {'accuracy': 0.9127, 'data_size': 10000}, 242.87046068199925)
INFO flwr 2024-04-26 17:55:54,868 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 17:55:54,869 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:56:21,124 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 17:56:22,726 | server.py:125 | fit progress: (9, 1.5567396879196167, {'accuracy': 0.9039, 'data_size': 10000}, 270.72797054499824)
INFO flwr 2024-04-26 17:56:22,726 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 17:56:22,726 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:56:48,481 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 17:56:50,052 | server.py:125 | fit progress: (10, 1.5557332038879395, {'accuracy': 0.9053, 'data_size': 10000}, 298.0545026309992)
INFO flwr 2024-04-26 17:56:50,052 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 17:56:50,053 | server.py:153 | FL finished in 298.0550702629989
INFO flwr 2024-04-26 17:56:50,053 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 17:56:50,053 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 17:56:50,053 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 17:56:50,053 | app.py:229 | app_fit: losses_centralized [(0, 2.3025853633880615), (1, 2.250096321105957), (2, 1.823575735092163), (3, 1.6434252262115479), (4, 1.5716372728347778), (5, 1.5543432235717773), (6, 1.5577510595321655), (7, 1.554893970489502), (8, 1.548346757888794), (9, 1.5567396879196167), (10, 1.5557332038879395)]
INFO flwr 2024-04-26 17:56:50,054 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0866), (1, 0.621), (2, 0.7156), (3, 0.822), (4, 0.8895), (5, 0.9064), (6, 0.9031), (7, 0.9061), (8, 0.9127), (9, 0.9039), (10, 0.9053)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.9053
wandb:     loss 1.55573
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_175131-xmthucmy
wandb: Find logs at: ./wandb/offline-run-20240426_175131-xmthucmy/logs
INFO flwr 2024-04-26 17:56:53,798 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 8
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 50
		Optimizer: FedAdam
			local: {'lr': 0.3}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: 2NN
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=200, bias=True)
			    (1): ReLU()
			    (2): Linear(in_features=200, out_features=200, bias=True)
			    (3): ReLU()
			    (4): Linear(in_features=200, out_features=200, bias=True)
			    (5): ReLU()
			    (6): Linear(in_features=200, out_features=10, bias=True)
			    (7): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 17:56:54,522 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=67728)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=67728)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 17:56:59,358	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 17:56:59,685	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 17:57:00,006	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 17:57:00,007	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 17:57:11,320 | app.py:213 | Flower VCE: Ray initialized with resources: {'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0, 'GPU': 1.0, 'accelerator_type:TITAN': 1.0, 'memory': 164648202445.0, 'CPU': 64.0, 'object_store_memory': 74849229619.0}
INFO flwr 2024-04-26 17:57:11,320 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 17:57:11,320 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 17:57:11,335 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 17:57:11,337 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 17:57:11,337 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 17:57:11,337 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 17:57:15,401 | server.py:94 | initial parameters (loss, other metrics): 2.3025784492492676, {'accuracy': 0.1135, 'data_size': 10000}
INFO flwr 2024-04-26 17:57:15,409 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 17:57:15,411 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=74582)[0m 2024-04-26 17:57:17.594694: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=74582)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=74584)[0m 2024-04-26 17:57:19.977777: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=74584)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=74584)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=74579)[0m 2024-04-26 17:57:17.793287: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=74579)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=74579)[0m 2024-04-26 17:57:20.166266: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 17:57:53,103 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 17:57:54,666 | server.py:125 | fit progress: (1, 2.259772539138794, {'accuracy': 0.7048, 'data_size': 10000}, 39.254885379999905)
INFO flwr 2024-04-26 17:57:54,666 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 17:57:54,667 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:58:20,673 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 17:58:22,264 | server.py:125 | fit progress: (2, 1.8598580360412598, {'accuracy': 0.768, 'data_size': 10000}, 66.85254591099874)
INFO flwr 2024-04-26 17:58:22,264 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 17:58:22,264 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:58:45,007 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 17:58:46,352 | server.py:125 | fit progress: (3, 1.6326497793197632, {'accuracy': 0.8399, 'data_size': 10000}, 90.94035125899973)
INFO flwr 2024-04-26 17:58:46,352 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 17:58:46,352 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:59:12,179 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 17:59:13,752 | server.py:125 | fit progress: (4, 1.5837877988815308, {'accuracy': 0.877, 'data_size': 10000}, 118.34071609999955)
INFO flwr 2024-04-26 17:59:13,752 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 17:59:13,752 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 17:59:38,579 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 17:59:40,138 | server.py:125 | fit progress: (5, 1.5639898777008057, {'accuracy': 0.8967, 'data_size': 10000}, 144.72659312799806)
INFO flwr 2024-04-26 17:59:40,138 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 17:59:40,138 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:00:04,212 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 18:00:05,800 | server.py:125 | fit progress: (6, 1.570623755455017, {'accuracy': 0.8908, 'data_size': 10000}, 170.3888113819994)
INFO flwr 2024-04-26 18:00:05,800 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 18:00:05,801 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:00:27,691 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 18:00:29,243 | server.py:125 | fit progress: (7, 1.5772446393966675, {'accuracy': 0.883, 'data_size': 10000}, 193.8315014109976)
INFO flwr 2024-04-26 18:00:29,243 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 18:00:29,243 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:00:58,380 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 18:00:59,993 | server.py:125 | fit progress: (8, 1.582222819328308, {'accuracy': 0.8791, 'data_size': 10000}, 224.58154280599774)
INFO flwr 2024-04-26 18:00:59,993 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 18:00:59,993 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:01:25,426 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 18:01:26,741 | server.py:125 | fit progress: (9, 1.5765154361724854, {'accuracy': 0.8842, 'data_size': 10000}, 251.3301597699974)
INFO flwr 2024-04-26 18:01:26,742 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 18:01:26,742 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:01:54,501 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 18:01:55,848 | server.py:125 | fit progress: (10, 1.5752274990081787, {'accuracy': 0.8859, 'data_size': 10000}, 280.43674891000046)
INFO flwr 2024-04-26 18:01:55,848 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 18:01:55,848 | server.py:153 | FL finished in 280.43724027400094
INFO flwr 2024-04-26 18:01:55,849 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 18:01:55,849 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 18:01:55,849 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 18:01:55,849 | app.py:229 | app_fit: losses_centralized [(0, 2.3025784492492676), (1, 2.259772539138794), (2, 1.8598580360412598), (3, 1.6326497793197632), (4, 1.5837877988815308), (5, 1.5639898777008057), (6, 1.570623755455017), (7, 1.5772446393966675), (8, 1.582222819328308), (9, 1.5765154361724854), (10, 1.5752274990081787)]
INFO flwr 2024-04-26 18:01:55,849 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.1135), (1, 0.7048), (2, 0.768), (3, 0.8399), (4, 0.877), (5, 0.8967), (6, 0.8908), (7, 0.883), (8, 0.8791), (9, 0.8842), (10, 0.8859)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.8859
wandb:     loss 1.57523
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_175654-uaclpdar
wandb: Find logs at: ./wandb/offline-run-20240426_175654-uaclpdar/logs
INFO flwr 2024-04-26 18:01:59,578 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 8
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 50
		Optimizer: FedAdam
			local: {'lr': 0.4}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: 2NN
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=200, bias=True)
			    (1): ReLU()
			    (2): Linear(in_features=200, out_features=200, bias=True)
			    (3): ReLU()
			    (4): Linear(in_features=200, out_features=200, bias=True)
			    (5): ReLU()
			    (6): Linear(in_features=200, out_features=10, bias=True)
			    (7): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 18:02:00,342 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=74578)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=74578)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 18:02:05,207	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 18:02:05,552	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 18:02:05,906	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 18:02:05,907	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 18:02:17,302 | app.py:213 | Flower VCE: Ray initialized with resources: {'GPU': 1.0, 'CPU': 64.0, 'object_store_memory': 74777581977.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0, 'accelerator_type:TITAN': 1.0, 'memory': 164481024615.0}
INFO flwr 2024-04-26 18:02:17,303 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 18:02:17,303 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 18:02:17,320 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 18:02:17,321 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 18:02:17,321 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 18:02:17,321 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 18:02:20,838 | server.py:94 | initial parameters (loss, other metrics): 2.3024845123291016, {'accuracy': 0.1249, 'data_size': 10000}
INFO flwr 2024-04-26 18:02:20,839 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 18:02:20,840 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=81439)[0m 2024-04-26 18:02:23.645057: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=81439)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=81439)[0m 2024-04-26 18:02:26.147885: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=81439)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=81439)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=81444)[0m 2024-04-26 18:02:23.849688: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=81444)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=81444)[0m 2024-04-26 18:02:26.292027: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 18:03:01,761 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 18:03:03,374 | server.py:125 | fit progress: (1, 2.2800710201263428, {'accuracy': 0.448, 'data_size': 10000}, 42.53508461599995)
INFO flwr 2024-04-26 18:03:03,375 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 18:03:03,375 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:03:31,632 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 18:03:33,191 | server.py:125 | fit progress: (2, 2.052962303161621, {'accuracy': 0.7165, 'data_size': 10000}, 72.35187478400258)
INFO flwr 2024-04-26 18:03:33,192 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 18:03:33,192 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:04:00,227 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 18:04:01,782 | server.py:125 | fit progress: (3, 1.7138739824295044, {'accuracy': 0.7997, 'data_size': 10000}, 100.94290035800077)
INFO flwr 2024-04-26 18:04:01,783 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 18:04:01,783 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:04:31,971 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 18:04:33,575 | server.py:125 | fit progress: (4, 1.6097850799560547, {'accuracy': 0.8579, 'data_size': 10000}, 132.73576220000177)
INFO flwr 2024-04-26 18:04:33,575 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 18:04:33,576 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:05:01,115 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 18:05:02,721 | server.py:125 | fit progress: (5, 1.5884915590286255, {'accuracy': 0.873, 'data_size': 10000}, 161.88179604800098)
INFO flwr 2024-04-26 18:05:02,721 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 18:05:02,722 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:05:32,006 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 18:05:33,352 | server.py:125 | fit progress: (6, 1.5966356992721558, {'accuracy': 0.864, 'data_size': 10000}, 192.5123747739999)
INFO flwr 2024-04-26 18:05:33,352 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 18:05:33,352 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:05:56,665 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 18:05:58,254 | server.py:125 | fit progress: (7, 1.603061318397522, {'accuracy': 0.8581, 'data_size': 10000}, 217.41504942600295)
INFO flwr 2024-04-26 18:05:58,255 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 18:05:58,255 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:06:22,338 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 18:06:23,878 | server.py:125 | fit progress: (8, 1.6065152883529663, {'accuracy': 0.8542, 'data_size': 10000}, 243.03884874600044)
INFO flwr 2024-04-26 18:06:23,879 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 18:06:23,879 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:06:50,460 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 18:06:52,081 | server.py:125 | fit progress: (9, 1.5999648571014404, {'accuracy': 0.8606, 'data_size': 10000}, 271.2412364970005)
INFO flwr 2024-04-26 18:06:52,081 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 18:06:52,081 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:07:18,649 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 18:07:20,233 | server.py:125 | fit progress: (10, 1.597653865814209, {'accuracy': 0.8634, 'data_size': 10000}, 299.39315678500134)
INFO flwr 2024-04-26 18:07:20,233 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 18:07:20,233 | server.py:153 | FL finished in 299.3936247720012
INFO flwr 2024-04-26 18:07:20,233 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 18:07:20,233 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 18:07:20,233 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 18:07:20,234 | app.py:229 | app_fit: losses_centralized [(0, 2.3024845123291016), (1, 2.2800710201263428), (2, 2.052962303161621), (3, 1.7138739824295044), (4, 1.6097850799560547), (5, 1.5884915590286255), (6, 1.5966356992721558), (7, 1.603061318397522), (8, 1.6065152883529663), (9, 1.5999648571014404), (10, 1.597653865814209)]
INFO flwr 2024-04-26 18:07:20,234 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.1249), (1, 0.448), (2, 0.7165), (3, 0.7997), (4, 0.8579), (5, 0.873), (6, 0.864), (7, 0.8581), (8, 0.8542), (9, 0.8606), (10, 0.8634)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.8634
wandb:     loss 1.59765
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_180159-ciwhzdsv
wandb: Find logs at: ./wandb/offline-run-20240426_180159-ciwhzdsv/logs
INFO flwr 2024-04-26 18:07:23,888 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 16
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 20
		Optimizer: FedAdam
			local: {'lr': 0.25}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: 2NN
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=200, bias=True)
			    (1): ReLU()
			    (2): Linear(in_features=200, out_features=200, bias=True)
			    (3): ReLU()
			    (4): Linear(in_features=200, out_features=200, bias=True)
			    (5): ReLU()
			    (6): Linear(in_features=200, out_features=10, bias=True)
			    (7): Softmax(dim=-1)
			  )
			)
Using the latest cached version of the dataset since mnist couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'mnist' at .cache/mnist/mnist/1.0.0/b06aab39e05f7bcd9635d18ed25d06eae523c574 (last modified on Tue Apr  2 18:09:57 2024).
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 18:14:36,986 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=81438)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=81438)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 18:14:41,525	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 18:14:41,838	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 18:14:42,168	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 18:14:42,170	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 18:14:53,700 | app.py:213 | Flower VCE: Ray initialized with resources: {'object_store_memory': 74698060185.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0, 'CPU': 64.0, 'GPU': 1.0, 'accelerator_type:TITAN': 1.0, 'memory': 164295473767.0}
INFO flwr 2024-04-26 18:14:53,700 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 18:14:53,700 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 18:14:53,716 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 18:14:53,717 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 18:14:53,717 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 18:14:53,717 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 18:14:56,727 | server.py:94 | initial parameters (loss, other metrics): 2.3026721477508545, {'accuracy': 0.0954, 'data_size': 10000}
INFO flwr 2024-04-26 18:14:56,727 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 18:14:56,727 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=93067)[0m 2024-04-26 18:15:00.055963: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=93067)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=93067)[0m 2024-04-26 18:15:02.426050: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=93072)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=93072)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=93073)[0m 2024-04-26 18:15:00.310846: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=93073)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=93073)[0m 2024-04-26 18:15:02.606052: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 18:15:21,647 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 18:15:22,976 | server.py:125 | fit progress: (1, 2.2072532176971436, {'accuracy': 0.4312, 'data_size': 10000}, 26.24856438599818)
INFO flwr 2024-04-26 18:15:22,976 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 18:15:22,976 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:15:36,353 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 18:15:37,697 | server.py:125 | fit progress: (2, 1.9209818840026855, {'accuracy': 0.5418, 'data_size': 10000}, 40.969494946999475)
INFO flwr 2024-04-26 18:15:37,697 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 18:15:37,697 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:15:48,981 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 18:15:50,319 | server.py:125 | fit progress: (3, 1.740438461303711, {'accuracy': 0.7144, 'data_size': 10000}, 53.59149409800011)
INFO flwr 2024-04-26 18:15:50,319 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 18:15:50,319 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:16:01,198 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 18:16:02,497 | server.py:125 | fit progress: (4, 1.6024283170700073, {'accuracy': 0.8582, 'data_size': 10000}, 65.76944518699747)
INFO flwr 2024-04-26 18:16:02,497 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 18:16:02,498 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:16:13,775 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 18:16:15,093 | server.py:125 | fit progress: (5, 1.560142993927002, {'accuracy': 0.9005, 'data_size': 10000}, 78.3653448039986)
INFO flwr 2024-04-26 18:16:15,093 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 18:16:15,093 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:16:25,438 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 18:16:26,763 | server.py:125 | fit progress: (6, 1.5459551811218262, {'accuracy': 0.9148, 'data_size': 10000}, 90.03588375400068)
INFO flwr 2024-04-26 18:16:26,763 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 18:16:26,764 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:16:37,486 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 18:16:39,028 | server.py:125 | fit progress: (7, 1.53776216506958, {'accuracy': 0.923, 'data_size': 10000}, 102.30072130299959)
INFO flwr 2024-04-26 18:16:39,028 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 18:16:39,028 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:16:49,558 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 18:16:51,083 | server.py:125 | fit progress: (8, 1.5321329832077026, {'accuracy': 0.9285, 'data_size': 10000}, 114.3555004109985)
INFO flwr 2024-04-26 18:16:51,084 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 18:16:51,084 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:17:02,878 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 18:17:04,431 | server.py:125 | fit progress: (9, 1.5309215784072876, {'accuracy': 0.9296, 'data_size': 10000}, 127.70380395199754)
INFO flwr 2024-04-26 18:17:04,431 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 18:17:04,432 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:17:15,644 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 18:17:17,162 | server.py:125 | fit progress: (10, 1.5348747968673706, {'accuracy': 0.9256, 'data_size': 10000}, 140.43479590700008)
INFO flwr 2024-04-26 18:17:17,162 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 18:17:17,162 | server.py:153 | FL finished in 140.43525214799956
INFO flwr 2024-04-26 18:17:17,163 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 18:17:17,163 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 18:17:17,163 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 18:17:17,163 | app.py:229 | app_fit: losses_centralized [(0, 2.3026721477508545), (1, 2.2072532176971436), (2, 1.9209818840026855), (3, 1.740438461303711), (4, 1.6024283170700073), (5, 1.560142993927002), (6, 1.5459551811218262), (7, 1.53776216506958), (8, 1.5321329832077026), (9, 1.5309215784072876), (10, 1.5348747968673706)]
INFO flwr 2024-04-26 18:17:17,163 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0954), (1, 0.4312), (2, 0.5418), (3, 0.7144), (4, 0.8582), (5, 0.9005), (6, 0.9148), (7, 0.923), (8, 0.9285), (9, 0.9296), (10, 0.9256)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.9256
wandb:     loss 1.53487
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_181436-10vfahfz
wandb: Find logs at: ./wandb/offline-run-20240426_181436-10vfahfz/logs
INFO flwr 2024-04-26 18:17:20,889 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 16
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 20
		Optimizer: FedAdam
			local: {'lr': 0.3}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: 2NN
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=200, bias=True)
			    (1): ReLU()
			    (2): Linear(in_features=200, out_features=200, bias=True)
			    (3): ReLU()
			    (4): Linear(in_features=200, out_features=200, bias=True)
			    (5): ReLU()
			    (6): Linear(in_features=200, out_features=10, bias=True)
			    (7): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 18:17:21,619 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=93062)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=93062)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 18:17:26,374	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 18:17:26,712	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 18:17:27,025	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 18:17:27,026	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 18:17:38,360 | app.py:213 | Flower VCE: Ray initialized with resources: {'GPU': 1.0, 'CPU': 64.0, 'accelerator_type:TITAN': 1.0, 'memory': 164531751117.0, 'object_store_memory': 74799321907.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0}
INFO flwr 2024-04-26 18:17:38,360 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 18:17:38,360 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 18:17:38,375 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 18:17:38,376 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 18:17:38,377 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 18:17:38,377 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 18:17:40,991 | server.py:94 | initial parameters (loss, other metrics): 2.30263352394104, {'accuracy': 0.1007, 'data_size': 10000}
INFO flwr 2024-04-26 18:17:40,991 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 18:17:40,992 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=99234)[0m 2024-04-26 18:17:44.664403: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=99234)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=99234)[0m 2024-04-26 18:17:47.037236: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=99231)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=99231)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=99228)[0m 2024-04-26 18:17:44.989745: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=99228)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=99228)[0m 2024-04-26 18:17:47.232785: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 18:18:06,683 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 18:18:08,035 | server.py:125 | fit progress: (1, 2.219021797180176, {'accuracy': 0.649, 'data_size': 10000}, 27.043252388000838)
INFO flwr 2024-04-26 18:18:08,035 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 18:18:08,035 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:18:19,018 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 18:18:20,553 | server.py:125 | fit progress: (2, 1.744370460510254, {'accuracy': 0.7717, 'data_size': 10000}, 39.561719072000415)
INFO flwr 2024-04-26 18:18:20,553 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 18:18:20,554 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:18:30,322 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 18:18:31,864 | server.py:125 | fit progress: (3, 1.5821253061294556, {'accuracy': 0.881, 'data_size': 10000}, 50.87261574200238)
INFO flwr 2024-04-26 18:18:31,864 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 18:18:31,865 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:18:42,620 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 18:18:44,170 | server.py:125 | fit progress: (4, 1.5577512979507446, {'accuracy': 0.9026, 'data_size': 10000}, 63.17887499100107)
INFO flwr 2024-04-26 18:18:44,171 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 18:18:44,171 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:18:55,589 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 18:18:57,201 | server.py:125 | fit progress: (5, 1.546579360961914, {'accuracy': 0.9145, 'data_size': 10000}, 76.20913923199987)
INFO flwr 2024-04-26 18:18:57,201 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 18:18:57,201 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:19:07,753 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 18:19:09,125 | server.py:125 | fit progress: (6, 1.5390087366104126, {'accuracy': 0.9211, 'data_size': 10000}, 88.13355888500155)
INFO flwr 2024-04-26 18:19:09,125 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 18:19:09,126 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:19:20,166 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 18:19:21,730 | server.py:125 | fit progress: (7, 1.530775785446167, {'accuracy': 0.9299, 'data_size': 10000}, 100.73829706500328)
INFO flwr 2024-04-26 18:19:21,730 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 18:19:21,730 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:19:32,978 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 18:19:34,551 | server.py:125 | fit progress: (8, 1.5258333683013916, {'accuracy': 0.9349, 'data_size': 10000}, 113.5600458150002)
INFO flwr 2024-04-26 18:19:34,552 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 18:19:34,552 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:19:45,226 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 18:19:46,788 | server.py:125 | fit progress: (9, 1.525047779083252, {'accuracy': 0.936, 'data_size': 10000}, 125.79692032300227)
INFO flwr 2024-04-26 18:19:46,789 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 18:19:46,789 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:19:58,520 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 18:20:00,097 | server.py:125 | fit progress: (10, 1.5256712436676025, {'accuracy': 0.9355, 'data_size': 10000}, 139.10516201200153)
INFO flwr 2024-04-26 18:20:00,097 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 18:20:00,097 | server.py:153 | FL finished in 139.10584183600076
INFO flwr 2024-04-26 18:20:00,097 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 18:20:00,098 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 18:20:00,098 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 18:20:00,098 | app.py:229 | app_fit: losses_centralized [(0, 2.30263352394104), (1, 2.219021797180176), (2, 1.744370460510254), (3, 1.5821253061294556), (4, 1.5577512979507446), (5, 1.546579360961914), (6, 1.5390087366104126), (7, 1.530775785446167), (8, 1.5258333683013916), (9, 1.525047779083252), (10, 1.5256712436676025)]
INFO flwr 2024-04-26 18:20:00,098 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.1007), (1, 0.649), (2, 0.7717), (3, 0.881), (4, 0.9026), (5, 0.9145), (6, 0.9211), (7, 0.9299), (8, 0.9349), (9, 0.936), (10, 0.9355)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.9355
wandb:     loss 1.52567
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_181721-uovh2835
wandb: Find logs at: ./wandb/offline-run-20240426_181721-uovh2835/logs
INFO flwr 2024-04-26 18:20:03,766 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 16
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 20
		Optimizer: FedAdam
			local: {'lr': 0.4}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: 2NN
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=200, bias=True)
			    (1): ReLU()
			    (2): Linear(in_features=200, out_features=200, bias=True)
			    (3): ReLU()
			    (4): Linear(in_features=200, out_features=200, bias=True)
			    (5): ReLU()
			    (6): Linear(in_features=200, out_features=10, bias=True)
			    (7): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 18:20:04,474 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=99226)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=99226)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 18:20:09,174	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 18:20:09,475	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 18:20:09,784	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 18:20:09,786	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 18:20:21,179 | app.py:213 | Flower VCE: Ray initialized with resources: {'CPU': 64.0, 'accelerator_type:TITAN': 1.0, 'memory': 164904375296.0, 'GPU': 1.0, 'object_store_memory': 74959017984.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0}
INFO flwr 2024-04-26 18:20:21,180 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 18:20:21,180 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 18:20:21,197 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 18:20:21,198 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 18:20:21,198 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 18:20:21,198 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 18:20:24,653 | server.py:94 | initial parameters (loss, other metrics): 2.3025307655334473, {'accuracy': 0.0974, 'data_size': 10000}
INFO flwr 2024-04-26 18:20:24,653 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 18:20:24,654 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=106032)[0m 2024-04-26 18:20:27.481370: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=106032)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=106025)[0m 2024-04-26 18:20:29.758571: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=106032)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=106032)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=106035)[0m 2024-04-26 18:20:27.663694: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=106035)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=106039)[0m 2024-04-26 18:20:30.150116: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 18:20:49,555 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 18:20:51,149 | server.py:125 | fit progress: (1, 2.203767776489258, {'accuracy': 0.6409, 'data_size': 10000}, 26.495085766000557)
INFO flwr 2024-04-26 18:20:51,149 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 18:20:51,149 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:21:03,167 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 18:21:04,521 | server.py:125 | fit progress: (2, 1.7853245735168457, {'accuracy': 0.7266, 'data_size': 10000}, 39.86702179799977)
INFO flwr 2024-04-26 18:21:04,521 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 18:21:04,521 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:21:15,942 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 18:21:17,254 | server.py:125 | fit progress: (3, 1.66845703125, {'accuracy': 0.793, 'data_size': 10000}, 52.60040138900149)
INFO flwr 2024-04-26 18:21:17,255 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 18:21:17,255 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:21:27,962 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 18:21:29,501 | server.py:125 | fit progress: (4, 1.6333433389663696, {'accuracy': 0.8267, 'data_size': 10000}, 64.84761391899883)
INFO flwr 2024-04-26 18:21:29,502 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 18:21:29,502 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:21:40,903 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 18:21:42,464 | server.py:125 | fit progress: (5, 1.6182645559310913, {'accuracy': 0.8416, 'data_size': 10000}, 77.8097241530013)
INFO flwr 2024-04-26 18:21:42,464 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 18:21:42,464 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:21:53,349 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 18:21:54,891 | server.py:125 | fit progress: (6, 1.5950770378112793, {'accuracy': 0.8658, 'data_size': 10000}, 90.23677699100153)
INFO flwr 2024-04-26 18:21:54,891 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 18:21:54,891 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:22:05,172 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 18:22:06,720 | server.py:125 | fit progress: (7, 1.573124885559082, {'accuracy': 0.8877, 'data_size': 10000}, 102.06617953499881)
INFO flwr 2024-04-26 18:22:06,720 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 18:22:06,721 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:22:16,993 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 18:22:18,592 | server.py:125 | fit progress: (8, 1.5521095991134644, {'accuracy': 0.909, 'data_size': 10000}, 113.93847638100124)
INFO flwr 2024-04-26 18:22:18,593 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 18:22:18,593 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:22:29,750 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 18:22:31,278 | server.py:125 | fit progress: (9, 1.5407350063323975, {'accuracy': 0.9201, 'data_size': 10000}, 126.62371446199904)
INFO flwr 2024-04-26 18:22:31,278 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 18:22:31,278 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:22:41,971 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 18:22:43,545 | server.py:125 | fit progress: (10, 1.5384585857391357, {'accuracy': 0.9227, 'data_size': 10000}, 138.8907573489996)
INFO flwr 2024-04-26 18:22:43,545 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 18:22:43,545 | server.py:153 | FL finished in 138.891221787002
INFO flwr 2024-04-26 18:22:43,545 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 18:22:43,545 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 18:22:43,546 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 18:22:43,546 | app.py:229 | app_fit: losses_centralized [(0, 2.3025307655334473), (1, 2.203767776489258), (2, 1.7853245735168457), (3, 1.66845703125), (4, 1.6333433389663696), (5, 1.6182645559310913), (6, 1.5950770378112793), (7, 1.573124885559082), (8, 1.5521095991134644), (9, 1.5407350063323975), (10, 1.5384585857391357)]
INFO flwr 2024-04-26 18:22:43,546 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0974), (1, 0.6409), (2, 0.7266), (3, 0.793), (4, 0.8267), (5, 0.8416), (6, 0.8658), (7, 0.8877), (8, 0.909), (9, 0.9201), (10, 0.9227)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.9227
wandb:     loss 1.53846
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_182004-t8w6bjfd
wandb: Find logs at: ./wandb/offline-run-20240426_182004-t8w6bjfd/logs
INFO flwr 2024-04-26 18:22:47,241 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 16
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 50
		Optimizer: FedAdam
			local: {'lr': 0.25}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: 2NN
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=200, bias=True)
			    (1): ReLU()
			    (2): Linear(in_features=200, out_features=200, bias=True)
			    (3): ReLU()
			    (4): Linear(in_features=200, out_features=200, bias=True)
			    (5): ReLU()
			    (6): Linear(in_features=200, out_features=10, bias=True)
			    (7): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 18:22:47,913 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=106025)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=106025)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 18:22:54,712	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 18:22:55,150	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 18:22:55,957	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 18:22:55,959	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 18:23:07,631 | app.py:213 | Flower VCE: Ray initialized with resources: {'GPU': 1.0, 'CPU': 64.0, 'object_store_memory': 76985366937.0, 'accelerator_type:TITAN': 1.0, 'memory': 169632522855.0, 'node:__internal_head__': 1.0, 'node:10.20.240.12': 1.0}
INFO flwr 2024-04-26 18:23:07,631 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 18:23:07,631 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 18:23:07,646 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 18:23:07,647 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 18:23:07,648 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 18:23:07,648 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 18:23:10,441 | server.py:94 | initial parameters (loss, other metrics): 2.3024537563323975, {'accuracy': 0.1429, 'data_size': 10000}
INFO flwr 2024-04-26 18:23:10,441 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 18:23:10,442 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=111953)[0m 2024-04-26 18:23:14.063451: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=111953)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=111948)[0m 2024-04-26 18:23:16.515769: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=111953)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=111953)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=111946)[0m 2024-04-26 18:23:14.482479: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=111946)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=111946)[0m 2024-04-26 18:23:17.059029: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 18:23:42,753 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 18:23:44,115 | server.py:125 | fit progress: (1, 2.203463554382324, {'accuracy': 0.5351, 'data_size': 10000}, 33.673476934000064)
INFO flwr 2024-04-26 18:23:44,115 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 18:23:44,116 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:24:00,043 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 18:24:01,577 | server.py:125 | fit progress: (2, 1.833814024925232, {'accuracy': 0.635, 'data_size': 10000}, 51.135878193999815)
INFO flwr 2024-04-26 18:24:01,578 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 18:24:01,578 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:24:16,380 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 18:24:17,947 | server.py:125 | fit progress: (3, 1.662702202796936, {'accuracy': 0.7981, 'data_size': 10000}, 67.50517486399986)
INFO flwr 2024-04-26 18:24:17,947 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 18:24:17,947 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:24:33,574 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 18:24:35,176 | server.py:125 | fit progress: (4, 1.5864427089691162, {'accuracy': 0.8746, 'data_size': 10000}, 84.73423500399804)
INFO flwr 2024-04-26 18:24:35,176 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 18:24:35,176 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:24:52,291 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 18:24:53,810 | server.py:125 | fit progress: (5, 1.5567189455032349, {'accuracy': 0.9042, 'data_size': 10000}, 103.36813476999669)
INFO flwr 2024-04-26 18:24:53,810 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 18:24:53,810 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:25:09,388 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 18:25:10,762 | server.py:125 | fit progress: (6, 1.5454039573669434, {'accuracy': 0.9149, 'data_size': 10000}, 120.32005166399904)
INFO flwr 2024-04-26 18:25:10,762 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 18:25:10,762 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:25:25,571 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 18:25:26,921 | server.py:125 | fit progress: (7, 1.5346362590789795, {'accuracy': 0.9264, 'data_size': 10000}, 136.4798335380001)
INFO flwr 2024-04-26 18:25:26,922 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 18:25:26,922 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:25:42,644 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 18:25:43,981 | server.py:125 | fit progress: (8, 1.5270718336105347, {'accuracy': 0.9341, 'data_size': 10000}, 153.53947857399908)
INFO flwr 2024-04-26 18:25:43,981 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 18:25:43,982 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:26:01,080 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 18:26:02,636 | server.py:125 | fit progress: (9, 1.5255035161972046, {'accuracy': 0.9355, 'data_size': 10000}, 172.19395773299766)
INFO flwr 2024-04-26 18:26:02,636 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 18:26:02,636 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:26:18,543 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 18:26:20,083 | server.py:125 | fit progress: (10, 1.5236672163009644, {'accuracy': 0.9374, 'data_size': 10000}, 189.6411915639983)
INFO flwr 2024-04-26 18:26:20,083 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 18:26:20,083 | server.py:153 | FL finished in 189.64163414699942
INFO flwr 2024-04-26 18:26:20,083 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 18:26:20,083 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 18:26:20,084 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 18:26:20,084 | app.py:229 | app_fit: losses_centralized [(0, 2.3024537563323975), (1, 2.203463554382324), (2, 1.833814024925232), (3, 1.662702202796936), (4, 1.5864427089691162), (5, 1.5567189455032349), (6, 1.5454039573669434), (7, 1.5346362590789795), (8, 1.5270718336105347), (9, 1.5255035161972046), (10, 1.5236672163009644)]
INFO flwr 2024-04-26 18:26:20,084 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.1429), (1, 0.5351), (2, 0.635), (3, 0.7981), (4, 0.8746), (5, 0.9042), (6, 0.9149), (7, 0.9264), (8, 0.9341), (9, 0.9355), (10, 0.9374)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.9374
wandb:     loss 1.52367
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_182247-f14qofna
wandb: Find logs at: ./wandb/offline-run-20240426_182247-f14qofna/logs
INFO flwr 2024-04-26 18:26:23,845 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 16
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 50
		Optimizer: FedAdam
			local: {'lr': 0.3}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: 2NN
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=200, bias=True)
			    (1): ReLU()
			    (2): Linear(in_features=200, out_features=200, bias=True)
			    (3): ReLU()
			    (4): Linear(in_features=200, out_features=200, bias=True)
			    (5): ReLU()
			    (6): Linear(in_features=200, out_features=10, bias=True)
			    (7): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 18:26:24,500 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=111944)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=111944)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 18:26:29,472	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 18:26:29,931	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 18:26:30,303	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 18:26:30,305	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 18:26:42,447 | app.py:213 | Flower VCE: Ray initialized with resources: {'CPU': 64.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0, 'GPU': 1.0, 'object_store_memory': 76748967936.0, 'accelerator_type:TITAN': 1.0, 'memory': 169080925184.0}
INFO flwr 2024-04-26 18:26:42,448 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 18:26:42,448 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 18:26:42,463 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 18:26:42,464 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 18:26:42,464 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 18:26:42,465 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 18:26:45,175 | server.py:94 | initial parameters (loss, other metrics): 2.3025310039520264, {'accuracy': 0.1006, 'data_size': 10000}
INFO flwr 2024-04-26 18:26:45,176 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 18:26:45,178 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=116358)[0m 2024-04-26 18:26:49.324097: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=116358)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=116358)[0m 2024-04-26 18:26:51.711847: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=116358)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=116358)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=116363)[0m 2024-04-26 18:26:49.371014: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=116363)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=116367)[0m 2024-04-26 18:26:51.701999: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 18:27:16,190 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 18:27:17,523 | server.py:125 | fit progress: (1, 2.200591802597046, {'accuracy': 0.6008, 'data_size': 10000}, 32.34585642800084)
INFO flwr 2024-04-26 18:27:17,524 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 18:27:17,524 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:27:33,412 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 18:27:34,979 | server.py:125 | fit progress: (2, 1.7614498138427734, {'accuracy': 0.7128, 'data_size': 10000}, 49.801525708000554)
INFO flwr 2024-04-26 18:27:34,979 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 18:27:34,980 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:27:50,757 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 18:27:52,318 | server.py:125 | fit progress: (3, 1.6975226402282715, {'accuracy': 0.7611, 'data_size': 10000}, 67.14009743399947)
INFO flwr 2024-04-26 18:27:52,318 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 18:27:52,318 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:28:07,982 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 18:28:09,544 | server.py:125 | fit progress: (4, 1.653388500213623, {'accuracy': 0.8069, 'data_size': 10000}, 84.36628362199917)
INFO flwr 2024-04-26 18:28:09,544 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 18:28:09,544 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:28:24,150 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 18:28:25,771 | server.py:125 | fit progress: (5, 1.6027876138687134, {'accuracy': 0.8579, 'data_size': 10000}, 100.5930709839995)
INFO flwr 2024-04-26 18:28:25,771 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 18:28:25,771 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:28:40,019 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 18:28:41,618 | server.py:125 | fit progress: (6, 1.5527540445327759, {'accuracy': 0.9078, 'data_size': 10000}, 116.44048021499839)
INFO flwr 2024-04-26 18:28:41,618 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 18:28:41,619 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:28:56,834 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 18:28:58,141 | server.py:125 | fit progress: (7, 1.544373631477356, {'accuracy': 0.9165, 'data_size': 10000}, 132.96367952500077)
INFO flwr 2024-04-26 18:28:58,141 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 18:28:58,142 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:29:13,306 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 18:29:14,906 | server.py:125 | fit progress: (8, 1.5413799285888672, {'accuracy': 0.9197, 'data_size': 10000}, 149.72900404399843)
INFO flwr 2024-04-26 18:29:14,907 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 18:29:14,907 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:29:30,352 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 18:29:31,966 | server.py:125 | fit progress: (9, 1.535447359085083, {'accuracy': 0.9256, 'data_size': 10000}, 166.78906463900057)
INFO flwr 2024-04-26 18:29:31,967 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 18:29:31,967 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:29:48,028 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 18:29:49,574 | server.py:125 | fit progress: (10, 1.5307271480560303, {'accuracy': 0.9299, 'data_size': 10000}, 184.397046064998)
INFO flwr 2024-04-26 18:29:49,575 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 18:29:49,575 | server.py:153 | FL finished in 184.39751338899805
INFO flwr 2024-04-26 18:29:49,575 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 18:29:49,575 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 18:29:49,575 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 18:29:49,576 | app.py:229 | app_fit: losses_centralized [(0, 2.3025310039520264), (1, 2.200591802597046), (2, 1.7614498138427734), (3, 1.6975226402282715), (4, 1.653388500213623), (5, 1.6027876138687134), (6, 1.5527540445327759), (7, 1.544373631477356), (8, 1.5413799285888672), (9, 1.535447359085083), (10, 1.5307271480560303)]
INFO flwr 2024-04-26 18:29:49,576 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.1006), (1, 0.6008), (2, 0.7128), (3, 0.7611), (4, 0.8069), (5, 0.8579), (6, 0.9078), (7, 0.9165), (8, 0.9197), (9, 0.9256), (10, 0.9299)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.9299
wandb:     loss 1.53073
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_182624-znxwew77
wandb: Find logs at: ./wandb/offline-run-20240426_182624-znxwew77/logs
INFO flwr 2024-04-26 18:29:53,480 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 16
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 50
		Optimizer: FedAdam
			local: {'lr': 0.4}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: 2NN
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=200, bias=True)
			    (1): ReLU()
			    (2): Linear(in_features=200, out_features=200, bias=True)
			    (3): ReLU()
			    (4): Linear(in_features=200, out_features=200, bias=True)
			    (5): ReLU()
			    (6): Linear(in_features=200, out_features=10, bias=True)
			    (7): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 18:29:54,844 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=116364)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=116364)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 18:29:59,750	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 18:30:00,109	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 18:30:00,557	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 18:30:00,559	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 18:30:11,854 | app.py:213 | Flower VCE: Ray initialized with resources: {'GPU': 1.0, 'CPU': 64.0, 'accelerator_type:TITAN': 1.0, 'memory': 164073526682.0, 'node:__internal_head__': 1.0, 'node:10.20.240.12': 1.0, 'object_store_memory': 74602940006.0}
INFO flwr 2024-04-26 18:30:11,854 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 18:30:11,854 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 18:30:11,870 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 18:30:11,871 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 18:30:11,871 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 18:30:11,871 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 18:30:15,688 | server.py:94 | initial parameters (loss, other metrics): 2.302619457244873, {'accuracy': 0.1031, 'data_size': 10000}
INFO flwr 2024-04-26 18:30:15,689 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 18:30:15,689 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=122887)[0m 2024-04-26 18:30:18.320176: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=122887)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=122878)[0m 2024-04-26 18:30:23.494797: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(pid=122886)[0m 2024-04-26 18:30:18.614812: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=122886)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=122878)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=122878)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=122874)[0m 2024-04-26 18:30:23.496793: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 18:30:53,552 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 18:30:55,105 | server.py:125 | fit progress: (1, 2.233347177505493, {'accuracy': 0.5949, 'data_size': 10000}, 39.415892721001)
INFO flwr 2024-04-26 18:30:55,105 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 18:30:55,105 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:31:12,524 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 18:31:13,868 | server.py:125 | fit progress: (2, 1.8358906507492065, {'accuracy': 0.7346, 'data_size': 10000}, 58.178699123000115)
INFO flwr 2024-04-26 18:31:13,868 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 18:31:13,868 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:31:31,637 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 18:31:33,194 | server.py:125 | fit progress: (3, 1.6109715700149536, {'accuracy': 0.8567, 'data_size': 10000}, 77.50473798199891)
INFO flwr 2024-04-26 18:31:33,194 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 18:31:33,194 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:31:48,353 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 18:31:49,922 | server.py:125 | fit progress: (4, 1.5633143186569214, {'accuracy': 0.8978, 'data_size': 10000}, 94.23319828799868)
INFO flwr 2024-04-26 18:31:49,923 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 18:31:49,923 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:32:05,177 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 18:32:06,722 | server.py:125 | fit progress: (5, 1.5507134199142456, {'accuracy': 0.91, 'data_size': 10000}, 111.0330699949991)
INFO flwr 2024-04-26 18:32:06,722 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 18:32:06,723 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:32:21,284 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 18:32:22,813 | server.py:125 | fit progress: (6, 1.5423266887664795, {'accuracy': 0.9183, 'data_size': 10000}, 127.12352270399788)
INFO flwr 2024-04-26 18:32:22,813 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 18:32:22,813 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:32:39,719 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 18:32:41,107 | server.py:125 | fit progress: (7, 1.5366098880767822, {'accuracy': 0.9242, 'data_size': 10000}, 145.41804418099855)
INFO flwr 2024-04-26 18:32:41,107 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 18:32:41,108 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:32:57,341 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 18:32:58,655 | server.py:125 | fit progress: (8, 1.5360568761825562, {'accuracy': 0.925, 'data_size': 10000}, 162.96557915700032)
INFO flwr 2024-04-26 18:32:58,655 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 18:32:58,655 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:33:15,333 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 18:33:16,714 | server.py:125 | fit progress: (9, 1.5339992046356201, {'accuracy': 0.9273, 'data_size': 10000}, 181.02463979899767)
INFO flwr 2024-04-26 18:33:16,714 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 18:33:16,714 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:33:32,372 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 18:33:33,977 | server.py:125 | fit progress: (10, 1.5374140739440918, {'accuracy': 0.9235, 'data_size': 10000}, 198.28809615099817)
INFO flwr 2024-04-26 18:33:33,977 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 18:33:33,978 | server.py:153 | FL finished in 198.28854560299806
INFO flwr 2024-04-26 18:33:33,978 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 18:33:33,978 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 18:33:33,978 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 18:33:33,978 | app.py:229 | app_fit: losses_centralized [(0, 2.302619457244873), (1, 2.233347177505493), (2, 1.8358906507492065), (3, 1.6109715700149536), (4, 1.5633143186569214), (5, 1.5507134199142456), (6, 1.5423266887664795), (7, 1.5366098880767822), (8, 1.5360568761825562), (9, 1.5339992046356201), (10, 1.5374140739440918)]
INFO flwr 2024-04-26 18:33:33,978 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.1031), (1, 0.5949), (2, 0.7346), (3, 0.8567), (4, 0.8978), (5, 0.91), (6, 0.9183), (7, 0.9242), (8, 0.925), (9, 0.9273), (10, 0.9235)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.9235
wandb:     loss 1.53741
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_182953-h2a0mvpn
wandb: Find logs at: ./wandb/offline-run-20240426_182953-h2a0mvpn/logs
INFO flwr 2024-04-26 18:33:37,721 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 32
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 20
		Optimizer: FedAdam
			local: {'lr': 0.25}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: 2NN
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=200, bias=True)
			    (1): ReLU()
			    (2): Linear(in_features=200, out_features=200, bias=True)
			    (3): ReLU()
			    (4): Linear(in_features=200, out_features=200, bias=True)
			    (5): ReLU()
			    (6): Linear(in_features=200, out_features=10, bias=True)
			    (7): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 18:33:38,711 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=122874)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=122874)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 18:33:44,514	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 18:33:44,893	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 18:33:45,340	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 18:33:45,342	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 18:33:56,843 | app.py:213 | Flower VCE: Ray initialized with resources: {'CPU': 64.0, 'GPU': 1.0, 'accelerator_type:TITAN': 1.0, 'memory': 163988310631.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0, 'object_store_memory': 74566418841.0}
INFO flwr 2024-04-26 18:33:56,844 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 18:33:56,844 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 18:33:56,862 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 18:33:56,863 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 18:33:56,864 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 18:33:56,864 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 18:34:00,091 | server.py:94 | initial parameters (loss, other metrics): 2.3024065494537354, {'accuracy': 0.0982, 'data_size': 10000}
INFO flwr 2024-04-26 18:34:00,091 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 18:34:00,092 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=129361)[0m 2024-04-26 18:34:06.332148: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=129361)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=129361)[0m 2024-04-26 18:34:08.840702: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=129361)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=129361)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=129363)[0m 2024-04-26 18:34:06.686000: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=129363)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=129363)[0m 2024-04-26 18:34:09.022169: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 18:34:27,438 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 18:34:29,020 | server.py:125 | fit progress: (1, 2.1715869903564453, {'accuracy': 0.5437, 'data_size': 10000}, 28.928050124002766)
INFO flwr 2024-04-26 18:34:29,020 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 18:34:29,020 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:34:39,011 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 18:34:40,306 | server.py:125 | fit progress: (2, 1.8749552965164185, {'accuracy': 0.5835, 'data_size': 10000}, 40.21448611100277)
INFO flwr 2024-04-26 18:34:40,306 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 18:34:40,306 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:34:49,619 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 18:34:51,141 | server.py:125 | fit progress: (3, 1.662943720817566, {'accuracy': 0.8003, 'data_size': 10000}, 51.04938496500108)
INFO flwr 2024-04-26 18:34:51,141 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 18:34:51,141 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:34:59,835 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 18:35:01,379 | server.py:125 | fit progress: (4, 1.630557894706726, {'accuracy': 0.8301, 'data_size': 10000}, 61.28783925600146)
INFO flwr 2024-04-26 18:35:01,380 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 18:35:01,380 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:35:10,034 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 18:35:11,552 | server.py:125 | fit progress: (5, 1.5736702680587769, {'accuracy': 0.8867, 'data_size': 10000}, 71.46013417100039)
INFO flwr 2024-04-26 18:35:11,552 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 18:35:11,552 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:35:20,860 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 18:35:22,378 | server.py:125 | fit progress: (6, 1.5612512826919556, {'accuracy': 0.8995, 'data_size': 10000}, 82.28613536500052)
INFO flwr 2024-04-26 18:35:22,378 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 18:35:22,378 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:35:31,142 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 18:35:32,656 | server.py:125 | fit progress: (7, 1.5558418035507202, {'accuracy': 0.9049, 'data_size': 10000}, 92.56409497000277)
INFO flwr 2024-04-26 18:35:32,656 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 18:35:32,656 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:35:41,653 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 18:35:43,216 | server.py:125 | fit progress: (8, 1.5414150953292847, {'accuracy': 0.9195, 'data_size': 10000}, 103.1242115519999)
INFO flwr 2024-04-26 18:35:43,216 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 18:35:43,216 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:35:52,187 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 18:35:53,700 | server.py:125 | fit progress: (9, 1.5353989601135254, {'accuracy': 0.9258, 'data_size': 10000}, 113.60812653000175)
INFO flwr 2024-04-26 18:35:53,700 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 18:35:53,700 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:36:02,886 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 18:36:04,200 | server.py:125 | fit progress: (10, 1.5394024848937988, {'accuracy': 0.9215, 'data_size': 10000}, 124.10846924699945)
INFO flwr 2024-04-26 18:36:04,200 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 18:36:04,200 | server.py:153 | FL finished in 124.10898460400131
INFO flwr 2024-04-26 18:36:04,201 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 18:36:04,201 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 18:36:04,201 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 18:36:04,201 | app.py:229 | app_fit: losses_centralized [(0, 2.3024065494537354), (1, 2.1715869903564453), (2, 1.8749552965164185), (3, 1.662943720817566), (4, 1.630557894706726), (5, 1.5736702680587769), (6, 1.5612512826919556), (7, 1.5558418035507202), (8, 1.5414150953292847), (9, 1.5353989601135254), (10, 1.5394024848937988)]
INFO flwr 2024-04-26 18:36:04,219 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0982), (1, 0.5437), (2, 0.5835), (3, 0.8003), (4, 0.8301), (5, 0.8867), (6, 0.8995), (7, 0.9049), (8, 0.9195), (9, 0.9258), (10, 0.9215)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.9215
wandb:     loss 1.5394
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_183338-vdu3cnvh
wandb: Find logs at: ./wandb/offline-run-20240426_183338-vdu3cnvh/logs
INFO flwr 2024-04-26 18:36:07,930 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 32
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 20
		Optimizer: FedAdam
			local: {'lr': 0.3}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: 2NN
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=200, bias=True)
			    (1): ReLU()
			    (2): Linear(in_features=200, out_features=200, bias=True)
			    (3): ReLU()
			    (4): Linear(in_features=200, out_features=200, bias=True)
			    (5): ReLU()
			    (6): Linear(in_features=200, out_features=10, bias=True)
			    (7): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 18:36:08,723 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=129363)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=129363)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 18:36:13,551	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 18:36:13,896	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 18:36:14,211	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 18:36:14,213	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 18:36:25,566 | app.py:213 | Flower VCE: Ray initialized with resources: {'object_store_memory': 74527355289.0, 'CPU': 64.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0, 'accelerator_type:TITAN': 1.0, 'memory': 163897162343.0, 'GPU': 1.0}
INFO flwr 2024-04-26 18:36:25,566 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 18:36:25,566 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 18:36:25,582 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 18:36:25,583 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 18:36:25,583 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 18:36:25,583 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 18:36:28,959 | server.py:94 | initial parameters (loss, other metrics): 2.302610397338867, {'accuracy': 0.0977, 'data_size': 10000}
INFO flwr 2024-04-26 18:36:28,959 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 18:36:28,959 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=135843)[0m 2024-04-26 18:36:32.012950: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=135843)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=135843)[0m 2024-04-26 18:36:34.354879: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=135843)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=135843)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=135842)[0m 2024-04-26 18:36:32.242364: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=135842)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=135842)[0m 2024-04-26 18:36:34.493819: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 18:36:51,170 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 18:36:52,729 | server.py:125 | fit progress: (1, 2.1746885776519775, {'accuracy': 0.6257, 'data_size': 10000}, 23.76977351199821)
INFO flwr 2024-04-26 18:36:52,729 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 18:36:52,729 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:37:02,824 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 18:37:04,388 | server.py:125 | fit progress: (2, 1.740963339805603, {'accuracy': 0.7324, 'data_size': 10000}, 35.428960306999215)
INFO flwr 2024-04-26 18:37:04,388 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 18:37:04,389 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:37:13,388 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 18:37:14,896 | server.py:125 | fit progress: (3, 1.6934255361557007, {'accuracy': 0.7669, 'data_size': 10000}, 45.93689725399963)
INFO flwr 2024-04-26 18:37:14,896 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 18:37:14,897 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:37:23,636 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 18:37:25,196 | server.py:125 | fit progress: (4, 1.6377514600753784, {'accuracy': 0.8219, 'data_size': 10000}, 56.237296303999756)
INFO flwr 2024-04-26 18:37:25,197 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 18:37:25,197 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:37:34,239 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 18:37:35,822 | server.py:125 | fit progress: (5, 1.5806503295898438, {'accuracy': 0.8798, 'data_size': 10000}, 66.86319942000046)
INFO flwr 2024-04-26 18:37:35,823 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 18:37:35,823 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:37:45,119 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 18:37:46,412 | server.py:125 | fit progress: (6, 1.551601767539978, {'accuracy': 0.909, 'data_size': 10000}, 77.45322489200043)
INFO flwr 2024-04-26 18:37:46,413 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 18:37:46,413 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:37:55,367 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 18:37:56,880 | server.py:125 | fit progress: (7, 1.543012261390686, {'accuracy': 0.918, 'data_size': 10000}, 87.92102101400087)
INFO flwr 2024-04-26 18:37:56,880 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 18:37:56,881 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:38:05,769 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 18:38:07,361 | server.py:125 | fit progress: (8, 1.53682279586792, {'accuracy': 0.9242, 'data_size': 10000}, 98.40209137999773)
INFO flwr 2024-04-26 18:38:07,362 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 18:38:07,362 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:38:16,396 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 18:38:17,938 | server.py:125 | fit progress: (9, 1.5322141647338867, {'accuracy': 0.9283, 'data_size': 10000}, 108.97895419199995)
INFO flwr 2024-04-26 18:38:17,938 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 18:38:17,939 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:38:27,083 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 18:38:28,596 | server.py:125 | fit progress: (10, 1.529611349105835, {'accuracy': 0.9315, 'data_size': 10000}, 119.63725159800015)
INFO flwr 2024-04-26 18:38:28,597 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 18:38:28,597 | server.py:153 | FL finished in 119.6377458729985
INFO flwr 2024-04-26 18:38:28,597 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 18:38:28,597 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 18:38:28,597 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 18:38:28,598 | app.py:229 | app_fit: losses_centralized [(0, 2.302610397338867), (1, 2.1746885776519775), (2, 1.740963339805603), (3, 1.6934255361557007), (4, 1.6377514600753784), (5, 1.5806503295898438), (6, 1.551601767539978), (7, 1.543012261390686), (8, 1.53682279586792), (9, 1.5322141647338867), (10, 1.529611349105835)]
INFO flwr 2024-04-26 18:38:28,598 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0977), (1, 0.6257), (2, 0.7324), (3, 0.7669), (4, 0.8219), (5, 0.8798), (6, 0.909), (7, 0.918), (8, 0.9242), (9, 0.9283), (10, 0.9315)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.9315
wandb:     loss 1.52961
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_183608-grt6bomd
wandb: Find logs at: ./wandb/offline-run-20240426_183608-grt6bomd/logs
INFO flwr 2024-04-26 18:38:32,341 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 32
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 20
		Optimizer: FedAdam
			local: {'lr': 0.4}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: 2NN
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=200, bias=True)
			    (1): ReLU()
			    (2): Linear(in_features=200, out_features=200, bias=True)
			    (3): ReLU()
			    (4): Linear(in_features=200, out_features=200, bias=True)
			    (5): ReLU()
			    (6): Linear(in_features=200, out_features=10, bias=True)
			    (7): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 18:38:33,173 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=135833)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=135833)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 18:38:37,825	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 18:38:38,139	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 18:38:38,465	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 18:38:38,467	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 18:38:49,868 | app.py:213 | Flower VCE: Ray initialized with resources: {'CPU': 64.0, 'GPU': 1.0, 'object_store_memory': 74659614720.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0, 'memory': 164205767680.0, 'accelerator_type:TITAN': 1.0}
INFO flwr 2024-04-26 18:38:49,869 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 18:38:49,869 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 18:38:49,884 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 18:38:49,885 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 18:38:49,886 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 18:38:49,886 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 18:38:53,284 | server.py:94 | initial parameters (loss, other metrics): 2.302450656890869, {'accuracy': 0.1029, 'data_size': 10000}
INFO flwr 2024-04-26 18:38:53,284 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 18:38:53,284 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=141993)[0m 2024-04-26 18:38:56.160986: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=141993)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=141993)[0m 2024-04-26 18:38:58.618643: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=141992)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=141992)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=141983)[0m 2024-04-26 18:38:56.318424: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=141983)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=141983)[0m 2024-04-26 18:38:58.861356: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 18:39:16,307 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 18:39:17,657 | server.py:125 | fit progress: (1, 2.2097561359405518, {'accuracy': 0.5699, 'data_size': 10000}, 24.373048388002644)
INFO flwr 2024-04-26 18:39:17,658 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 18:39:17,658 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:39:27,318 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 18:39:28,680 | server.py:125 | fit progress: (2, 1.7648711204528809, {'accuracy': 0.7566, 'data_size': 10000}, 35.39581779500077)
INFO flwr 2024-04-26 18:39:28,680 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 18:39:28,681 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:39:37,892 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 18:39:39,243 | server.py:125 | fit progress: (3, 1.6961052417755127, {'accuracy': 0.7603, 'data_size': 10000}, 45.95897503800006)
INFO flwr 2024-04-26 18:39:39,244 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 18:39:39,244 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:39:49,003 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 18:39:50,342 | server.py:125 | fit progress: (4, 1.6457535028457642, {'accuracy': 0.8126, 'data_size': 10000}, 57.057572624002205)
INFO flwr 2024-04-26 18:39:50,342 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 18:39:50,342 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:40:00,033 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 18:40:01,371 | server.py:125 | fit progress: (5, 1.5737277269363403, {'accuracy': 0.8874, 'data_size': 10000}, 68.08614092100106)
INFO flwr 2024-04-26 18:40:01,371 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 18:40:01,371 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:40:10,710 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 18:40:12,016 | server.py:125 | fit progress: (6, 1.534846305847168, {'accuracy': 0.9268, 'data_size': 10000}, 78.73145451800156)
INFO flwr 2024-04-26 18:40:12,016 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 18:40:12,016 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:40:21,287 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 18:40:22,616 | server.py:125 | fit progress: (7, 1.531477451324463, {'accuracy': 0.9287, 'data_size': 10000}, 89.3315353500002)
INFO flwr 2024-04-26 18:40:22,616 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 18:40:22,616 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:40:31,592 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 18:40:32,950 | server.py:125 | fit progress: (8, 1.528846025466919, {'accuracy': 0.9316, 'data_size': 10000}, 99.66541613799927)
INFO flwr 2024-04-26 18:40:32,950 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 18:40:32,950 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:40:41,706 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 18:40:43,267 | server.py:125 | fit progress: (9, 1.5219093561172485, {'accuracy': 0.939, 'data_size': 10000}, 109.98309800800052)
INFO flwr 2024-04-26 18:40:43,268 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 18:40:43,268 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:40:52,740 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 18:40:54,270 | server.py:125 | fit progress: (10, 1.5215816497802734, {'accuracy': 0.9394, 'data_size': 10000}, 120.98515355700147)
INFO flwr 2024-04-26 18:40:54,270 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 18:40:54,270 | server.py:153 | FL finished in 120.9856095110008
INFO flwr 2024-04-26 18:40:54,270 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 18:40:54,270 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 18:40:54,270 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 18:40:54,271 | app.py:229 | app_fit: losses_centralized [(0, 2.302450656890869), (1, 2.2097561359405518), (2, 1.7648711204528809), (3, 1.6961052417755127), (4, 1.6457535028457642), (5, 1.5737277269363403), (6, 1.534846305847168), (7, 1.531477451324463), (8, 1.528846025466919), (9, 1.5219093561172485), (10, 1.5215816497802734)]
INFO flwr 2024-04-26 18:40:54,271 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.1029), (1, 0.5699), (2, 0.7566), (3, 0.7603), (4, 0.8126), (5, 0.8874), (6, 0.9268), (7, 0.9287), (8, 0.9316), (9, 0.939), (10, 0.9394)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.9394
wandb:     loss 1.52158
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_183832-ff3b7xun
wandb: Find logs at: ./wandb/offline-run-20240426_183832-ff3b7xun/logs
INFO flwr 2024-04-26 18:40:58,030 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 32
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 50
		Optimizer: FedAdam
			local: {'lr': 0.25}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: 2NN
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=200, bias=True)
			    (1): ReLU()
			    (2): Linear(in_features=200, out_features=200, bias=True)
			    (3): ReLU()
			    (4): Linear(in_features=200, out_features=200, bias=True)
			    (5): ReLU()
			    (6): Linear(in_features=200, out_features=10, bias=True)
			    (7): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 18:40:58,837 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=141980)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=141980)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 18:41:03,626	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 18:41:03,932	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 18:41:04,242	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 18:41:04,244	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 18:41:15,910 | app.py:213 | Flower VCE: Ray initialized with resources: {'CPU': 64.0, 'memory': 167315822388.0, 'accelerator_type:TITAN': 1.0, 'GPU': 1.0, 'object_store_memory': 75992495308.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0}
INFO flwr 2024-04-26 18:41:15,910 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 18:41:15,910 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 18:41:15,926 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 18:41:15,927 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 18:41:15,927 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 18:41:15,927 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 18:41:19,660 | server.py:94 | initial parameters (loss, other metrics): 2.3023674488067627, {'accuracy': 0.101, 'data_size': 10000}
INFO flwr 2024-04-26 18:41:19,660 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 18:41:19,661 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=149174)[0m 2024-04-26 18:41:22.158327: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=149174)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=149174)[0m 2024-04-26 18:41:24.431636: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=149179)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=149179)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=149170)[0m 2024-04-26 18:41:22.552082: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=149170)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=149170)[0m 2024-04-26 18:41:24.936712: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 18:41:45,003 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 18:41:46,571 | server.py:125 | fit progress: (1, 2.1821587085723877, {'accuracy': 0.5072, 'data_size': 10000}, 26.910916747001465)
INFO flwr 2024-04-26 18:41:46,572 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 18:41:46,572 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:41:58,696 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 18:42:00,035 | server.py:125 | fit progress: (2, 1.8806099891662598, {'accuracy': 0.5806, 'data_size': 10000}, 40.37422471500031)
INFO flwr 2024-04-26 18:42:00,035 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 18:42:00,035 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:42:11,302 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 18:42:12,604 | server.py:125 | fit progress: (3, 1.7026488780975342, {'accuracy': 0.757, 'data_size': 10000}, 52.943778217002546)
INFO flwr 2024-04-26 18:42:12,605 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 18:42:12,605 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:42:24,500 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 18:42:26,082 | server.py:125 | fit progress: (4, 1.576956033706665, {'accuracy': 0.8838, 'data_size': 10000}, 66.42111681900133)
INFO flwr 2024-04-26 18:42:26,082 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 18:42:26,082 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:42:37,708 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 18:42:39,271 | server.py:125 | fit progress: (5, 1.5526305437088013, {'accuracy': 0.9079, 'data_size': 10000}, 79.6108044749999)
INFO flwr 2024-04-26 18:42:39,272 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 18:42:39,272 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:42:50,343 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 18:42:51,871 | server.py:125 | fit progress: (6, 1.5426762104034424, {'accuracy': 0.918, 'data_size': 10000}, 92.21066412300206)
INFO flwr 2024-04-26 18:42:51,871 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 18:42:51,872 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:43:03,314 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 18:43:04,833 | server.py:125 | fit progress: (7, 1.5411726236343384, {'accuracy': 0.9194, 'data_size': 10000}, 105.17262036500324)
INFO flwr 2024-04-26 18:43:04,833 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 18:43:04,834 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:43:15,236 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 18:43:16,783 | server.py:125 | fit progress: (8, 1.5372143983840942, {'accuracy': 0.9236, 'data_size': 10000}, 117.12265030300114)
INFO flwr 2024-04-26 18:43:16,784 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 18:43:16,784 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:43:29,187 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 18:43:30,510 | server.py:125 | fit progress: (9, 1.5372596979141235, {'accuracy': 0.9236, 'data_size': 10000}, 130.84917094400225)
INFO flwr 2024-04-26 18:43:30,510 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 18:43:30,510 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:43:42,645 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 18:43:43,964 | server.py:125 | fit progress: (10, 1.530044674873352, {'accuracy': 0.9308, 'data_size': 10000}, 144.3033044420008)
INFO flwr 2024-04-26 18:43:43,964 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 18:43:43,964 | server.py:153 | FL finished in 144.30385214000125
INFO flwr 2024-04-26 18:43:43,965 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 18:43:43,965 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 18:43:43,965 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 18:43:43,965 | app.py:229 | app_fit: losses_centralized [(0, 2.3023674488067627), (1, 2.1821587085723877), (2, 1.8806099891662598), (3, 1.7026488780975342), (4, 1.576956033706665), (5, 1.5526305437088013), (6, 1.5426762104034424), (7, 1.5411726236343384), (8, 1.5372143983840942), (9, 1.5372596979141235), (10, 1.530044674873352)]
INFO flwr 2024-04-26 18:43:43,965 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.101), (1, 0.5072), (2, 0.5806), (3, 0.757), (4, 0.8838), (5, 0.9079), (6, 0.918), (7, 0.9194), (8, 0.9236), (9, 0.9236), (10, 0.9308)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.9308
wandb:     loss 1.53004
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_184058-0z45l4o6
wandb: Find logs at: ./wandb/offline-run-20240426_184058-0z45l4o6/logs
INFO flwr 2024-04-26 18:43:47,782 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 32
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 50
		Optimizer: FedAdam
			local: {'lr': 0.3}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: 2NN
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=200, bias=True)
			    (1): ReLU()
			    (2): Linear(in_features=200, out_features=200, bias=True)
			    (3): ReLU()
			    (4): Linear(in_features=200, out_features=200, bias=True)
			    (5): ReLU()
			    (6): Linear(in_features=200, out_features=10, bias=True)
			    (7): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 18:43:49,102 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=149166)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=149166)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 18:43:54,234	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 18:43:54,703	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 18:43:55,021	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 18:43:55,023	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 18:44:09,713 | app.py:213 | Flower VCE: Ray initialized with resources: {'GPU': 1.0, 'object_store_memory': 76657038950.0, 'CPU': 64.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0, 'accelerator_type:TITAN': 1.0, 'memory': 168866424218.0}
INFO flwr 2024-04-26 18:44:09,714 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 18:44:09,714 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 18:44:09,733 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 18:44:09,734 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 18:44:09,734 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 18:44:09,734 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 18:44:13,185 | server.py:94 | initial parameters (loss, other metrics): 2.3025574684143066, {'accuracy': 0.1282, 'data_size': 10000}
INFO flwr 2024-04-26 18:44:13,186 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 18:44:13,186 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=155177)[0m 2024-04-26 18:44:16.110083: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=155177)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=155172)[0m 2024-04-26 18:44:18.356072: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=155177)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=155177)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=155178)[0m 2024-04-26 18:44:16.330541: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=155178)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=155171)[0m 2024-04-26 18:44:18.873665: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 18:44:40,922 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 18:44:42,506 | server.py:125 | fit progress: (1, 2.1895763874053955, {'accuracy': 0.516, 'data_size': 10000}, 29.32040863400107)
INFO flwr 2024-04-26 18:44:42,507 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 18:44:42,507 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:44:55,026 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 18:44:56,556 | server.py:125 | fit progress: (2, 1.8177425861358643, {'accuracy': 0.6569, 'data_size': 10000}, 43.36976597899775)
INFO flwr 2024-04-26 18:44:56,556 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 18:44:56,556 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:45:08,309 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 18:45:09,886 | server.py:125 | fit progress: (3, 1.7036640644073486, {'accuracy': 0.7565, 'data_size': 10000}, 56.70036593400073)
INFO flwr 2024-04-26 18:45:09,886 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 18:45:09,887 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:45:22,403 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 18:45:23,976 | server.py:125 | fit progress: (4, 1.641721248626709, {'accuracy': 0.818, 'data_size': 10000}, 70.79012278899972)
INFO flwr 2024-04-26 18:45:23,976 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 18:45:23,976 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:45:34,895 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 18:45:36,246 | server.py:125 | fit progress: (5, 1.587602972984314, {'accuracy': 0.8728, 'data_size': 10000}, 83.0596871609996)
INFO flwr 2024-04-26 18:45:36,246 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 18:45:36,246 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:45:47,927 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 18:45:49,496 | server.py:125 | fit progress: (6, 1.5590957403182983, {'accuracy': 0.9011, 'data_size': 10000}, 96.30974965399946)
INFO flwr 2024-04-26 18:45:49,496 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 18:45:49,496 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:46:01,537 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 18:46:03,126 | server.py:125 | fit progress: (7, 1.552844762802124, {'accuracy': 0.9083, 'data_size': 10000}, 109.94023248499798)
INFO flwr 2024-04-26 18:46:03,126 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 18:46:03,127 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:46:14,784 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 18:46:16,332 | server.py:125 | fit progress: (8, 1.5400787591934204, {'accuracy': 0.9204, 'data_size': 10000}, 123.14634927899897)
INFO flwr 2024-04-26 18:46:16,332 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 18:46:16,333 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:46:28,157 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 18:46:29,726 | server.py:125 | fit progress: (9, 1.5309484004974365, {'accuracy': 0.9303, 'data_size': 10000}, 136.53983512500054)
INFO flwr 2024-04-26 18:46:29,726 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 18:46:29,726 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:46:41,219 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 18:46:42,800 | server.py:125 | fit progress: (10, 1.5258970260620117, {'accuracy': 0.935, 'data_size': 10000}, 149.61458356000003)
INFO flwr 2024-04-26 18:46:42,801 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 18:46:42,801 | server.py:153 | FL finished in 149.61516435099838
INFO flwr 2024-04-26 18:46:42,801 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 18:46:42,801 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 18:46:42,801 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 18:46:42,802 | app.py:229 | app_fit: losses_centralized [(0, 2.3025574684143066), (1, 2.1895763874053955), (2, 1.8177425861358643), (3, 1.7036640644073486), (4, 1.641721248626709), (5, 1.587602972984314), (6, 1.5590957403182983), (7, 1.552844762802124), (8, 1.5400787591934204), (9, 1.5309484004974365), (10, 1.5258970260620117)]
INFO flwr 2024-04-26 18:46:42,802 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.1282), (1, 0.516), (2, 0.6569), (3, 0.7565), (4, 0.818), (5, 0.8728), (6, 0.9011), (7, 0.9083), (8, 0.9204), (9, 0.9303), (10, 0.935)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.935
wandb:     loss 1.5259
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_184348-cj2cdmaw
wandb: Find logs at: ./wandb/offline-run-20240426_184348-cj2cdmaw/logs
INFO flwr 2024-04-26 18:46:46,546 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 32
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 50
		Optimizer: FedAdam
			local: {'lr': 0.4}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: 2NN
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=200, bias=True)
			    (1): ReLU()
			    (2): Linear(in_features=200, out_features=200, bias=True)
			    (3): ReLU()
			    (4): Linear(in_features=200, out_features=200, bias=True)
			    (5): ReLU()
			    (6): Linear(in_features=200, out_features=10, bias=True)
			    (7): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 18:46:48,042 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=155167)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=155167)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 18:46:54,930	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 18:46:55,250	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 18:46:55,580	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 18:46:55,581	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 18:47:06,903 | app.py:213 | Flower VCE: Ray initialized with resources: {'object_store_memory': 76397223936.0, 'CPU': 64.0, 'node:__internal_head__': 1.0, 'node:10.20.240.12': 1.0, 'GPU': 1.0, 'accelerator_type:TITAN': 1.0, 'memory': 168260189184.0}
INFO flwr 2024-04-26 18:47:06,903 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 18:47:06,903 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 18:47:06,918 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 18:47:06,920 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 18:47:06,920 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 18:47:06,920 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 18:47:10,293 | server.py:94 | initial parameters (loss, other metrics): 2.3025667667388916, {'accuracy': 0.1028, 'data_size': 10000}
INFO flwr 2024-04-26 18:47:10,293 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 18:47:10,294 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=161934)[0m 2024-04-26 18:47:13.320729: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=161934)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=161934)[0m 2024-04-26 18:47:15.602831: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=161932)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=161932)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=161929)[0m 2024-04-26 18:47:13.495714: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=161929)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=161929)[0m 2024-04-26 18:47:15.866234: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 18:47:35,767 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 18:47:37,393 | server.py:125 | fit progress: (1, 2.212388515472412, {'accuracy': 0.3853, 'data_size': 10000}, 27.09961885699886)
INFO flwr 2024-04-26 18:47:37,393 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 18:47:37,393 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:47:50,676 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 18:47:51,993 | server.py:125 | fit progress: (2, 1.8904433250427246, {'accuracy': 0.5871, 'data_size': 10000}, 41.69938198800082)
INFO flwr 2024-04-26 18:47:51,993 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 18:47:51,993 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:48:04,018 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 18:48:05,383 | server.py:125 | fit progress: (3, 1.6272423267364502, {'accuracy': 0.8363, 'data_size': 10000}, 55.089929475001554)
INFO flwr 2024-04-26 18:48:05,384 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 18:48:05,384 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:48:16,914 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 18:48:18,473 | server.py:125 | fit progress: (4, 1.6027053594589233, {'accuracy': 0.8568, 'data_size': 10000}, 68.1799533830017)
INFO flwr 2024-04-26 18:48:18,474 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 18:48:18,474 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:48:30,065 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 18:48:31,595 | server.py:125 | fit progress: (5, 1.5758020877838135, {'accuracy': 0.8838, 'data_size': 10000}, 81.30180998099968)
INFO flwr 2024-04-26 18:48:31,596 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 18:48:31,596 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:48:43,534 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 18:48:45,122 | server.py:125 | fit progress: (6, 1.5447614192962646, {'accuracy': 0.9167, 'data_size': 10000}, 94.82852062800157)
INFO flwr 2024-04-26 18:48:45,122 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 18:48:45,122 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:48:57,667 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 18:48:59,196 | server.py:125 | fit progress: (7, 1.5319905281066895, {'accuracy': 0.929, 'data_size': 10000}, 108.90228680799919)
INFO flwr 2024-04-26 18:48:59,196 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 18:48:59,196 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:49:09,692 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 18:49:11,199 | server.py:125 | fit progress: (8, 1.535687804222107, {'accuracy': 0.9253, 'data_size': 10000}, 120.90603249700143)
INFO flwr 2024-04-26 18:49:11,200 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 18:49:11,200 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:49:23,305 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 18:49:24,844 | server.py:125 | fit progress: (9, 1.530234694480896, {'accuracy': 0.9309, 'data_size': 10000}, 134.55015434099914)
INFO flwr 2024-04-26 18:49:24,844 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 18:49:24,844 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:49:37,058 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 18:49:38,583 | server.py:125 | fit progress: (10, 1.5206801891326904, {'accuracy': 0.9401, 'data_size': 10000}, 148.28993718100173)
INFO flwr 2024-04-26 18:49:38,584 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 18:49:38,584 | server.py:153 | FL finished in 148.29040494500077
INFO flwr 2024-04-26 18:49:38,584 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 18:49:38,584 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 18:49:38,584 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 18:49:38,584 | app.py:229 | app_fit: losses_centralized [(0, 2.3025667667388916), (1, 2.212388515472412), (2, 1.8904433250427246), (3, 1.6272423267364502), (4, 1.6027053594589233), (5, 1.5758020877838135), (6, 1.5447614192962646), (7, 1.5319905281066895), (8, 1.535687804222107), (9, 1.530234694480896), (10, 1.5206801891326904)]
INFO flwr 2024-04-26 18:49:38,584 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.1028), (1, 0.3853), (2, 0.5871), (3, 0.8363), (4, 0.8568), (5, 0.8838), (6, 0.9167), (7, 0.929), (8, 0.9253), (9, 0.9309), (10, 0.9401)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.9401
wandb:     loss 1.52068
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_184646-159efuwk
wandb: Find logs at: ./wandb/offline-run-20240426_184646-159efuwk/logs
[2m[36m(DefaultActor pid=161923)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=161923)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 18:50:57.739869: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-04-26 18:50:58.906930: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
INFO flwr 2024-04-26 18:51:08,162 | batch_run_simulation.py:80 | Loaded 9 configs with name MINST-CNN-FEDADAM, running...
INFO flwr 2024-04-26 18:51:08,163 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 8
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 10
		Optimizer: FedAdam
			local: {'lr': 0.1}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(1, 28, 28) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: CNN
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
			    (1): ReLU()
			    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
			    (3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
			    (4): ReLU()
			    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
			    (6): Flatten(start_dim=1, end_dim=-1)
			    (7): Linear(in_features=3136, out_features=512, bias=True)
			    (8): ReLU()
			    (9): Linear(in_features=512, out_features=10, bias=True)
			    (10): Softmax(dim=-1)
			  )
			)
Using the latest cached version of the dataset since mnist couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'mnist' at .cache/mnist/mnist/1.0.0/b06aab39e05f7bcd9635d18ed25d06eae523c574 (last modified on Tue Apr  2 18:09:57 2024).
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 18:58:43,444 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
2024-04-26 18:58:46,034	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 18:58:46,390	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 18:58:46,711	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 18:58:46,713	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 18:58:57,968 | app.py:213 | Flower VCE: Ray initialized with resources: {'object_store_memory': 78392463360.0, 'CPU': 64.0, 'GPU': 1.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0, 'accelerator_type:TITAN': 1.0, 'memory': 172915747840.0}
INFO flwr 2024-04-26 18:58:57,969 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 18:58:57,969 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 18:58:57,986 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 18:58:57,986 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 18:58:57,987 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 18:58:57,987 | server.py:91 | Evaluating initial parameters
[2m[36m(pid=172941)[0m 2024-04-26 18:59:04.155853: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=172941)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=172946)[0m 2024-04-26 18:59:06.494020: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
INFO flwr 2024-04-26 18:59:11,920 | server.py:94 | initial parameters (loss, other metrics): 2.302238702774048, {'accuracy': 0.1222, 'data_size': 10000}
INFO flwr 2024-04-26 18:59:11,920 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 18:59:11,921 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(DefaultActor pid=172952)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=172952)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=172943)[0m 2024-04-26 18:59:04.242179: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)[0m
[2m[36m(pid=172943)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=172948)[0m 2024-04-26 18:59:06.702323: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=172945)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 4x across cluster][0m
[2m[36m(DefaultActor pid=172945)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 4x across cluster][0m
DEBUG flwr 2024-04-26 18:59:31,268 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 18:59:35,909 | server.py:125 | fit progress: (1, 1.8235431909561157, {'accuracy': 0.6601, 'data_size': 10000}, 23.9887378070016)
INFO flwr 2024-04-26 18:59:35,909 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 18:59:35,910 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 18:59:48,478 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 18:59:53,176 | server.py:125 | fit progress: (2, 1.5443599224090576, {'accuracy': 0.9202, 'data_size': 10000}, 41.25538709399916)
INFO flwr 2024-04-26 18:59:53,176 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 18:59:53,176 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:00:05,143 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 19:00:09,772 | server.py:125 | fit progress: (3, 1.5086679458618164, {'accuracy': 0.9531, 'data_size': 10000}, 57.85119043300074)
INFO flwr 2024-04-26 19:00:09,772 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 19:00:09,772 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:00:21,234 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 19:00:25,632 | server.py:125 | fit progress: (4, 1.4967886209487915, {'accuracy': 0.9643, 'data_size': 10000}, 73.71185006900123)
INFO flwr 2024-04-26 19:00:25,633 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 19:00:25,633 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:00:36,632 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 19:00:41,295 | server.py:125 | fit progress: (5, 1.491178035736084, {'accuracy': 0.97, 'data_size': 10000}, 89.37496056099917)
INFO flwr 2024-04-26 19:00:41,296 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 19:00:41,296 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:00:53,193 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 19:00:57,869 | server.py:125 | fit progress: (6, 1.4921079874038696, {'accuracy': 0.9689, 'data_size': 10000}, 105.94816924000042)
INFO flwr 2024-04-26 19:00:57,869 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 19:00:57,869 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:01:09,222 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 19:01:13,673 | server.py:125 | fit progress: (7, 1.4858131408691406, {'accuracy': 0.9754, 'data_size': 10000}, 121.75307609800075)
INFO flwr 2024-04-26 19:01:13,674 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 19:01:13,674 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:01:25,330 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 19:01:29,713 | server.py:125 | fit progress: (8, 1.48841392993927, {'accuracy': 0.9726, 'data_size': 10000}, 137.79243535000205)
INFO flwr 2024-04-26 19:01:29,713 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 19:01:29,714 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:01:41,524 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 19:01:46,222 | server.py:125 | fit progress: (9, 1.499781608581543, {'accuracy': 0.9615, 'data_size': 10000}, 154.30154857100206)
INFO flwr 2024-04-26 19:01:46,222 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 19:01:46,223 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:01:58,206 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 19:02:02,850 | server.py:125 | fit progress: (10, 1.4914147853851318, {'accuracy': 0.9697, 'data_size': 10000}, 170.92928934900192)
INFO flwr 2024-04-26 19:02:02,850 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 19:02:02,850 | server.py:153 | FL finished in 170.93007841600047
INFO flwr 2024-04-26 19:02:02,857 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 19:02:02,857 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 19:02:02,857 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 19:02:02,857 | app.py:229 | app_fit: losses_centralized [(0, 2.302238702774048), (1, 1.8235431909561157), (2, 1.5443599224090576), (3, 1.5086679458618164), (4, 1.4967886209487915), (5, 1.491178035736084), (6, 1.4921079874038696), (7, 1.4858131408691406), (8, 1.48841392993927), (9, 1.499781608581543), (10, 1.4914147853851318)]
INFO flwr 2024-04-26 19:02:02,857 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.1222), (1, 0.6601), (2, 0.9202), (3, 0.9531), (4, 0.9643), (5, 0.97), (6, 0.9689), (7, 0.9754), (8, 0.9726), (9, 0.9615), (10, 0.9697)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.9697
wandb:     loss 1.49141
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_185842-xw6onzpc
wandb: Find logs at: ./wandb/offline-run-20240426_185842-xw6onzpc/logs
INFO flwr 2024-04-26 19:02:06,550 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 8
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 10
		Optimizer: FedAdam
			local: {'lr': 0.15}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(1, 28, 28) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: CNN
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
			    (1): ReLU()
			    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
			    (3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
			    (4): ReLU()
			    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
			    (6): Flatten(start_dim=1, end_dim=-1)
			    (7): Linear(in_features=3136, out_features=512, bias=True)
			    (8): ReLU()
			    (9): Linear(in_features=512, out_features=10, bias=True)
			    (10): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 19:02:07,312 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=172941)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 3x across cluster][0m
[2m[36m(DefaultActor pid=172941)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 3x across cluster][0m
2024-04-26 19:02:12,470	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 19:02:12,829	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 19:02:13,145	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 19:02:13,146	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 19:02:24,414 | app.py:213 | Flower VCE: Ray initialized with resources: {'object_store_memory': 78188594380.0, 'GPU': 1.0, 'node:__internal_head__': 1.0, 'node:10.20.240.12': 1.0, 'CPU': 64.0, 'accelerator_type:TITAN': 1.0, 'memory': 172440053556.0}
INFO flwr 2024-04-26 19:02:24,414 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 19:02:24,415 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 19:02:24,431 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 19:02:24,432 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 19:02:24,432 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 19:02:24,432 | server.py:91 | Evaluating initial parameters
[2m[36m(pid=176715)[0m 2024-04-26 19:02:30.752584: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=176715)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=176714)[0m 2024-04-26 19:02:33.088520: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
INFO flwr 2024-04-26 19:02:33,821 | server.py:94 | initial parameters (loss, other metrics): 2.3024935722351074, {'accuracy': 0.1005, 'data_size': 10000}
INFO flwr 2024-04-26 19:02:33,821 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 19:02:33,822 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(DefaultActor pid=176716)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=176716)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=176712)[0m 2024-04-26 19:02:30.922401: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=176712)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=176712)[0m 2024-04-26 19:02:33.308816: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=176710)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 5x across cluster][0m
[2m[36m(DefaultActor pid=176710)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 5x across cluster][0m
DEBUG flwr 2024-04-26 19:02:53,984 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 19:02:58,610 | server.py:125 | fit progress: (1, 1.8595136404037476, {'accuracy': 0.6367, 'data_size': 10000}, 24.788453680997918)
INFO flwr 2024-04-26 19:02:58,610 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 19:02:58,610 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:03:10,933 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 19:03:15,583 | server.py:125 | fit progress: (2, 1.6223266124725342, {'accuracy': 0.8412, 'data_size': 10000}, 41.761148074998346)
INFO flwr 2024-04-26 19:03:15,583 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 19:03:15,583 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:03:26,464 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 19:03:31,040 | server.py:125 | fit progress: (3, 1.5735098123550415, {'accuracy': 0.8882, 'data_size': 10000}, 57.21880847599823)
INFO flwr 2024-04-26 19:03:31,041 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 19:03:31,041 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:03:42,805 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 19:03:47,431 | server.py:125 | fit progress: (4, 1.5085904598236084, {'accuracy': 0.9526, 'data_size': 10000}, 73.60978830999738)
INFO flwr 2024-04-26 19:03:47,431 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 19:03:47,432 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:03:59,391 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 19:04:04,051 | server.py:125 | fit progress: (5, 1.4993088245391846, {'accuracy': 0.9615, 'data_size': 10000}, 90.22963102499853)
INFO flwr 2024-04-26 19:04:04,051 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 19:04:04,052 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:04:16,304 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 19:04:20,750 | server.py:125 | fit progress: (6, 1.491769552230835, {'accuracy': 0.969, 'data_size': 10000}, 106.92844658399918)
INFO flwr 2024-04-26 19:04:20,750 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 19:04:20,751 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:04:33,707 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 19:04:38,166 | server.py:125 | fit progress: (7, 1.491212010383606, {'accuracy': 0.9697, 'data_size': 10000}, 124.34457488800035)
INFO flwr 2024-04-26 19:04:38,166 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 19:04:38,167 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:04:50,611 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 19:04:55,271 | server.py:125 | fit progress: (8, 1.4895254373550415, {'accuracy': 0.9716, 'data_size': 10000}, 141.4495430529969)
INFO flwr 2024-04-26 19:04:55,271 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 19:04:55,272 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:05:07,395 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 19:05:12,020 | server.py:125 | fit progress: (9, 1.4923909902572632, {'accuracy': 0.9689, 'data_size': 10000}, 158.1990420919974)
INFO flwr 2024-04-26 19:05:12,021 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 19:05:12,021 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:05:23,834 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 19:05:28,498 | server.py:125 | fit progress: (10, 1.496158242225647, {'accuracy': 0.965, 'data_size': 10000}, 174.67708132400003)
INFO flwr 2024-04-26 19:05:28,499 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 19:05:28,499 | server.py:153 | FL finished in 174.67753524900036
INFO flwr 2024-04-26 19:05:28,502 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 19:05:28,502 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 19:05:28,502 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 19:05:28,503 | app.py:229 | app_fit: losses_centralized [(0, 2.3024935722351074), (1, 1.8595136404037476), (2, 1.6223266124725342), (3, 1.5735098123550415), (4, 1.5085904598236084), (5, 1.4993088245391846), (6, 1.491769552230835), (7, 1.491212010383606), (8, 1.4895254373550415), (9, 1.4923909902572632), (10, 1.496158242225647)]
INFO flwr 2024-04-26 19:05:28,503 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.1005), (1, 0.6367), (2, 0.8412), (3, 0.8882), (4, 0.9526), (5, 0.9615), (6, 0.969), (7, 0.9697), (8, 0.9716), (9, 0.9689), (10, 0.965)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.965
wandb:     loss 1.49616
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_190206-dxacjar3
wandb: Find logs at: ./wandb/offline-run-20240426_190206-dxacjar3/logs
INFO flwr 2024-04-26 19:05:32,483 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 8
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 10
		Optimizer: FedAdam
			local: {'lr': 0.2}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(1, 28, 28) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: CNN
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
			    (1): ReLU()
			    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
			    (3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
			    (4): ReLU()
			    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
			    (6): Flatten(start_dim=1, end_dim=-1)
			    (7): Linear(in_features=3136, out_features=512, bias=True)
			    (8): ReLU()
			    (9): Linear(in_features=512, out_features=10, bias=True)
			    (10): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 19:05:33,491 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=176708)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 2x across cluster][0m
[2m[36m(DefaultActor pid=176708)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 2x across cluster][0m
2024-04-26 19:05:38,453	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 19:05:38,890	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 19:05:39,217	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 19:05:39,219	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 19:05:50,453 | app.py:213 | Flower VCE: Ray initialized with resources: {'object_store_memory': 74126442086.0, 'GPU': 1.0, 'CPU': 64.0, 'accelerator_type:TITAN': 1.0, 'memory': 162961698202.0, 'node:__internal_head__': 1.0, 'node:10.20.240.12': 1.0}
INFO flwr 2024-04-26 19:05:50,453 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 19:05:50,453 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 19:05:50,468 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 19:05:50,469 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 19:05:50,470 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 19:05:50,470 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 19:05:57,143 | server.py:94 | initial parameters (loss, other metrics): 2.3026363849639893, {'accuracy': 0.096, 'data_size': 10000}
INFO flwr 2024-04-26 19:05:57,143 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 19:05:57,144 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=183914)[0m 2024-04-26 19:06:01.481816: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=183914)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=183914)[0m 2024-04-26 19:06:03.959398: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=183914)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=183914)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=183911)[0m 2024-04-26 19:06:01.648347: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=183911)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=183911)[0m 2024-04-26 19:06:04.006331: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 19:06:27,353 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 19:06:31,862 | server.py:125 | fit progress: (1, 1.9624537229537964, {'accuracy': 0.5033, 'data_size': 10000}, 34.7182414150011)
INFO flwr 2024-04-26 19:06:31,862 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 19:06:31,862 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:06:45,345 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 19:06:49,754 | server.py:125 | fit progress: (2, 1.5424087047576904, {'accuracy': 0.9317, 'data_size': 10000}, 52.61018048800179)
INFO flwr 2024-04-26 19:06:49,754 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 19:06:49,754 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:07:02,061 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 19:07:06,478 | server.py:125 | fit progress: (3, 1.4997832775115967, {'accuracy': 0.9622, 'data_size': 10000}, 69.33466284699898)
INFO flwr 2024-04-26 19:07:06,478 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 19:07:06,479 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:07:19,135 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 19:07:23,720 | server.py:125 | fit progress: (4, 1.4958453178405762, {'accuracy': 0.9656, 'data_size': 10000}, 86.57614117299818)
INFO flwr 2024-04-26 19:07:23,720 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 19:07:23,721 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:07:34,925 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 19:07:39,523 | server.py:125 | fit progress: (5, 1.4895268678665161, {'accuracy': 0.972, 'data_size': 10000}, 102.37958216799962)
INFO flwr 2024-04-26 19:07:39,523 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 19:07:39,524 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:07:51,689 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 19:07:56,309 | server.py:125 | fit progress: (6, 1.4878478050231934, {'accuracy': 0.973, 'data_size': 10000}, 119.16597798300063)
INFO flwr 2024-04-26 19:07:56,310 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 19:07:56,310 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:08:08,694 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 19:08:13,326 | server.py:125 | fit progress: (7, 1.492583155632019, {'accuracy': 0.9686, 'data_size': 10000}, 136.1826027870011)
INFO flwr 2024-04-26 19:08:13,327 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 19:08:13,327 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:08:25,935 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 19:08:30,512 | server.py:125 | fit progress: (8, 1.4915072917938232, {'accuracy': 0.9697, 'data_size': 10000}, 153.36811974800003)
INFO flwr 2024-04-26 19:08:30,512 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 19:08:30,512 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:08:41,819 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 19:08:46,424 | server.py:125 | fit progress: (9, 1.4947551488876343, {'accuracy': 0.9662, 'data_size': 10000}, 169.28075075599918)
INFO flwr 2024-04-26 19:08:46,425 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 19:08:46,425 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:08:58,517 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 19:09:02,852 | server.py:125 | fit progress: (10, 1.494924545288086, {'accuracy': 0.9662, 'data_size': 10000}, 185.7085603509986)
INFO flwr 2024-04-26 19:09:02,852 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 19:09:02,852 | server.py:153 | FL finished in 185.70902027099874
INFO flwr 2024-04-26 19:09:02,861 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 19:09:02,861 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 19:09:02,861 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 19:09:02,862 | app.py:229 | app_fit: losses_centralized [(0, 2.3026363849639893), (1, 1.9624537229537964), (2, 1.5424087047576904), (3, 1.4997832775115967), (4, 1.4958453178405762), (5, 1.4895268678665161), (6, 1.4878478050231934), (7, 1.492583155632019), (8, 1.4915072917938232), (9, 1.4947551488876343), (10, 1.494924545288086)]
INFO flwr 2024-04-26 19:09:02,862 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.096), (1, 0.5033), (2, 0.9317), (3, 0.9622), (4, 0.9656), (5, 0.972), (6, 0.973), (7, 0.9686), (8, 0.9697), (9, 0.9662), (10, 0.9662)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.9662
wandb:     loss 1.49492
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_190532-1vtetq0f
wandb: Find logs at: ./wandb/offline-run-20240426_190532-1vtetq0f/logs
INFO flwr 2024-04-26 19:09:06,597 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 16
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 10
		Optimizer: FedAdam
			local: {'lr': 0.1}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(1, 28, 28) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: CNN
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
			    (1): ReLU()
			    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
			    (3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
			    (4): ReLU()
			    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
			    (6): Flatten(start_dim=1, end_dim=-1)
			    (7): Linear(in_features=3136, out_features=512, bias=True)
			    (8): ReLU()
			    (9): Linear(in_features=512, out_features=10, bias=True)
			    (10): Softmax(dim=-1)
			  )
			)
Using the latest cached version of the dataset since mnist couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'mnist' at .cache/mnist/mnist/1.0.0/b06aab39e05f7bcd9635d18ed25d06eae523c574 (last modified on Tue Apr  2 18:09:57 2024).
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 19:16:38,646 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=183917)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=183917)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 19:16:43,989	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 19:16:44,323	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 19:16:44,643	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 19:16:44,645	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 19:16:55,894 | app.py:213 | Flower VCE: Ray initialized with resources: {'GPU': 1.0, 'object_store_memory': 74051503718.0, 'CPU': 64.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0, 'memory': 162786842010.0, 'accelerator_type:TITAN': 1.0}
INFO flwr 2024-04-26 19:16:55,894 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 19:16:55,894 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 19:16:55,910 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 19:16:55,911 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 19:16:55,912 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 19:16:55,912 | server.py:91 | Evaluating initial parameters
[2m[36m(pid=197938)[0m 2024-04-26 19:17:02.187397: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=197938)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=197931)[0m 2024-04-26 19:17:04.510109: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
INFO flwr 2024-04-26 19:17:04,770 | server.py:94 | initial parameters (loss, other metrics): 2.302727460861206, {'accuracy': 0.1025, 'data_size': 10000}
INFO flwr 2024-04-26 19:17:04,770 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 19:17:04,771 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(DefaultActor pid=197943)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=197943)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=197933)[0m 2024-04-26 19:17:02.414397: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=197933)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=197933)[0m 2024-04-26 19:17:04.682061: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=197933)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 6x across cluster][0m
[2m[36m(DefaultActor pid=197933)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 6x across cluster][0m
DEBUG flwr 2024-04-26 19:17:23,661 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 19:17:28,198 | server.py:125 | fit progress: (1, 2.200806140899658, {'accuracy': 0.2541, 'data_size': 10000}, 23.427648901000794)
INFO flwr 2024-04-26 19:17:28,199 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 19:17:28,199 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:17:39,309 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 19:17:43,954 | server.py:125 | fit progress: (2, 1.7293107509613037, {'accuracy': 0.7316, 'data_size': 10000}, 39.18292167799882)
INFO flwr 2024-04-26 19:17:43,954 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 19:17:43,954 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:17:54,115 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 19:17:58,481 | server.py:125 | fit progress: (3, 1.6133816242218018, {'accuracy': 0.8474, 'data_size': 10000}, 53.71014073200058)
INFO flwr 2024-04-26 19:17:58,481 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 19:17:58,482 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:18:08,202 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 19:18:12,843 | server.py:125 | fit progress: (4, 1.6215801239013672, {'accuracy': 0.8388, 'data_size': 10000}, 68.07274839499951)
INFO flwr 2024-04-26 19:18:12,844 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 19:18:12,844 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:18:23,066 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 19:18:27,665 | server.py:125 | fit progress: (5, 1.5983999967575073, {'accuracy': 0.8624, 'data_size': 10000}, 82.89404157199897)
INFO flwr 2024-04-26 19:18:27,665 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 19:18:27,665 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:18:37,647 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 19:18:42,391 | server.py:125 | fit progress: (6, 1.596940279006958, {'accuracy': 0.8639, 'data_size': 10000}, 97.6207112810007)
INFO flwr 2024-04-26 19:18:42,392 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 19:18:42,392 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:18:52,573 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 19:18:57,183 | server.py:125 | fit progress: (7, 1.5880343914031982, {'accuracy': 0.8724, 'data_size': 10000}, 112.41190555800131)
INFO flwr 2024-04-26 19:18:57,183 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 19:18:57,183 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:19:07,218 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 19:19:11,857 | server.py:125 | fit progress: (8, 1.593643307685852, {'accuracy': 0.8672, 'data_size': 10000}, 127.0861163970003)
INFO flwr 2024-04-26 19:19:11,857 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 19:19:11,857 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:19:21,882 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 19:19:26,505 | server.py:125 | fit progress: (9, 1.5909026861190796, {'accuracy': 0.8699, 'data_size': 10000}, 141.73460664899903)
INFO flwr 2024-04-26 19:19:26,506 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 19:19:26,506 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:19:36,870 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 19:19:41,625 | server.py:125 | fit progress: (10, 1.5850815773010254, {'accuracy': 0.876, 'data_size': 10000}, 156.8540394390002)
INFO flwr 2024-04-26 19:19:41,625 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 19:19:41,625 | server.py:153 | FL finished in 156.85458141900017
INFO flwr 2024-04-26 19:19:41,625 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 19:19:41,626 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 19:19:41,626 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 19:19:41,626 | app.py:229 | app_fit: losses_centralized [(0, 2.302727460861206), (1, 2.200806140899658), (2, 1.7293107509613037), (3, 1.6133816242218018), (4, 1.6215801239013672), (5, 1.5983999967575073), (6, 1.596940279006958), (7, 1.5880343914031982), (8, 1.593643307685852), (9, 1.5909026861190796), (10, 1.5850815773010254)]
INFO flwr 2024-04-26 19:19:41,626 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.1025), (1, 0.2541), (2, 0.7316), (3, 0.8474), (4, 0.8388), (5, 0.8624), (6, 0.8639), (7, 0.8724), (8, 0.8672), (9, 0.8699), (10, 0.876)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.876
wandb:     loss 1.58508
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_191638-tard916u
wandb: Find logs at: ./wandb/offline-run-20240426_191638-tard916u/logs
INFO flwr 2024-04-26 19:19:45,309 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 16
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 10
		Optimizer: FedAdam
			local: {'lr': 0.15}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(1, 28, 28) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: CNN
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
			    (1): ReLU()
			    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
			    (3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
			    (4): ReLU()
			    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
			    (6): Flatten(start_dim=1, end_dim=-1)
			    (7): Linear(in_features=3136, out_features=512, bias=True)
			    (8): ReLU()
			    (9): Linear(in_features=512, out_features=10, bias=True)
			    (10): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 19:19:46,005 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=197931)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=197931)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
2024-04-26 19:19:50,893	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 19:19:51,218	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 19:19:51,538	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 19:19:51,539	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 19:20:02,823 | app.py:213 | Flower VCE: Ray initialized with resources: {'object_store_memory': 73991823360.0, 'GPU': 1.0, 'node:__internal_head__': 1.0, 'node:10.20.240.12': 1.0, 'CPU': 64.0, 'memory': 162647587840.0, 'accelerator_type:TITAN': 1.0}
INFO flwr 2024-04-26 19:20:02,824 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 19:20:02,824 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 19:20:02,839 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 19:20:02,840 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 19:20:02,840 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 19:20:02,841 | server.py:91 | Evaluating initial parameters
[2m[36m(pid=201068)[0m 2024-04-26 19:20:09.132797: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=201068)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=201068)[0m 2024-04-26 19:20:11.467123: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
INFO flwr 2024-04-26 19:20:11,750 | server.py:94 | initial parameters (loss, other metrics): 2.302785634994507, {'accuracy': 0.0847, 'data_size': 10000}
INFO flwr 2024-04-26 19:20:11,751 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 19:20:11,751 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(DefaultActor pid=201078)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=201078)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=201075)[0m 2024-04-26 19:20:09.520398: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=201075)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=201075)[0m 2024-04-26 19:20:11.727555: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=201072)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 4x across cluster][0m
[2m[36m(DefaultActor pid=201072)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 4x across cluster][0m
DEBUG flwr 2024-04-26 19:20:30,111 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 19:20:34,826 | server.py:125 | fit progress: (1, 1.8798537254333496, {'accuracy': 0.5762, 'data_size': 10000}, 23.074464942001214)
INFO flwr 2024-04-26 19:20:34,826 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 19:20:34,826 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:20:45,468 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 19:20:50,113 | server.py:125 | fit progress: (2, 1.564950704574585, {'accuracy': 0.9003, 'data_size': 10000}, 38.362256935000914)
INFO flwr 2024-04-26 19:20:50,114 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 19:20:50,114 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:21:00,509 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 19:21:05,133 | server.py:125 | fit progress: (3, 1.5089696645736694, {'accuracy': 0.9527, 'data_size': 10000}, 53.381867446001706)
INFO flwr 2024-04-26 19:21:05,133 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 19:21:05,134 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:21:15,175 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 19:21:19,821 | server.py:125 | fit progress: (4, 1.5036704540252686, {'accuracy': 0.957, 'data_size': 10000}, 68.07012635499996)
INFO flwr 2024-04-26 19:21:19,822 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 19:21:19,822 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:21:29,738 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 19:21:34,471 | server.py:125 | fit progress: (5, 1.5177993774414062, {'accuracy': 0.9433, 'data_size': 10000}, 82.71948159400199)
INFO flwr 2024-04-26 19:21:34,471 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 19:21:34,471 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:21:43,550 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 19:21:48,309 | server.py:125 | fit progress: (6, 1.4952545166015625, {'accuracy': 0.9662, 'data_size': 10000}, 96.55735748900042)
INFO flwr 2024-04-26 19:21:48,309 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 19:21:48,309 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:21:57,908 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 19:22:02,415 | server.py:125 | fit progress: (7, 1.4939193725585938, {'accuracy': 0.9672, 'data_size': 10000}, 110.66427773900068)
INFO flwr 2024-04-26 19:22:02,416 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 19:22:02,416 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:22:12,410 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 19:22:16,817 | server.py:125 | fit progress: (8, 1.4915472269058228, {'accuracy': 0.9695, 'data_size': 10000}, 125.0657733879998)
INFO flwr 2024-04-26 19:22:16,817 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 19:22:16,817 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:22:26,917 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 19:22:31,393 | server.py:125 | fit progress: (9, 1.4947677850723267, {'accuracy': 0.9661, 'data_size': 10000}, 139.6420002420018)
INFO flwr 2024-04-26 19:22:31,393 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 19:22:31,394 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:22:40,928 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 19:22:45,353 | server.py:125 | fit progress: (10, 1.490951418876648, {'accuracy': 0.9701, 'data_size': 10000}, 153.6018258990007)
INFO flwr 2024-04-26 19:22:45,353 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 19:22:45,354 | server.py:153 | FL finished in 153.60234390900223
INFO flwr 2024-04-26 19:22:45,359 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 19:22:45,360 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 19:22:45,360 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 19:22:45,360 | app.py:229 | app_fit: losses_centralized [(0, 2.302785634994507), (1, 1.8798537254333496), (2, 1.564950704574585), (3, 1.5089696645736694), (4, 1.5036704540252686), (5, 1.5177993774414062), (6, 1.4952545166015625), (7, 1.4939193725585938), (8, 1.4915472269058228), (9, 1.4947677850723267), (10, 1.490951418876648)]
INFO flwr 2024-04-26 19:22:45,360 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0847), (1, 0.5762), (2, 0.9003), (3, 0.9527), (4, 0.957), (5, 0.9433), (6, 0.9662), (7, 0.9672), (8, 0.9695), (9, 0.9661), (10, 0.9701)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.9701
wandb:     loss 1.49095
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_191945-rmz1ohaj
wandb: Find logs at: ./wandb/offline-run-20240426_191945-rmz1ohaj/logs
INFO flwr 2024-04-26 19:22:49,112 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 16
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 10
		Optimizer: FedAdam
			local: {'lr': 0.2}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(1, 28, 28) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: CNN
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
			    (1): ReLU()
			    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
			    (3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
			    (4): ReLU()
			    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
			    (6): Flatten(start_dim=1, end_dim=-1)
			    (7): Linear(in_features=3136, out_features=512, bias=True)
			    (8): ReLU()
			    (9): Linear(in_features=512, out_features=10, bias=True)
			    (10): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 19:22:49,733 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=201067)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 3x across cluster][0m
[2m[36m(DefaultActor pid=201067)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 3x across cluster][0m
2024-04-26 19:22:55,019	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 19:22:55,320	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 19:22:55,632	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 19:22:55,633	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 19:23:07,020 | app.py:213 | Flower VCE: Ray initialized with resources: {'GPU': 1.0, 'object_store_memory': 75003912192.0, 'CPU': 64.0, 'accelerator_type:TITAN': 1.0, 'memory': 165009128448.0, 'node:__internal_head__': 1.0, 'node:10.20.240.12': 1.0}
INFO flwr 2024-04-26 19:23:07,020 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 19:23:07,020 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 19:23:07,035 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 19:23:07,036 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 19:23:07,036 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 19:23:07,036 | server.py:91 | Evaluating initial parameters
[2m[36m(pid=207866)[0m 2024-04-26 19:23:13.250710: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=207866)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=207866)[0m 2024-04-26 19:23:15.542174: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
INFO flwr 2024-04-26 19:23:16,517 | server.py:94 | initial parameters (loss, other metrics): 2.302922487258911, {'accuracy': 0.1152, 'data_size': 10000}
INFO flwr 2024-04-26 19:23:16,518 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 19:23:16,518 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(DefaultActor pid=207869)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=207869)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=207862)[0m 2024-04-26 19:23:13.658530: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=207862)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=207862)[0m 2024-04-26 19:23:16.062781: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=207864)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 5x across cluster][0m
[2m[36m(DefaultActor pid=207864)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 5x across cluster][0m
DEBUG flwr 2024-04-26 19:23:34,469 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 19:23:39,211 | server.py:125 | fit progress: (1, 1.9243144989013672, {'accuracy': 0.5435, 'data_size': 10000}, 22.693000580002263)
INFO flwr 2024-04-26 19:23:39,211 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 19:23:39,212 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:23:49,951 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 19:23:54,426 | server.py:125 | fit progress: (2, 1.6283116340637207, {'accuracy': 0.8344, 'data_size': 10000}, 37.90821265699924)
INFO flwr 2024-04-26 19:23:54,427 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 19:23:54,427 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:24:04,734 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 19:24:09,218 | server.py:125 | fit progress: (3, 1.5032490491867065, {'accuracy': 0.958, 'data_size': 10000}, 52.69996078999975)
INFO flwr 2024-04-26 19:24:09,218 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 19:24:09,219 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:24:18,613 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 19:24:23,168 | server.py:125 | fit progress: (4, 1.4991742372512817, {'accuracy': 0.9624, 'data_size': 10000}, 66.65026704200136)
INFO flwr 2024-04-26 19:24:23,169 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 19:24:23,169 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:24:33,519 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 19:24:38,169 | server.py:125 | fit progress: (5, 1.4961014986038208, {'accuracy': 0.965, 'data_size': 10000}, 81.65097439800229)
INFO flwr 2024-04-26 19:24:38,169 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 19:24:38,170 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:24:48,190 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 19:24:52,834 | server.py:125 | fit progress: (6, 1.4919936656951904, {'accuracy': 0.9691, 'data_size': 10000}, 96.31541381200077)
INFO flwr 2024-04-26 19:24:52,834 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 19:24:52,834 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:25:02,709 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 19:25:07,376 | server.py:125 | fit progress: (7, 1.4872305393218994, {'accuracy': 0.9736, 'data_size': 10000}, 110.85765085800085)
INFO flwr 2024-04-26 19:25:07,376 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 19:25:07,376 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:25:17,894 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 19:25:22,570 | server.py:125 | fit progress: (8, 1.4860711097717285, {'accuracy': 0.9753, 'data_size': 10000}, 126.05143522300204)
INFO flwr 2024-04-26 19:25:22,570 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 19:25:22,570 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:25:32,695 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 19:25:37,324 | server.py:125 | fit progress: (9, 1.488295555114746, {'accuracy': 0.9727, 'data_size': 10000}, 140.8054146760005)
INFO flwr 2024-04-26 19:25:37,324 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 19:25:37,324 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:25:47,730 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 19:25:52,400 | server.py:125 | fit progress: (10, 1.4874175786972046, {'accuracy': 0.9738, 'data_size': 10000}, 155.8821361770024)
INFO flwr 2024-04-26 19:25:52,401 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 19:25:52,401 | server.py:153 | FL finished in 155.88270459600244
INFO flwr 2024-04-26 19:25:52,404 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 19:25:52,404 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 19:25:52,404 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 19:25:52,404 | app.py:229 | app_fit: losses_centralized [(0, 2.302922487258911), (1, 1.9243144989013672), (2, 1.6283116340637207), (3, 1.5032490491867065), (4, 1.4991742372512817), (5, 1.4961014986038208), (6, 1.4919936656951904), (7, 1.4872305393218994), (8, 1.4860711097717285), (9, 1.488295555114746), (10, 1.4874175786972046)]
INFO flwr 2024-04-26 19:25:52,405 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.1152), (1, 0.5435), (2, 0.8344), (3, 0.958), (4, 0.9624), (5, 0.965), (6, 0.9691), (7, 0.9736), (8, 0.9753), (9, 0.9727), (10, 0.9738)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.9738
wandb:     loss 1.48742
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_192249-rzojf77n
wandb: Find logs at: ./wandb/offline-run-20240426_192249-rzojf77n/logs
INFO flwr 2024-04-26 19:25:56,136 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 32
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 10
		Optimizer: FedAdam
			local: {'lr': 0.1}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(1, 28, 28) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: CNN
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
			    (1): ReLU()
			    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
			    (3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
			    (4): ReLU()
			    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
			    (6): Flatten(start_dim=1, end_dim=-1)
			    (7): Linear(in_features=3136, out_features=512, bias=True)
			    (8): ReLU()
			    (9): Linear(in_features=512, out_features=10, bias=True)
			    (10): Softmax(dim=-1)
			  )
			)
Using the latest cached version of the dataset since mnist couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'mnist' at .cache/mnist/mnist/1.0.0/b06aab39e05f7bcd9635d18ed25d06eae523c574 (last modified on Tue Apr  2 18:09:57 2024).
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 19:33:28,108 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=207862)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 2x across cluster][0m
[2m[36m(DefaultActor pid=207862)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 2x across cluster][0m
2024-04-26 19:33:33,133	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 19:33:33,525	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 19:33:33,843	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 19:33:33,845	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 19:33:45,076 | app.py:213 | Flower VCE: Ray initialized with resources: {'object_store_memory': 73863387955.0, 'CPU': 64.0, 'GPU': 1.0, 'node:__internal_head__': 1.0, 'node:10.20.240.12': 1.0, 'accelerator_type:TITAN': 1.0, 'memory': 162347905229.0}
INFO flwr 2024-04-26 19:33:45,076 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 19:33:45,077 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 19:33:45,108 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 19:33:45,109 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 19:33:45,110 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 19:33:45,110 | server.py:91 | Evaluating initial parameters
[2m[36m(pid=221852)[0m 2024-04-26 19:33:51.326078: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=221852)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=221852)[0m 2024-04-26 19:33:53.669292: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
INFO flwr 2024-04-26 19:33:54,369 | server.py:94 | initial parameters (loss, other metrics): 2.3025691509246826, {'accuracy': 0.1088, 'data_size': 10000}
INFO flwr 2024-04-26 19:33:54,369 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 19:33:54,370 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(DefaultActor pid=221855)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=221855)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=221847)[0m 2024-04-26 19:33:51.474448: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=221847)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=221847)[0m 2024-04-26 19:33:53.819594: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=221849)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 6x across cluster][0m
[2m[36m(DefaultActor pid=221849)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 6x across cluster][0m
DEBUG flwr 2024-04-26 19:34:12,160 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 19:34:16,631 | server.py:125 | fit progress: (1, 2.285792589187622, {'accuracy': 0.1684, 'data_size': 10000}, 22.262049553999532)
INFO flwr 2024-04-26 19:34:16,632 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 19:34:16,632 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:34:26,511 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 19:34:31,153 | server.py:125 | fit progress: (2, 1.8894912004470825, {'accuracy': 0.5714, 'data_size': 10000}, 36.78369675399881)
INFO flwr 2024-04-26 19:34:31,153 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 19:34:31,154 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:34:40,194 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 19:34:44,793 | server.py:125 | fit progress: (3, 1.5844142436981201, {'accuracy': 0.8765, 'data_size': 10000}, 50.423851555999136)
INFO flwr 2024-04-26 19:34:44,794 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 19:34:44,794 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:34:53,436 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 19:34:58,064 | server.py:125 | fit progress: (4, 1.5447942018508911, {'accuracy': 0.9163, 'data_size': 10000}, 63.6944148199982)
INFO flwr 2024-04-26 19:34:58,064 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 19:34:58,065 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:35:06,842 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 19:35:11,454 | server.py:125 | fit progress: (5, 1.5296834707260132, {'accuracy': 0.9313, 'data_size': 10000}, 77.08418515800076)
INFO flwr 2024-04-26 19:35:11,454 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 19:35:11,454 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:35:20,048 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 19:35:24,618 | server.py:125 | fit progress: (6, 1.5147125720977783, {'accuracy': 0.9466, 'data_size': 10000}, 90.24839796800006)
INFO flwr 2024-04-26 19:35:24,618 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 19:35:24,618 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:35:33,559 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 19:35:37,958 | server.py:125 | fit progress: (7, 1.505995273590088, {'accuracy': 0.9554, 'data_size': 10000}, 103.58808772399789)
INFO flwr 2024-04-26 19:35:37,958 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 19:35:37,958 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:35:47,322 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 19:35:51,721 | server.py:125 | fit progress: (8, 1.5019240379333496, {'accuracy': 0.9592, 'data_size': 10000}, 117.35176777999732)
INFO flwr 2024-04-26 19:35:51,721 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 19:35:51,722 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:36:00,827 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 19:36:05,326 | server.py:125 | fit progress: (9, 1.495498538017273, {'accuracy': 0.9653, 'data_size': 10000}, 130.95675212499918)
INFO flwr 2024-04-26 19:36:05,326 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 19:36:05,327 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:36:14,366 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 19:36:18,974 | server.py:125 | fit progress: (10, 1.4970309734344482, {'accuracy': 0.9641, 'data_size': 10000}, 144.6046247919985)
INFO flwr 2024-04-26 19:36:18,974 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 19:36:18,974 | server.py:153 | FL finished in 144.60508033699807
INFO flwr 2024-04-26 19:36:18,977 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 19:36:18,977 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 19:36:18,978 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 19:36:18,978 | app.py:229 | app_fit: losses_centralized [(0, 2.3025691509246826), (1, 2.285792589187622), (2, 1.8894912004470825), (3, 1.5844142436981201), (4, 1.5447942018508911), (5, 1.5296834707260132), (6, 1.5147125720977783), (7, 1.505995273590088), (8, 1.5019240379333496), (9, 1.495498538017273), (10, 1.4970309734344482)]
INFO flwr 2024-04-26 19:36:18,978 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.1088), (1, 0.1684), (2, 0.5714), (3, 0.8765), (4, 0.9163), (5, 0.9313), (6, 0.9466), (7, 0.9554), (8, 0.9592), (9, 0.9653), (10, 0.9641)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.9641
wandb:     loss 1.49703
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_193327-ko8s11x8
wandb: Find logs at: ./wandb/offline-run-20240426_193327-ko8s11x8/logs
INFO flwr 2024-04-26 19:36:22,646 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 32
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 10
		Optimizer: FedAdam
			local: {'lr': 0.15}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(1, 28, 28) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: CNN
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
			    (1): ReLU()
			    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
			    (3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
			    (4): ReLU()
			    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
			    (6): Flatten(start_dim=1, end_dim=-1)
			    (7): Linear(in_features=3136, out_features=512, bias=True)
			    (8): ReLU()
			    (9): Linear(in_features=512, out_features=10, bias=True)
			    (10): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 19:36:23,373 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=221847)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=221847)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
2024-04-26 19:36:28,224	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 19:36:28,550	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 19:36:28,870	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 19:36:28,872	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 19:36:40,114 | app.py:213 | Flower VCE: Ray initialized with resources: {'CPU': 64.0, 'node:__internal_head__': 1.0, 'node:10.20.240.12': 1.0, 'GPU': 1.0, 'object_store_memory': 73937204428.0, 'accelerator_type:TITAN': 1.0, 'memory': 162520143668.0}
INFO flwr 2024-04-26 19:36:40,115 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 19:36:40,115 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 19:36:40,130 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 19:36:40,131 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 19:36:40,131 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 19:36:40,131 | server.py:91 | Evaluating initial parameters
[2m[36m(pid=225555)[0m 2024-04-26 19:36:46.415544: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=225555)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=225555)[0m 2024-04-26 19:36:48.751399: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
INFO flwr 2024-04-26 19:36:49,558 | server.py:94 | initial parameters (loss, other metrics): 2.302553415298462, {'accuracy': 0.1028, 'data_size': 10000}
INFO flwr 2024-04-26 19:36:49,558 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 19:36:49,559 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(DefaultActor pid=225562)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=225562)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=225553)[0m 2024-04-26 19:36:46.567100: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=225553)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=225559)[0m 2024-04-26 19:36:48.844093: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=225553)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 5x across cluster][0m
[2m[36m(DefaultActor pid=225553)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 5x across cluster][0m
DEBUG flwr 2024-04-26 19:37:06,576 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 19:37:11,336 | server.py:125 | fit progress: (1, 2.135789394378662, {'accuracy': 0.3189, 'data_size': 10000}, 21.777335726001184)
INFO flwr 2024-04-26 19:37:11,336 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 19:37:11,336 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:37:21,095 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 19:37:25,550 | server.py:125 | fit progress: (2, 2.3016855716705322, {'accuracy': 0.1581, 'data_size': 10000}, 35.991710419999436)
INFO flwr 2024-04-26 19:37:25,551 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 19:37:25,551 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:37:33,714 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 19:37:38,324 | server.py:125 | fit progress: (3, 2.3719422817230225, {'accuracy': 0.0892, 'data_size': 10000}, 48.765360041998065)
INFO flwr 2024-04-26 19:37:38,324 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 19:37:38,324 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:37:47,366 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 19:37:52,014 | server.py:125 | fit progress: (4, 2.3719422817230225, {'accuracy': 0.0892, 'data_size': 10000}, 62.45539856499818)
INFO flwr 2024-04-26 19:37:52,014 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 19:37:52,014 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:38:00,572 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 19:38:05,203 | server.py:125 | fit progress: (5, 2.3719422817230225, {'accuracy': 0.0892, 'data_size': 10000}, 75.64432889700038)
INFO flwr 2024-04-26 19:38:05,203 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 19:38:05,204 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:38:14,024 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 19:38:18,707 | server.py:125 | fit progress: (6, 2.3719422817230225, {'accuracy': 0.0892, 'data_size': 10000}, 89.14895406099822)
INFO flwr 2024-04-26 19:38:18,708 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 19:38:18,708 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:38:27,746 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 19:38:32,414 | server.py:125 | fit progress: (7, 2.3719422817230225, {'accuracy': 0.0892, 'data_size': 10000}, 102.85581127099795)
INFO flwr 2024-04-26 19:38:32,415 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 19:38:32,415 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:38:41,210 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 19:38:45,813 | server.py:125 | fit progress: (8, 2.3719422817230225, {'accuracy': 0.0892, 'data_size': 10000}, 116.2544129079979)
INFO flwr 2024-04-26 19:38:45,813 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 19:38:45,814 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:38:54,842 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 19:38:59,526 | server.py:125 | fit progress: (9, 2.3719422817230225, {'accuracy': 0.0892, 'data_size': 10000}, 129.96754162800062)
INFO flwr 2024-04-26 19:38:59,527 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 19:38:59,527 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:39:08,354 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 19:39:12,775 | server.py:125 | fit progress: (10, 2.3719422817230225, {'accuracy': 0.0892, 'data_size': 10000}, 143.21637899299822)
INFO flwr 2024-04-26 19:39:12,775 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 19:39:12,775 | server.py:153 | FL finished in 143.2168530300005
INFO flwr 2024-04-26 19:39:12,784 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 19:39:12,784 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 19:39:12,784 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 19:39:12,784 | app.py:229 | app_fit: losses_centralized [(0, 2.302553415298462), (1, 2.135789394378662), (2, 2.3016855716705322), (3, 2.3719422817230225), (4, 2.3719422817230225), (5, 2.3719422817230225), (6, 2.3719422817230225), (7, 2.3719422817230225), (8, 2.3719422817230225), (9, 2.3719422817230225), (10, 2.3719422817230225)]
INFO flwr 2024-04-26 19:39:12,784 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.1028), (1, 0.3189), (2, 0.1581), (3, 0.0892), (4, 0.0892), (5, 0.0892), (6, 0.0892), (7, 0.0892), (8, 0.0892), (9, 0.0892), (10, 0.0892)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.0892
wandb:     loss 2.37194
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_193622-bq7duopt
wandb: Find logs at: ./wandb/offline-run-20240426_193622-bq7duopt/logs
INFO flwr 2024-04-26 19:39:16,514 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 32
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 10
		Optimizer: FedAdam
			local: {'lr': 0.2}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(1, 28, 28) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: CNN
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
			    (1): ReLU()
			    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
			    (3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
			    (4): ReLU()
			    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
			    (6): Flatten(start_dim=1, end_dim=-1)
			    (7): Linear(in_features=3136, out_features=512, bias=True)
			    (8): ReLU()
			    (9): Linear(in_features=512, out_features=10, bias=True)
			    (10): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 19:39:17,721 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=225550)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 2x across cluster][0m
[2m[36m(DefaultActor pid=225550)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 2x across cluster][0m
2024-04-26 19:39:24,310	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 19:39:24,757	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 19:39:25,089	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 19:39:25,090	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 19:39:36,370 | app.py:213 | Flower VCE: Ray initialized with resources: {'CPU': 64.0, 'object_store_memory': 76415029248.0, 'GPU': 1.0, 'node:__internal_head__': 1.0, 'node:10.20.240.12': 1.0, 'memory': 168301734912.0, 'accelerator_type:TITAN': 1.0}
INFO flwr 2024-04-26 19:39:36,370 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 19:39:36,370 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 19:39:36,385 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 19:39:36,386 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 19:39:36,386 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 19:39:36,386 | server.py:91 | Evaluating initial parameters
[2m[36m(pid=231757)[0m 2024-04-26 19:39:42.625711: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=231757)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=231757)[0m 2024-04-26 19:39:44.957392: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
INFO flwr 2024-04-26 19:39:46,047 | server.py:94 | initial parameters (loss, other metrics): 2.302480459213257, {'accuracy': 0.0621, 'data_size': 10000}
INFO flwr 2024-04-26 19:39:46,048 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 19:39:46,048 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(DefaultActor pid=231765)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=231765)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=231756)[0m 2024-04-26 19:39:42.993274: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=231756)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=231756)[0m 2024-04-26 19:39:45.310540: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=231757)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 5x across cluster][0m
[2m[36m(DefaultActor pid=231757)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 5x across cluster][0m
DEBUG flwr 2024-04-26 19:40:03,472 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 19:40:08,209 | server.py:125 | fit progress: (1, 2.0238332748413086, {'accuracy': 0.437, 'data_size': 10000}, 22.161182616000588)
INFO flwr 2024-04-26 19:40:08,209 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 19:40:08,210 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:40:18,027 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 19:40:22,690 | server.py:125 | fit progress: (2, 1.6368727684020996, {'accuracy': 0.8244, 'data_size': 10000}, 36.64162327699887)
INFO flwr 2024-04-26 19:40:22,690 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 19:40:22,690 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:40:31,417 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 19:40:36,026 | server.py:125 | fit progress: (3, 1.5189162492752075, {'accuracy': 0.9426, 'data_size': 10000}, 49.97755986300035)
INFO flwr 2024-04-26 19:40:36,026 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 19:40:36,026 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:40:45,093 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 19:40:49,781 | server.py:125 | fit progress: (4, 1.5308969020843506, {'accuracy': 0.9304, 'data_size': 10000}, 63.733110944001965)
INFO flwr 2024-04-26 19:40:49,781 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 19:40:49,782 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:40:58,640 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 19:41:03,277 | server.py:125 | fit progress: (5, 1.5109093189239502, {'accuracy': 0.9496, 'data_size': 10000}, 77.22891422199973)
INFO flwr 2024-04-26 19:41:03,277 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 19:41:03,277 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:41:12,548 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 19:41:17,114 | server.py:125 | fit progress: (6, 1.494852066040039, {'accuracy': 0.9661, 'data_size': 10000}, 91.06626847900043)
INFO flwr 2024-04-26 19:41:17,115 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 19:41:17,115 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:41:26,021 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 19:41:30,647 | server.py:125 | fit progress: (7, 1.4958090782165527, {'accuracy': 0.9656, 'data_size': 10000}, 104.59910551299981)
INFO flwr 2024-04-26 19:41:30,647 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 19:41:30,648 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:41:39,587 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 19:41:44,254 | server.py:125 | fit progress: (8, 1.4903894662857056, {'accuracy': 0.9708, 'data_size': 10000}, 118.20606603399938)
INFO flwr 2024-04-26 19:41:44,254 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 19:41:44,255 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:41:52,954 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 19:41:57,730 | server.py:125 | fit progress: (9, 1.4933582544326782, {'accuracy': 0.9678, 'data_size': 10000}, 131.68237284600036)
INFO flwr 2024-04-26 19:41:57,731 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 19:41:57,731 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:42:06,261 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 19:42:10,754 | server.py:125 | fit progress: (10, 1.4900898933410645, {'accuracy': 0.9712, 'data_size': 10000}, 144.70622961700064)
INFO flwr 2024-04-26 19:42:10,755 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 19:42:10,755 | server.py:153 | FL finished in 144.70671468500223
INFO flwr 2024-04-26 19:42:10,758 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 19:42:10,758 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 19:42:10,758 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 19:42:10,759 | app.py:229 | app_fit: losses_centralized [(0, 2.302480459213257), (1, 2.0238332748413086), (2, 1.6368727684020996), (3, 1.5189162492752075), (4, 1.5308969020843506), (5, 1.5109093189239502), (6, 1.494852066040039), (7, 1.4958090782165527), (8, 1.4903894662857056), (9, 1.4933582544326782), (10, 1.4900898933410645)]
INFO flwr 2024-04-26 19:42:10,759 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0621), (1, 0.437), (2, 0.8244), (3, 0.9426), (4, 0.9304), (5, 0.9496), (6, 0.9661), (7, 0.9656), (8, 0.9708), (9, 0.9678), (10, 0.9712)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.9712
wandb:     loss 1.49009
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_193916-03awrowj
wandb: Find logs at: ./wandb/offline-run-20240426_193916-03awrowj/logs
[2m[36m(DefaultActor pid=231755)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 2x across cluster][0m
[2m[36m(DefaultActor pid=231755)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 2x across cluster][0m
2024-04-26 19:43:17.985526: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-04-26 19:43:19.151944: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
INFO flwr 2024-04-26 19:43:25,064 | batch_run_simulation.py:80 | Loaded 24 configs with name MINST-LOGISTICREGRESSION-FEDADAM, running...
INFO flwr 2024-04-26 19:43:25,064 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 1
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 10
		Optimizer: FedAdam
			local: {'lr': 0.05}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: Logistic Regression
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=10, bias=True)
			    (1): Softmax(dim=-1)
			  )
			)
Using the latest cached version of the dataset since mnist couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'mnist' at .cache/mnist/mnist/1.0.0/b06aab39e05f7bcd9635d18ed25d06eae523c574 (last modified on Tue Apr  2 18:09:57 2024).
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 19:50:39,903 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
2024-04-26 19:50:42,548	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 19:50:42,932	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 19:50:43,260	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 19:50:43,261	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 19:50:54,505 | app.py:213 | Flower VCE: Ray initialized with resources: {'GPU': 1.0, 'CPU': 64.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0, 'memory': 162854929408.0, 'accelerator_type:TITAN': 1.0, 'object_store_memory': 74080684032.0}
INFO flwr 2024-04-26 19:50:54,505 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 19:50:54,506 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 19:50:54,521 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 19:50:54,522 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 19:50:54,522 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 19:50:54,523 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 19:50:58,522 | server.py:94 | initial parameters (loss, other metrics): 2.3044753074645996, {'accuracy': 0.0654, 'data_size': 10000}
INFO flwr 2024-04-26 19:50:58,522 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 19:50:58,523 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=246808)[0m 2024-04-26 19:51:00.726978: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=246808)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=246803)[0m 2024-04-26 19:51:03.052827: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=246808)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=246808)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=246805)[0m 2024-04-26 19:51:00.855931: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)[0m
[2m[36m(pid=246805)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=246809)[0m 2024-04-26 19:51:03.276541: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 19:51:34,100 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 19:51:35,571 | server.py:125 | fit progress: (1, 2.2496821880340576, {'accuracy': 0.5631, 'data_size': 10000}, 37.04863764799666)
INFO flwr 2024-04-26 19:51:35,572 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 19:51:35,572 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:51:58,677 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 19:52:00,182 | server.py:125 | fit progress: (2, 2.1555097103118896, {'accuracy': 0.6664, 'data_size': 10000}, 61.6592294209986)
INFO flwr 2024-04-26 19:52:00,182 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 19:52:00,183 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:52:22,973 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 19:52:24,528 | server.py:125 | fit progress: (3, 2.0507936477661133, {'accuracy': 0.6897, 'data_size': 10000}, 86.00517233499704)
INFO flwr 2024-04-26 19:52:24,528 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 19:52:24,529 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:52:46,324 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 19:52:47,872 | server.py:125 | fit progress: (4, 1.9603406190872192, {'accuracy': 0.7033, 'data_size': 10000}, 109.34891104799681)
INFO flwr 2024-04-26 19:52:47,872 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 19:52:47,872 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:53:09,641 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 19:53:11,107 | server.py:125 | fit progress: (5, 1.8871965408325195, {'accuracy': 0.7311, 'data_size': 10000}, 132.58427183799722)
INFO flwr 2024-04-26 19:53:11,107 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 19:53:11,108 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:53:34,572 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 19:53:36,064 | server.py:125 | fit progress: (6, 1.8295167684555054, {'accuracy': 0.7562, 'data_size': 10000}, 157.54096253799798)
INFO flwr 2024-04-26 19:53:36,064 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 19:53:36,064 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:53:56,301 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 19:53:57,792 | server.py:125 | fit progress: (7, 1.7822619676589966, {'accuracy': 0.782, 'data_size': 10000}, 179.26881384599983)
INFO flwr 2024-04-26 19:53:57,792 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 19:53:57,792 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:54:18,181 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 19:54:19,435 | server.py:125 | fit progress: (8, 1.7429777383804321, {'accuracy': 0.8029, 'data_size': 10000}, 200.91264912399856)
INFO flwr 2024-04-26 19:54:19,436 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 19:54:19,436 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:54:43,255 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 19:54:44,742 | server.py:125 | fit progress: (9, 1.712902545928955, {'accuracy': 0.8124, 'data_size': 10000}, 226.21895747399685)
INFO flwr 2024-04-26 19:54:44,742 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 19:54:44,742 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:55:07,656 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 19:55:09,185 | server.py:125 | fit progress: (10, 1.689797282218933, {'accuracy': 0.8224, 'data_size': 10000}, 250.6618826729973)
INFO flwr 2024-04-26 19:55:09,185 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 19:55:09,185 | server.py:153 | FL finished in 250.66249991899895
INFO flwr 2024-04-26 19:55:09,186 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 19:55:09,186 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 19:55:09,186 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 19:55:09,187 | app.py:229 | app_fit: losses_centralized [(0, 2.3044753074645996), (1, 2.2496821880340576), (2, 2.1555097103118896), (3, 2.0507936477661133), (4, 1.9603406190872192), (5, 1.8871965408325195), (6, 1.8295167684555054), (7, 1.7822619676589966), (8, 1.7429777383804321), (9, 1.712902545928955), (10, 1.689797282218933)]
INFO flwr 2024-04-26 19:55:09,187 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0654), (1, 0.5631), (2, 0.6664), (3, 0.6897), (4, 0.7033), (5, 0.7311), (6, 0.7562), (7, 0.782), (8, 0.8029), (9, 0.8124), (10, 0.8224)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.8224
wandb:     loss 1.6898
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_195039-rgl43raw
wandb: Find logs at: ./wandb/offline-run-20240426_195039-rgl43raw/logs
INFO flwr 2024-04-26 19:55:12,921 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 1
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 10
		Optimizer: FedAdam
			local: {'lr': 0.1}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: Logistic Regression
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=10, bias=True)
			    (1): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 19:55:13,629 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=246800)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=246800)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 19:55:18,193	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 19:55:18,549	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 19:55:18,870	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 19:55:18,872	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 19:55:30,125 | app.py:213 | Flower VCE: Ray initialized with resources: {'object_store_memory': 75945251635.0, 'GPU': 1.0, 'CPU': 64.0, 'node:__internal_head__': 1.0, 'node:10.20.240.12': 1.0, 'memory': 167205587149.0, 'accelerator_type:TITAN': 1.0}
INFO flwr 2024-04-26 19:55:30,125 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 19:55:30,125 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 19:55:30,140 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 19:55:30,142 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 19:55:30,142 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 19:55:30,142 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 19:55:33,216 | server.py:94 | initial parameters (loss, other metrics): 2.3022866249084473, {'accuracy': 0.1039, 'data_size': 10000}
INFO flwr 2024-04-26 19:55:33,217 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 19:55:33,218 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=250552)[0m 2024-04-26 19:55:36.488388: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=250552)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=250552)[0m 2024-04-26 19:55:39.768628: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=250550)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=250550)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=250550)[0m 2024-04-26 19:55:36.638844: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=250550)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=250551)[0m 2024-04-26 19:55:39.768303: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 19:56:18,291 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 19:56:19,774 | server.py:125 | fit progress: (1, 2.248094081878662, {'accuracy': 0.4343, 'data_size': 10000}, 46.555900313000166)
INFO flwr 2024-04-26 19:56:19,774 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 19:56:19,775 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:56:41,958 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 19:56:43,508 | server.py:125 | fit progress: (2, 2.160597562789917, {'accuracy': 0.6363, 'data_size': 10000}, 70.28962440800024)
INFO flwr 2024-04-26 19:56:43,508 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 19:56:43,508 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:57:05,345 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 19:57:06,905 | server.py:125 | fit progress: (3, 2.0620787143707275, {'accuracy': 0.7019, 'data_size': 10000}, 93.68704037100179)
INFO flwr 2024-04-26 19:57:06,906 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 19:57:06,906 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:57:26,693 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 19:57:28,254 | server.py:125 | fit progress: (4, 1.969442367553711, {'accuracy': 0.7355, 'data_size': 10000}, 115.03567294000095)
INFO flwr 2024-04-26 19:57:28,254 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 19:57:28,254 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:57:50,037 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 19:57:51,536 | server.py:125 | fit progress: (5, 1.8905426263809204, {'accuracy': 0.7592, 'data_size': 10000}, 138.31731966000007)
INFO flwr 2024-04-26 19:57:51,536 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 19:57:51,536 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:58:15,554 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 19:58:17,060 | server.py:125 | fit progress: (6, 1.8279622793197632, {'accuracy': 0.7773, 'data_size': 10000}, 163.84151931400265)
INFO flwr 2024-04-26 19:58:17,060 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 19:58:17,060 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:58:38,055 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 19:58:39,628 | server.py:125 | fit progress: (7, 1.7794603109359741, {'accuracy': 0.7925, 'data_size': 10000}, 186.40940224800215)
INFO flwr 2024-04-26 19:58:39,628 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 19:58:39,628 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:59:01,259 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 19:59:02,806 | server.py:125 | fit progress: (8, 1.7418971061706543, {'accuracy': 0.807, 'data_size': 10000}, 209.58744179300265)
INFO flwr 2024-04-26 19:59:02,806 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 19:59:02,806 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:59:27,934 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 19:59:29,498 | server.py:125 | fit progress: (9, 1.7127857208251953, {'accuracy': 0.817, 'data_size': 10000}, 236.28010397300022)
INFO flwr 2024-04-26 19:59:29,499 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 19:59:29,499 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 19:59:51,467 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 19:59:53,098 | server.py:125 | fit progress: (10, 1.6876320838928223, {'accuracy': 0.8314, 'data_size': 10000}, 259.8796288000012)
INFO flwr 2024-04-26 19:59:53,098 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 19:59:53,098 | server.py:153 | FL finished in 259.880062704
INFO flwr 2024-04-26 19:59:53,098 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 19:59:53,099 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 19:59:53,099 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 19:59:53,099 | app.py:229 | app_fit: losses_centralized [(0, 2.3022866249084473), (1, 2.248094081878662), (2, 2.160597562789917), (3, 2.0620787143707275), (4, 1.969442367553711), (5, 1.8905426263809204), (6, 1.8279622793197632), (7, 1.7794603109359741), (8, 1.7418971061706543), (9, 1.7127857208251953), (10, 1.6876320838928223)]
INFO flwr 2024-04-26 19:59:53,099 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.1039), (1, 0.4343), (2, 0.6363), (3, 0.7019), (4, 0.7355), (5, 0.7592), (6, 0.7773), (7, 0.7925), (8, 0.807), (9, 0.817), (10, 0.8314)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.8314
wandb:     loss 1.68763
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_195513-v7alb3r4
wandb: Find logs at: ./wandb/offline-run-20240426_195513-v7alb3r4/logs
INFO flwr 2024-04-26 19:59:56,879 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 1
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 10
		Optimizer: FedAdam
			local: {'lr': 0.2}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: Logistic Regression
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=10, bias=True)
			    (1): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 19:59:57,553 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=250553)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=250553)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 20:00:02,490	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 20:00:02,990	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 20:00:03,339	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 20:00:03,341	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 20:00:14,545 | app.py:213 | Flower VCE: Ray initialized with resources: {'node:__internal_head__': 1.0, 'node:10.20.240.12': 1.0, 'memory': 161964033024.0, 'accelerator_type:TITAN': 1.0, 'object_store_memory': 73698871296.0, 'GPU': 1.0, 'CPU': 64.0}
INFO flwr 2024-04-26 20:00:14,545 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 20:00:14,545 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 20:00:14,561 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 20:00:14,562 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 20:00:14,562 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 20:00:14,562 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 20:00:17,250 | server.py:94 | initial parameters (loss, other metrics): 2.302816867828369, {'accuracy': 0.0734, 'data_size': 10000}
INFO flwr 2024-04-26 20:00:17,250 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 20:00:17,250 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=261639)[0m 2024-04-26 20:00:20.861221: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=261639)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=261639)[0m 2024-04-26 20:00:23.232580: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=261642)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=261642)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=261645)[0m 2024-04-26 20:00:21.052639: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=261645)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=261645)[0m 2024-04-26 20:00:23.417823: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 20:00:55,723 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 20:00:57,060 | server.py:125 | fit progress: (1, 2.248034715652466, {'accuracy': 0.6479, 'data_size': 10000}, 39.80964925800072)
INFO flwr 2024-04-26 20:00:57,060 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 20:00:57,060 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:01:16,664 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 20:01:18,182 | server.py:125 | fit progress: (2, 2.1511070728302, {'accuracy': 0.8074, 'data_size': 10000}, 60.93177880000076)
INFO flwr 2024-04-26 20:01:18,182 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 20:01:18,183 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:01:38,927 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 20:01:40,478 | server.py:125 | fit progress: (3, 2.0333282947540283, {'accuracy': 0.8254, 'data_size': 10000}, 83.2281151520001)
INFO flwr 2024-04-26 20:01:40,479 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 20:01:40,479 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:02:03,287 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 20:02:04,656 | server.py:125 | fit progress: (4, 1.9309675693511963, {'accuracy': 0.8228, 'data_size': 10000}, 107.4060987720004)
INFO flwr 2024-04-26 20:02:04,657 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 20:02:04,657 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:02:24,781 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 20:02:26,108 | server.py:125 | fit progress: (5, 1.8566484451293945, {'accuracy': 0.819, 'data_size': 10000}, 128.85782921899954)
INFO flwr 2024-04-26 20:02:26,108 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 20:02:26,109 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:02:46,534 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 20:02:48,095 | server.py:125 | fit progress: (6, 1.8041609525680542, {'accuracy': 0.814, 'data_size': 10000}, 150.84449997800039)
INFO flwr 2024-04-26 20:02:48,095 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 20:02:48,095 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:03:11,909 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 20:03:13,478 | server.py:125 | fit progress: (7, 1.766281247138977, {'accuracy': 0.8129, 'data_size': 10000}, 176.22746941700098)
INFO flwr 2024-04-26 20:03:13,478 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 20:03:13,478 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:03:36,109 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 20:03:37,608 | server.py:125 | fit progress: (8, 1.738037347793579, {'accuracy': 0.8123, 'data_size': 10000}, 200.35808999000074)
INFO flwr 2024-04-26 20:03:37,609 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 20:03:37,609 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:04:01,949 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 20:04:03,466 | server.py:125 | fit progress: (9, 1.7185028791427612, {'accuracy': 0.8116, 'data_size': 10000}, 226.21580039699984)
INFO flwr 2024-04-26 20:04:03,466 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 20:04:03,467 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:04:25,983 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 20:04:27,498 | server.py:125 | fit progress: (10, 1.7026786804199219, {'accuracy': 0.8112, 'data_size': 10000}, 250.24749468500158)
INFO flwr 2024-04-26 20:04:27,498 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 20:04:27,498 | server.py:153 | FL finished in 250.24792890400204
INFO flwr 2024-04-26 20:04:27,498 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 20:04:27,498 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 20:04:27,498 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 20:04:27,499 | app.py:229 | app_fit: losses_centralized [(0, 2.302816867828369), (1, 2.248034715652466), (2, 2.1511070728302), (3, 2.0333282947540283), (4, 1.9309675693511963), (5, 1.8566484451293945), (6, 1.8041609525680542), (7, 1.766281247138977), (8, 1.738037347793579), (9, 1.7185028791427612), (10, 1.7026786804199219)]
INFO flwr 2024-04-26 20:04:27,499 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0734), (1, 0.6479), (2, 0.8074), (3, 0.8254), (4, 0.8228), (5, 0.819), (6, 0.814), (7, 0.8129), (8, 0.8123), (9, 0.8116), (10, 0.8112)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.8112
wandb:     loss 1.70268
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_195957-ch48b4av
wandb: Find logs at: ./wandb/offline-run-20240426_195957-ch48b4av/logs
INFO flwr 2024-04-26 20:04:31,209 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 1
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 20
		Optimizer: FedAdam
			local: {'lr': 0.05}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: Logistic Regression
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=10, bias=True)
			    (1): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 20:04:31,860 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=261639)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=261639)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 20:04:37,504	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 20:04:37,835	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 20:04:38,163	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 20:04:38,164	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 20:04:49,403 | app.py:213 | Flower VCE: Ray initialized with resources: {'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0, 'CPU': 64.0, 'GPU': 1.0, 'memory': 161968792576.0, 'accelerator_type:TITAN': 1.0, 'object_store_memory': 73700911104.0}
INFO flwr 2024-04-26 20:04:49,404 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 20:04:49,404 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 20:04:49,419 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 20:04:49,420 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 20:04:49,420 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 20:04:49,421 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 20:04:52,949 | server.py:94 | initial parameters (loss, other metrics): 2.304152250289917, {'accuracy': 0.0948, 'data_size': 10000}
INFO flwr 2024-04-26 20:04:52,949 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 20:04:52,950 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=270135)[0m 2024-04-26 20:04:55.617031: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=270135)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=270135)[0m 2024-04-26 20:04:57.984911: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=270138)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=270138)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=270138)[0m 2024-04-26 20:04:55.891888: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=270138)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=270145)[0m 2024-04-26 20:04:58.426930: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 20:05:45,673 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 20:05:47,013 | server.py:125 | fit progress: (1, 2.2527260780334473, {'accuracy': 0.4495, 'data_size': 10000}, 54.06392025899913)
INFO flwr 2024-04-26 20:05:47,014 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 20:05:47,014 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:06:30,920 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 20:06:32,197 | server.py:125 | fit progress: (2, 2.1646242141723633, {'accuracy': 0.6206, 'data_size': 10000}, 99.2474954720019)
INFO flwr 2024-04-26 20:06:32,197 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 20:06:32,197 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:07:15,542 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 20:07:16,850 | server.py:125 | fit progress: (3, 2.059950590133667, {'accuracy': 0.7168, 'data_size': 10000}, 143.90015192200008)
INFO flwr 2024-04-26 20:07:16,850 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 20:07:16,850 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:07:57,466 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 20:07:58,990 | server.py:125 | fit progress: (4, 1.9641122817993164, {'accuracy': 0.7578, 'data_size': 10000}, 186.0408306829995)
INFO flwr 2024-04-26 20:07:58,991 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 20:07:58,991 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:08:39,456 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 20:08:40,993 | server.py:125 | fit progress: (5, 1.8877837657928467, {'accuracy': 0.7744, 'data_size': 10000}, 228.04329128999962)
INFO flwr 2024-04-26 20:08:40,993 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 20:08:40,993 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:09:23,384 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 20:09:24,955 | server.py:125 | fit progress: (6, 1.827380657196045, {'accuracy': 0.786, 'data_size': 10000}, 272.0056848860004)
INFO flwr 2024-04-26 20:09:24,955 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 20:09:24,956 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:10:01,746 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 20:10:03,228 | server.py:125 | fit progress: (7, 1.780197024345398, {'accuracy': 0.7969, 'data_size': 10000}, 310.2789562479993)
INFO flwr 2024-04-26 20:10:03,229 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 20:10:03,229 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:10:45,761 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 20:10:47,285 | server.py:125 | fit progress: (8, 1.7425509691238403, {'accuracy': 0.8092, 'data_size': 10000}, 354.33521770100197)
INFO flwr 2024-04-26 20:10:47,285 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 20:10:47,285 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:11:29,885 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 20:11:31,398 | server.py:125 | fit progress: (9, 1.715023398399353, {'accuracy': 0.8182, 'data_size': 10000}, 398.4490269119997)
INFO flwr 2024-04-26 20:11:31,399 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 20:11:31,399 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:12:11,351 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 20:12:12,907 | server.py:125 | fit progress: (10, 1.6909877061843872, {'accuracy': 0.8278, 'data_size': 10000}, 439.95783478700105)
INFO flwr 2024-04-26 20:12:12,908 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 20:12:12,908 | server.py:153 | FL finished in 439.958328181001
INFO flwr 2024-04-26 20:12:12,908 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 20:12:12,908 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 20:12:12,908 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 20:12:12,908 | app.py:229 | app_fit: losses_centralized [(0, 2.304152250289917), (1, 2.2527260780334473), (2, 2.1646242141723633), (3, 2.059950590133667), (4, 1.9641122817993164), (5, 1.8877837657928467), (6, 1.827380657196045), (7, 1.780197024345398), (8, 1.7425509691238403), (9, 1.715023398399353), (10, 1.6909877061843872)]
INFO flwr 2024-04-26 20:12:12,909 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0948), (1, 0.4495), (2, 0.6206), (3, 0.7168), (4, 0.7578), (5, 0.7744), (6, 0.786), (7, 0.7969), (8, 0.8092), (9, 0.8182), (10, 0.8278)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.8278
wandb:     loss 1.69099
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_200431-jivmld3n
wandb: Find logs at: ./wandb/offline-run-20240426_200431-jivmld3n/logs
INFO flwr 2024-04-26 20:12:16,649 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 1
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 20
		Optimizer: FedAdam
			local: {'lr': 0.1}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: Logistic Regression
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=10, bias=True)
			    (1): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 20:12:17,309 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=270135)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=270135)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 20:12:22,363	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 20:12:22,836	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 20:12:23,314	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 20:12:23,315	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 20:12:34,467 | app.py:213 | Flower VCE: Ray initialized with resources: {'GPU': 1.0, 'CPU': 64.0, 'object_store_memory': 74296315084.0, 'accelerator_type:TITAN': 1.0, 'memory': 163358068532.0, 'node:__internal_head__': 1.0, 'node:10.20.240.12': 1.0}
INFO flwr 2024-04-26 20:12:34,468 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 20:12:34,468 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 20:12:34,485 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 20:12:34,486 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 20:12:34,487 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 20:12:34,487 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 20:12:37,270 | server.py:94 | initial parameters (loss, other metrics): 2.3035645484924316, {'accuracy': 0.0768, 'data_size': 10000}
INFO flwr 2024-04-26 20:12:37,271 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 20:12:37,271 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=281107)[0m 2024-04-26 20:12:40.789082: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=281107)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=281107)[0m 2024-04-26 20:12:43.178054: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=281107)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=281107)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=281109)[0m 2024-04-26 20:12:41.022668: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=281109)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=281109)[0m 2024-04-26 20:12:43.309982: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 20:13:31,644 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 20:13:32,938 | server.py:125 | fit progress: (1, 2.248494863510132, {'accuracy': 0.5781, 'data_size': 10000}, 55.66648463599995)
INFO flwr 2024-04-26 20:13:32,938 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 20:13:32,938 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:14:13,550 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 20:14:15,094 | server.py:125 | fit progress: (2, 2.1571125984191895, {'accuracy': 0.6585, 'data_size': 10000}, 97.82329399100126)
INFO flwr 2024-04-26 20:14:15,095 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 20:14:15,095 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:14:50,667 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 20:14:52,200 | server.py:125 | fit progress: (3, 2.0537540912628174, {'accuracy': 0.7199, 'data_size': 10000}, 134.9293914450027)
INFO flwr 2024-04-26 20:14:52,201 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 20:14:52,201 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:15:32,978 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 20:15:34,516 | server.py:125 | fit progress: (4, 1.963260531425476, {'accuracy': 0.7307, 'data_size': 10000}, 177.24471081500087)
INFO flwr 2024-04-26 20:15:34,516 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 20:15:34,516 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:16:12,731 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 20:16:14,270 | server.py:125 | fit progress: (5, 1.8912765979766846, {'accuracy': 0.7409, 'data_size': 10000}, 216.99870556400128)
INFO flwr 2024-04-26 20:16:14,270 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 20:16:14,270 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:16:52,789 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 20:16:54,303 | server.py:125 | fit progress: (6, 1.833506464958191, {'accuracy': 0.7598, 'data_size': 10000}, 257.0318708040031)
INFO flwr 2024-04-26 20:16:54,303 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 20:16:54,304 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:17:29,307 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 20:17:30,589 | server.py:125 | fit progress: (7, 1.7905185222625732, {'accuracy': 0.7717, 'data_size': 10000}, 293.31753884400314)
INFO flwr 2024-04-26 20:17:30,589 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 20:17:30,589 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:18:15,634 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 20:18:17,173 | server.py:125 | fit progress: (8, 1.7617107629776, {'accuracy': 0.7747, 'data_size': 10000}, 339.9015949470013)
INFO flwr 2024-04-26 20:18:17,173 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 20:18:17,173 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:18:56,754 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 20:18:58,323 | server.py:125 | fit progress: (9, 1.7379542589187622, {'accuracy': 0.7824, 'data_size': 10000}, 381.0521579410015)
INFO flwr 2024-04-26 20:18:58,324 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 20:18:58,324 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:19:40,198 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 20:19:41,717 | server.py:125 | fit progress: (10, 1.7188340425491333, {'accuracy': 0.7875, 'data_size': 10000}, 424.4457313510029)
INFO flwr 2024-04-26 20:19:41,717 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 20:19:41,717 | server.py:153 | FL finished in 424.44622975899983
INFO flwr 2024-04-26 20:19:41,718 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 20:19:41,718 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 20:19:41,718 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 20:19:41,718 | app.py:229 | app_fit: losses_centralized [(0, 2.3035645484924316), (1, 2.248494863510132), (2, 2.1571125984191895), (3, 2.0537540912628174), (4, 1.963260531425476), (5, 1.8912765979766846), (6, 1.833506464958191), (7, 1.7905185222625732), (8, 1.7617107629776), (9, 1.7379542589187622), (10, 1.7188340425491333)]
INFO flwr 2024-04-26 20:19:41,718 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0768), (1, 0.5781), (2, 0.6585), (3, 0.7199), (4, 0.7307), (5, 0.7409), (6, 0.7598), (7, 0.7717), (8, 0.7747), (9, 0.7824), (10, 0.7875)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.7875
wandb:     loss 1.71883
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_201216-9ft8a7sz
wandb: Find logs at: ./wandb/offline-run-20240426_201216-9ft8a7sz/logs
INFO flwr 2024-04-26 20:19:45,402 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 1
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 20
		Optimizer: FedAdam
			local: {'lr': 0.2}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: Logistic Regression
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=10, bias=True)
			    (1): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 20:19:46,775 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=281105)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=281105)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 20:19:52,626	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 20:19:52,940	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 20:19:53,276	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 20:19:53,277	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 20:20:04,652 | app.py:213 | Flower VCE: Ray initialized with resources: {'memory': 167751960781.0, 'accelerator_type:TITAN': 1.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0, 'object_store_memory': 76179411763.0, 'CPU': 64.0, 'GPU': 1.0}
INFO flwr 2024-04-26 20:20:04,653 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 20:20:04,653 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 20:20:04,668 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 20:20:04,669 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 20:20:04,669 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 20:20:04,670 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 20:20:07,969 | server.py:94 | initial parameters (loss, other metrics): 2.304069757461548, {'accuracy': 0.0882, 'data_size': 10000}
INFO flwr 2024-04-26 20:20:07,970 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 20:20:07,970 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=290886)[0m 2024-04-26 20:20:11.102734: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=290886)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=290886)[0m 2024-04-26 20:20:13.380779: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=290885)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=290885)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=290887)[0m 2024-04-26 20:20:11.190817: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=290887)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=290890)[0m 2024-04-26 20:20:13.634443: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 20:20:59,951 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 20:21:01,472 | server.py:125 | fit progress: (1, 2.2496423721313477, {'accuracy': 0.67, 'data_size': 10000}, 53.50252270400233)
INFO flwr 2024-04-26 20:21:01,473 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 20:21:01,473 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:21:43,019 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 20:21:44,584 | server.py:125 | fit progress: (2, 2.153761148452759, {'accuracy': 0.7199, 'data_size': 10000}, 96.61405575400204)
INFO flwr 2024-04-26 20:21:44,584 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 20:21:44,584 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:22:27,027 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 20:22:28,586 | server.py:125 | fit progress: (3, 2.045384407043457, {'accuracy': 0.732, 'data_size': 10000}, 140.61628752999968)
INFO flwr 2024-04-26 20:22:28,586 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 20:22:28,587 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:23:12,421 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 20:23:13,914 | server.py:125 | fit progress: (4, 1.9533054828643799, {'accuracy': 0.743, 'data_size': 10000}, 185.9439626429994)
INFO flwr 2024-04-26 20:23:13,914 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 20:23:13,914 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:23:55,312 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 20:23:56,841 | server.py:125 | fit progress: (5, 1.8865082263946533, {'accuracy': 0.7423, 'data_size': 10000}, 228.8710818670006)
INFO flwr 2024-04-26 20:23:56,841 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 20:23:56,842 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:24:40,456 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 20:24:41,988 | server.py:125 | fit progress: (6, 1.8370859622955322, {'accuracy': 0.7484, 'data_size': 10000}, 274.01839610500247)
INFO flwr 2024-04-26 20:24:41,989 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 20:24:41,989 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:25:19,330 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 20:25:20,916 | server.py:125 | fit progress: (7, 1.7991379499435425, {'accuracy': 0.7617, 'data_size': 10000}, 312.94613351000226)
INFO flwr 2024-04-26 20:25:20,916 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 20:25:20,917 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:25:59,007 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 20:26:00,529 | server.py:125 | fit progress: (8, 1.7684242725372314, {'accuracy': 0.7724, 'data_size': 10000}, 352.55887918200096)
INFO flwr 2024-04-26 20:26:00,529 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 20:26:00,529 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:26:41,115 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 20:26:42,644 | server.py:125 | fit progress: (9, 1.7425804138183594, {'accuracy': 0.7845, 'data_size': 10000}, 394.67385024100076)
INFO flwr 2024-04-26 20:26:42,644 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 20:26:42,644 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:27:24,015 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 20:27:25,556 | server.py:125 | fit progress: (10, 1.7214136123657227, {'accuracy': 0.7925, 'data_size': 10000}, 437.58651498900144)
INFO flwr 2024-04-26 20:27:25,557 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 20:27:25,557 | server.py:153 | FL finished in 437.58695489599995
INFO flwr 2024-04-26 20:27:25,557 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 20:27:25,557 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 20:27:25,557 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 20:27:25,557 | app.py:229 | app_fit: losses_centralized [(0, 2.304069757461548), (1, 2.2496423721313477), (2, 2.153761148452759), (3, 2.045384407043457), (4, 1.9533054828643799), (5, 1.8865082263946533), (6, 1.8370859622955322), (7, 1.7991379499435425), (8, 1.7684242725372314), (9, 1.7425804138183594), (10, 1.7214136123657227)]
INFO flwr 2024-04-26 20:27:25,558 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0882), (1, 0.67), (2, 0.7199), (3, 0.732), (4, 0.743), (5, 0.7423), (6, 0.7484), (7, 0.7617), (8, 0.7724), (9, 0.7845), (10, 0.7925)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.7925
wandb:     loss 1.72141
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_201945-bmi44xdj
wandb: Find logs at: ./wandb/offline-run-20240426_201945-bmi44xdj/logs
INFO flwr 2024-04-26 20:27:29,264 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 2
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 10
		Optimizer: FedAdam
			local: {'lr': 0.05}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: Logistic Regression
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=10, bias=True)
			    (1): Softmax(dim=-1)
			  )
			)
Using the latest cached version of the dataset since mnist couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'mnist' at .cache/mnist/mnist/1.0.0/b06aab39e05f7bcd9635d18ed25d06eae523c574 (last modified on Tue Apr  2 18:09:57 2024).
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 20:34:43,570 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=290878)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=290878)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 20:34:47,961	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 20:34:48,289	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 20:34:48,644	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 20:34:48,645	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 20:34:59,847 | app.py:213 | Flower VCE: Ray initialized with resources: {'object_store_memory': 75146883072.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0, 'GPU': 1.0, 'memory': 165342727168.0, 'accelerator_type:TITAN': 1.0, 'CPU': 64.0}
INFO flwr 2024-04-26 20:34:59,847 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 20:34:59,848 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 20:34:59,863 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 20:34:59,864 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 20:34:59,864 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 20:34:59,865 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 20:35:02,666 | server.py:94 | initial parameters (loss, other metrics): 2.299149513244629, {'accuracy': 0.1618, 'data_size': 10000}
INFO flwr 2024-04-26 20:35:02,666 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 20:35:02,668 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=305386)[0m 2024-04-26 20:35:06.077434: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=305386)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=305395)[0m 2024-04-26 20:35:08.357790: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=305389)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=305389)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=305392)[0m 2024-04-26 20:35:06.544292: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=305392)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=305392)[0m 2024-04-26 20:35:09.149191: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 20:35:32,298 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 20:35:33,819 | server.py:125 | fit progress: (1, 2.2412288188934326, {'accuracy': 0.5747, 'data_size': 10000}, 31.15236992300197)
INFO flwr 2024-04-26 20:35:33,819 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 20:35:33,820 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:35:51,468 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 20:35:52,986 | server.py:125 | fit progress: (2, 2.1434624195098877, {'accuracy': 0.6513, 'data_size': 10000}, 50.319188919002045)
INFO flwr 2024-04-26 20:35:52,986 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 20:35:52,986 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:36:06,529 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 20:36:08,057 | server.py:125 | fit progress: (3, 2.0383450984954834, {'accuracy': 0.6862, 'data_size': 10000}, 65.3900724640007)
INFO flwr 2024-04-26 20:36:08,057 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 20:36:08,057 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:36:21,818 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 20:36:23,299 | server.py:125 | fit progress: (4, 1.9438738822937012, {'accuracy': 0.7316, 'data_size': 10000}, 80.63271704699946)
INFO flwr 2024-04-26 20:36:23,300 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 20:36:23,300 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:36:37,744 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 20:36:39,308 | server.py:125 | fit progress: (5, 1.867789626121521, {'accuracy': 0.7517, 'data_size': 10000}, 96.64117334600087)
INFO flwr 2024-04-26 20:36:39,308 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 20:36:39,308 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:36:52,427 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 20:36:53,941 | server.py:125 | fit progress: (6, 1.808618187904358, {'accuracy': 0.7693, 'data_size': 10000}, 111.2738596320014)
INFO flwr 2024-04-26 20:36:53,941 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 20:36:53,941 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:37:07,682 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 20:37:09,260 | server.py:125 | fit progress: (7, 1.7621246576309204, {'accuracy': 0.7848, 'data_size': 10000}, 126.59354285700101)
INFO flwr 2024-04-26 20:37:09,261 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 20:37:09,261 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:37:21,600 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 20:37:23,133 | server.py:125 | fit progress: (8, 1.7264865636825562, {'accuracy': 0.7994, 'data_size': 10000}, 140.46638127700135)
INFO flwr 2024-04-26 20:37:23,133 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 20:37:23,134 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:37:37,541 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 20:37:39,036 | server.py:125 | fit progress: (9, 1.697147250175476, {'accuracy': 0.8186, 'data_size': 10000}, 156.36959199000194)
INFO flwr 2024-04-26 20:37:39,037 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 20:37:39,037 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:37:53,347 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 20:37:54,921 | server.py:125 | fit progress: (10, 1.6715035438537598, {'accuracy': 0.8388, 'data_size': 10000}, 172.2540176319999)
INFO flwr 2024-04-26 20:37:54,921 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 20:37:54,921 | server.py:153 | FL finished in 172.25446280400138
INFO flwr 2024-04-26 20:37:54,921 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 20:37:54,921 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 20:37:54,922 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 20:37:54,922 | app.py:229 | app_fit: losses_centralized [(0, 2.299149513244629), (1, 2.2412288188934326), (2, 2.1434624195098877), (3, 2.0383450984954834), (4, 1.9438738822937012), (5, 1.867789626121521), (6, 1.808618187904358), (7, 1.7621246576309204), (8, 1.7264865636825562), (9, 1.697147250175476), (10, 1.6715035438537598)]
INFO flwr 2024-04-26 20:37:54,922 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.1618), (1, 0.5747), (2, 0.6513), (3, 0.6862), (4, 0.7316), (5, 0.7517), (6, 0.7693), (7, 0.7848), (8, 0.7994), (9, 0.8186), (10, 0.8388)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.8388
wandb:     loss 1.6715
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_203443-qy1dfc6q
wandb: Find logs at: ./wandb/offline-run-20240426_203443-qy1dfc6q/logs
INFO flwr 2024-04-26 20:37:58,725 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 2
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 10
		Optimizer: FedAdam
			local: {'lr': 0.1}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: Logistic Regression
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=10, bias=True)
			    (1): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 20:37:59,517 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=305384)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=305384)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 20:38:04,166	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 20:38:04,490	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 20:38:04,818	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 20:38:04,819	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 20:38:16,070 | app.py:213 | Flower VCE: Ray initialized with resources: {'CPU': 64.0, 'GPU': 1.0, 'node:__internal_head__': 1.0, 'node:10.20.240.12': 1.0, 'object_store_memory': 74289490329.0, 'memory': 163342144103.0, 'accelerator_type:TITAN': 1.0}
INFO flwr 2024-04-26 20:38:16,071 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 20:38:16,071 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 20:38:16,088 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 20:38:16,089 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 20:38:16,089 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 20:38:16,089 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 20:38:18,644 | server.py:94 | initial parameters (loss, other metrics): 2.3048603534698486, {'accuracy': 0.098, 'data_size': 10000}
INFO flwr 2024-04-26 20:38:18,644 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 20:38:18,644 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=309217)[0m 2024-04-26 20:38:22.473644: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=309217)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=309217)[0m 2024-04-26 20:38:24.817074: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=309217)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=309217)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=309211)[0m 2024-04-26 20:38:22.688959: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=309211)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=309212)[0m 2024-04-26 20:38:24.971882: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 20:38:48,694 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 20:38:49,988 | server.py:125 | fit progress: (1, 2.2516322135925293, {'accuracy': 0.5111, 'data_size': 10000}, 31.343500276001578)
INFO flwr 2024-04-26 20:38:49,988 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 20:38:49,988 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:39:04,048 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 20:39:05,355 | server.py:125 | fit progress: (2, 2.1592633724212646, {'accuracy': 0.6927, 'data_size': 10000}, 46.710496403000434)
INFO flwr 2024-04-26 20:39:05,355 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 20:39:05,355 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:39:18,105 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 20:39:19,642 | server.py:125 | fit progress: (3, 2.0460457801818848, {'accuracy': 0.764, 'data_size': 10000}, 60.99751735300015)
INFO flwr 2024-04-26 20:39:19,642 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 20:39:19,642 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:39:33,319 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 20:39:34,848 | server.py:125 | fit progress: (4, 1.9478753805160522, {'accuracy': 0.7799, 'data_size': 10000}, 76.20425670300028)
INFO flwr 2024-04-26 20:39:34,849 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 20:39:34,849 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:39:48,599 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 20:39:50,135 | server.py:125 | fit progress: (5, 1.8711650371551514, {'accuracy': 0.7923, 'data_size': 10000}, 91.49105599500035)
INFO flwr 2024-04-26 20:39:50,136 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 20:39:50,136 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:40:04,024 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 20:40:05,546 | server.py:125 | fit progress: (6, 1.8141357898712158, {'accuracy': 0.7975, 'data_size': 10000}, 106.90140089999841)
INFO flwr 2024-04-26 20:40:05,546 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 20:40:05,546 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:40:19,770 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 20:40:21,391 | server.py:125 | fit progress: (7, 1.768608808517456, {'accuracy': 0.8066, 'data_size': 10000}, 122.74680916500074)
INFO flwr 2024-04-26 20:40:21,391 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 20:40:21,392 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:40:35,189 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 20:40:36,729 | server.py:125 | fit progress: (8, 1.7310616970062256, {'accuracy': 0.8198, 'data_size': 10000}, 138.08517317400037)
INFO flwr 2024-04-26 20:40:36,730 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 20:40:36,730 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:40:50,821 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 20:40:52,360 | server.py:125 | fit progress: (9, 1.6996320486068726, {'accuracy': 0.8318, 'data_size': 10000}, 153.71548112899836)
INFO flwr 2024-04-26 20:40:52,360 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 20:40:52,360 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:41:06,346 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 20:41:07,935 | server.py:125 | fit progress: (10, 1.6744601726531982, {'accuracy': 0.844, 'data_size': 10000}, 169.29083192300095)
INFO flwr 2024-04-26 20:41:07,935 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 20:41:07,935 | server.py:153 | FL finished in 169.2913122200007
INFO flwr 2024-04-26 20:41:07,936 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 20:41:07,936 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 20:41:07,936 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 20:41:07,936 | app.py:229 | app_fit: losses_centralized [(0, 2.3048603534698486), (1, 2.2516322135925293), (2, 2.1592633724212646), (3, 2.0460457801818848), (4, 1.9478753805160522), (5, 1.8711650371551514), (6, 1.8141357898712158), (7, 1.768608808517456), (8, 1.7310616970062256), (9, 1.6996320486068726), (10, 1.6744601726531982)]
INFO flwr 2024-04-26 20:41:07,936 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.098), (1, 0.5111), (2, 0.6927), (3, 0.764), (4, 0.7799), (5, 0.7923), (6, 0.7975), (7, 0.8066), (8, 0.8198), (9, 0.8318), (10, 0.844)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.844
wandb:     loss 1.67446
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_203759-bj3corb6
wandb: Find logs at: ./wandb/offline-run-20240426_203759-bj3corb6/logs
INFO flwr 2024-04-26 20:41:14,753 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 2
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 10
		Optimizer: FedAdam
			local: {'lr': 0.2}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: Logistic Regression
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=10, bias=True)
			    (1): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 20:41:15,492 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=309209)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=309209)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 20:41:20,445	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 20:41:20,779	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 20:41:21,138	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 20:41:21,139	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 20:41:32,373 | app.py:213 | Flower VCE: Ray initialized with resources: {'CPU': 64.0, 'node:__internal_head__': 1.0, 'node:10.20.240.12': 1.0, 'GPU': 1.0, 'object_store_memory': 74097571430.0, 'accelerator_type:TITAN': 1.0, 'memory': 162894333338.0}
INFO flwr 2024-04-26 20:41:32,373 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 20:41:32,373 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 20:41:32,388 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 20:41:32,389 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 20:41:32,389 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 20:41:32,390 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 20:41:35,252 | server.py:94 | initial parameters (loss, other metrics): 2.3016185760498047, {'accuracy': 0.1246, 'data_size': 10000}
INFO flwr 2024-04-26 20:41:35,252 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 20:41:35,253 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=316400)[0m 2024-04-26 20:41:38.692414: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=316400)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=316401)[0m 2024-04-26 20:41:41.022746: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=316405)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=316405)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=316408)[0m 2024-04-26 20:41:38.909530: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=316408)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=316408)[0m 2024-04-26 20:41:41.201476: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 20:42:04,044 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 20:42:05,539 | server.py:125 | fit progress: (1, 2.2460317611694336, {'accuracy': 0.4624, 'data_size': 10000}, 30.285903592000977)
INFO flwr 2024-04-26 20:42:05,539 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 20:42:05,539 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:42:20,152 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 20:42:21,459 | server.py:125 | fit progress: (2, 2.1566615104675293, {'accuracy': 0.6555, 'data_size': 10000}, 46.206427198998426)
INFO flwr 2024-04-26 20:42:21,459 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 20:42:21,460 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:42:36,405 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 20:42:37,683 | server.py:125 | fit progress: (3, 2.0556249618530273, {'accuracy': 0.6989, 'data_size': 10000}, 62.43033954400016)
INFO flwr 2024-04-26 20:42:37,683 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 20:42:37,683 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:42:53,106 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 20:42:54,405 | server.py:125 | fit progress: (4, 1.965135931968689, {'accuracy': 0.7181, 'data_size': 10000}, 79.15250387700144)
INFO flwr 2024-04-26 20:42:54,405 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 20:42:54,406 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:43:08,286 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 20:43:09,831 | server.py:125 | fit progress: (5, 1.893406629562378, {'accuracy': 0.7312, 'data_size': 10000}, 94.5787541259997)
INFO flwr 2024-04-26 20:43:09,832 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 20:43:09,832 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:43:23,931 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 20:43:25,443 | server.py:125 | fit progress: (6, 1.8373644351959229, {'accuracy': 0.7469, 'data_size': 10000}, 110.19055040999956)
INFO flwr 2024-04-26 20:43:25,444 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 20:43:25,444 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:43:38,284 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 20:43:39,808 | server.py:125 | fit progress: (7, 1.796067237854004, {'accuracy': 0.7568, 'data_size': 10000}, 124.55546988200149)
INFO flwr 2024-04-26 20:43:39,808 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 20:43:39,809 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:43:53,325 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 20:43:54,847 | server.py:125 | fit progress: (8, 1.7631725072860718, {'accuracy': 0.7643, 'data_size': 10000}, 139.59473262300162)
INFO flwr 2024-04-26 20:43:54,848 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 20:43:54,848 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:44:08,535 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 20:44:10,085 | server.py:125 | fit progress: (9, 1.7367392778396606, {'accuracy': 0.7744, 'data_size': 10000}, 154.83273921699947)
INFO flwr 2024-04-26 20:44:10,086 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 20:44:10,086 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:44:24,080 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 20:44:25,421 | server.py:125 | fit progress: (10, 1.714171051979065, {'accuracy': 0.7859, 'data_size': 10000}, 170.16877927099995)
INFO flwr 2024-04-26 20:44:25,422 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 20:44:25,422 | server.py:153 | FL finished in 170.16928039200138
INFO flwr 2024-04-26 20:44:25,422 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 20:44:25,422 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 20:44:25,422 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 20:44:25,423 | app.py:229 | app_fit: losses_centralized [(0, 2.3016185760498047), (1, 2.2460317611694336), (2, 2.1566615104675293), (3, 2.0556249618530273), (4, 1.965135931968689), (5, 1.893406629562378), (6, 1.8373644351959229), (7, 1.796067237854004), (8, 1.7631725072860718), (9, 1.7367392778396606), (10, 1.714171051979065)]
INFO flwr 2024-04-26 20:44:25,423 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.1246), (1, 0.4624), (2, 0.6555), (3, 0.6989), (4, 0.7181), (5, 0.7312), (6, 0.7469), (7, 0.7568), (8, 0.7643), (9, 0.7744), (10, 0.7859)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.7859
wandb:     loss 1.71417
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_204115-4bjmdwmg
wandb: Find logs at: ./wandb/offline-run-20240426_204115-4bjmdwmg/logs
INFO flwr 2024-04-26 20:44:28,666 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 2
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 20
		Optimizer: FedAdam
			local: {'lr': 0.05}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: Logistic Regression
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=10, bias=True)
			    (1): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 20:44:29,391 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=316400)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=316400)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 20:44:34,923	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 20:44:35,268	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 20:44:35,602	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 20:44:35,604	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 20:44:46,825 | app.py:213 | Flower VCE: Ray initialized with resources: {'GPU': 1.0, 'object_store_memory': 74821741363.0, 'memory': 164584063181.0, 'accelerator_type:TITAN': 1.0, 'CPU': 64.0, 'node:__internal_head__': 1.0, 'node:10.20.240.12': 1.0}
INFO flwr 2024-04-26 20:44:46,825 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 20:44:46,825 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 20:44:46,841 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 20:44:46,842 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 20:44:46,842 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 20:44:46,842 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 20:44:50,213 | server.py:94 | initial parameters (loss, other metrics): 2.3034725189208984, {'accuracy': 0.077, 'data_size': 10000}
INFO flwr 2024-04-26 20:44:50,214 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 20:44:50,214 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=322561)[0m 2024-04-26 20:44:53.032372: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=322561)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=322561)[0m 2024-04-26 20:44:55.344295: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=322556)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=322556)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=322554)[0m 2024-04-26 20:44:53.448806: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=322554)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=322554)[0m 2024-04-26 20:44:56.026596: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 20:45:26,712 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 20:45:28,248 | server.py:125 | fit progress: (1, 2.2488415241241455, {'accuracy': 0.581, 'data_size': 10000}, 38.03416504600318)
INFO flwr 2024-04-26 20:45:28,249 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 20:45:28,249 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:45:54,376 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 20:45:55,934 | server.py:125 | fit progress: (2, 2.152104616165161, {'accuracy': 0.6768, 'data_size': 10000}, 65.71965639800328)
INFO flwr 2024-04-26 20:45:55,934 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 20:45:55,935 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:46:18,351 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 20:46:19,879 | server.py:125 | fit progress: (3, 2.044621467590332, {'accuracy': 0.7039, 'data_size': 10000}, 89.6646492070031)
INFO flwr 2024-04-26 20:46:19,879 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 20:46:19,879 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:46:43,327 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 20:46:44,819 | server.py:125 | fit progress: (4, 1.9571558237075806, {'accuracy': 0.7213, 'data_size': 10000}, 114.60491390400057)
INFO flwr 2024-04-26 20:46:44,819 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 20:46:44,820 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:47:07,767 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 20:47:09,110 | server.py:125 | fit progress: (5, 1.8866890668869019, {'accuracy': 0.7449, 'data_size': 10000}, 138.89571182400323)
INFO flwr 2024-04-26 20:47:09,110 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 20:47:09,110 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:47:32,398 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 20:47:33,901 | server.py:125 | fit progress: (6, 1.8322086334228516, {'accuracy': 0.76, 'data_size': 10000}, 163.68696510300288)
INFO flwr 2024-04-26 20:47:33,902 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 20:47:33,902 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:47:56,616 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 20:47:58,124 | server.py:125 | fit progress: (7, 1.7881768941879272, {'accuracy': 0.7745, 'data_size': 10000}, 187.90957768700173)
INFO flwr 2024-04-26 20:47:58,124 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 20:47:58,124 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:48:19,863 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 20:48:21,344 | server.py:125 | fit progress: (8, 1.7517383098602295, {'accuracy': 0.7874, 'data_size': 10000}, 211.1297567870024)
INFO flwr 2024-04-26 20:48:21,344 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 20:48:21,345 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:48:45,831 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 20:48:47,383 | server.py:125 | fit progress: (9, 1.7208658456802368, {'accuracy': 0.801, 'data_size': 10000}, 237.16847964300177)
INFO flwr 2024-04-26 20:48:47,383 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 20:48:47,383 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:49:09,176 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 20:49:10,703 | server.py:125 | fit progress: (10, 1.6936689615249634, {'accuracy': 0.8167, 'data_size': 10000}, 260.48831204400267)
INFO flwr 2024-04-26 20:49:10,703 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 20:49:10,703 | server.py:153 | FL finished in 260.48873014700075
INFO flwr 2024-04-26 20:49:10,703 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 20:49:10,703 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 20:49:10,703 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 20:49:10,704 | app.py:229 | app_fit: losses_centralized [(0, 2.3034725189208984), (1, 2.2488415241241455), (2, 2.152104616165161), (3, 2.044621467590332), (4, 1.9571558237075806), (5, 1.8866890668869019), (6, 1.8322086334228516), (7, 1.7881768941879272), (8, 1.7517383098602295), (9, 1.7208658456802368), (10, 1.6936689615249634)]
INFO flwr 2024-04-26 20:49:10,704 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.077), (1, 0.581), (2, 0.6768), (3, 0.7039), (4, 0.7213), (5, 0.7449), (6, 0.76), (7, 0.7745), (8, 0.7874), (9, 0.801), (10, 0.8167)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.8167
wandb:     loss 1.69367
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_204428-cy3vqru4
wandb: Find logs at: ./wandb/offline-run-20240426_204428-cy3vqru4/logs
INFO flwr 2024-04-26 20:49:14,505 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 2
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 20
		Optimizer: FedAdam
			local: {'lr': 0.1}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: Logistic Regression
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=10, bias=True)
			    (1): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 20:49:15,162 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=322552)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=322552)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 20:49:20,025	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 20:49:20,363	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 20:49:20,691	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 20:49:20,692	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 20:49:31,988 | app.py:213 | Flower VCE: Ray initialized with resources: {'CPU': 64.0, 'memory': 164703639757.0, 'accelerator_type:TITAN': 1.0, 'GPU': 1.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0, 'object_store_memory': 74872988467.0}
INFO flwr 2024-04-26 20:49:31,988 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 20:49:31,989 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 20:49:32,004 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 20:49:32,005 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 20:49:32,005 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 20:49:32,005 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 20:49:34,927 | server.py:94 | initial parameters (loss, other metrics): 2.30568265914917, {'accuracy': 0.0528, 'data_size': 10000}
INFO flwr 2024-04-26 20:49:34,927 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 20:49:34,928 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=329390)[0m 2024-04-26 20:49:38.292072: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=329390)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=329459)[0m 2024-04-26 20:49:40.464382: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=329392)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=329392)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=329387)[0m 2024-04-26 20:49:38.610357: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=329387)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=329389)[0m 2024-04-26 20:49:41.069664: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 20:50:09,659 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 20:50:11,179 | server.py:125 | fit progress: (1, 2.251474380493164, {'accuracy': 0.5302, 'data_size': 10000}, 36.251427623999916)
INFO flwr 2024-04-26 20:50:11,179 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 20:50:11,180 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:50:33,039 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 20:50:34,528 | server.py:125 | fit progress: (2, 2.1546263694763184, {'accuracy': 0.6454, 'data_size': 10000}, 59.59990760900109)
INFO flwr 2024-04-26 20:50:34,528 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 20:50:34,528 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:50:56,531 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 20:50:58,083 | server.py:125 | fit progress: (3, 2.0466530323028564, {'accuracy': 0.6845, 'data_size': 10000}, 83.15580632199999)
INFO flwr 2024-04-26 20:50:58,084 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 20:50:58,084 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:51:21,067 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 20:51:22,554 | server.py:125 | fit progress: (4, 1.9559855461120605, {'accuracy': 0.7083, 'data_size': 10000}, 107.62596698999914)
INFO flwr 2024-04-26 20:51:22,554 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 20:51:22,554 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:51:46,847 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 20:51:48,405 | server.py:125 | fit progress: (5, 1.8892463445663452, {'accuracy': 0.7236, 'data_size': 10000}, 133.47693995699956)
INFO flwr 2024-04-26 20:51:48,405 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 20:51:48,405 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:52:09,316 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 20:52:10,829 | server.py:125 | fit progress: (6, 1.8388218879699707, {'accuracy': 0.7355, 'data_size': 10000}, 155.9009423819989)
INFO flwr 2024-04-26 20:52:10,829 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 20:52:10,829 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:52:33,844 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 20:52:35,359 | server.py:125 | fit progress: (7, 1.800173282623291, {'accuracy': 0.7482, 'data_size': 10000}, 180.43175123499896)
INFO flwr 2024-04-26 20:52:35,360 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 20:52:35,360 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:52:58,903 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 20:53:00,431 | server.py:125 | fit progress: (8, 1.7664366960525513, {'accuracy': 0.7663, 'data_size': 10000}, 205.50370538100105)
INFO flwr 2024-04-26 20:53:00,432 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 20:53:00,432 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:53:22,795 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 20:53:24,314 | server.py:125 | fit progress: (9, 1.734973430633545, {'accuracy': 0.7863, 'data_size': 10000}, 229.3865376319991)
INFO flwr 2024-04-26 20:53:24,314 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 20:53:24,315 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:53:44,443 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 20:53:45,950 | server.py:125 | fit progress: (10, 1.706246256828308, {'accuracy': 0.8052, 'data_size': 10000}, 251.02265136699862)
INFO flwr 2024-04-26 20:53:45,951 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 20:53:45,951 | server.py:153 | FL finished in 251.023206924001
INFO flwr 2024-04-26 20:53:45,951 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 20:53:45,951 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 20:53:45,952 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 20:53:45,952 | app.py:229 | app_fit: losses_centralized [(0, 2.30568265914917), (1, 2.251474380493164), (2, 2.1546263694763184), (3, 2.0466530323028564), (4, 1.9559855461120605), (5, 1.8892463445663452), (6, 1.8388218879699707), (7, 1.800173282623291), (8, 1.7664366960525513), (9, 1.734973430633545), (10, 1.706246256828308)]
INFO flwr 2024-04-26 20:53:45,952 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0528), (1, 0.5302), (2, 0.6454), (3, 0.6845), (4, 0.7083), (5, 0.7236), (6, 0.7355), (7, 0.7482), (8, 0.7663), (9, 0.7863), (10, 0.8052)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.8052
wandb:     loss 1.70625
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_204914-nucfz55q
wandb: Find logs at: ./wandb/offline-run-20240426_204914-nucfz55q/logs
INFO flwr 2024-04-26 20:53:49,613 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 2
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 20
		Optimizer: FedAdam
			local: {'lr': 0.2}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: Logistic Regression
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=10, bias=True)
			    (1): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 20:53:50,256 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=329387)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=329387)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 20:53:55,256	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 20:53:55,602	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 20:53:56,072	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 20:53:56,073	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 20:54:07,284 | app.py:213 | Flower VCE: Ray initialized with resources: {'GPU': 1.0, 'node:__internal_head__': 1.0, 'node:10.20.240.12': 1.0, 'CPU': 64.0, 'memory': 162932217652.0, 'accelerator_type:TITAN': 1.0, 'object_store_memory': 74113807564.0}
INFO flwr 2024-04-26 20:54:07,284 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 20:54:07,284 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 20:54:07,299 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 20:54:07,300 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 20:54:07,300 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 20:54:07,301 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 20:54:11,403 | server.py:94 | initial parameters (loss, other metrics): 2.3044581413269043, {'accuracy': 0.0625, 'data_size': 10000}
INFO flwr 2024-04-26 20:54:11,407 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 20:54:11,409 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=333217)[0m 2024-04-26 20:54:13.460838: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=333217)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=333217)[0m 2024-04-26 20:54:15.826647: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=333221)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=333221)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=333216)[0m 2024-04-26 20:54:13.736425: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=333216)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=333214)[0m 2024-04-26 20:54:15.913321: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 20:54:49,192 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 20:54:50,486 | server.py:125 | fit progress: (1, 2.250155448913574, {'accuracy': 0.4943, 'data_size': 10000}, 39.0777646830029)
INFO flwr 2024-04-26 20:54:50,487 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 20:54:50,487 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:55:15,319 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 20:55:16,843 | server.py:125 | fit progress: (2, 2.1593868732452393, {'accuracy': 0.6518, 'data_size': 10000}, 65.43475557900092)
INFO flwr 2024-04-26 20:55:16,844 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 20:55:16,844 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:55:40,970 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 20:55:42,497 | server.py:125 | fit progress: (3, 2.0568549633026123, {'accuracy': 0.7407, 'data_size': 10000}, 91.08855515799951)
INFO flwr 2024-04-26 20:55:42,497 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 20:55:42,498 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:56:04,615 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 20:56:05,874 | server.py:125 | fit progress: (4, 1.9648398160934448, {'accuracy': 0.7683, 'data_size': 10000}, 114.46569405700211)
INFO flwr 2024-04-26 20:56:05,875 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 20:56:05,875 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:56:26,745 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 20:56:28,042 | server.py:125 | fit progress: (5, 1.8900278806686401, {'accuracy': 0.7884, 'data_size': 10000}, 136.63326371400035)
INFO flwr 2024-04-26 20:56:28,042 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 20:56:28,042 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:56:51,880 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 20:56:53,360 | server.py:125 | fit progress: (6, 1.8315839767456055, {'accuracy': 0.799, 'data_size': 10000}, 161.95152860300004)
INFO flwr 2024-04-26 20:56:53,360 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 20:56:53,361 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:57:16,908 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 20:57:18,372 | server.py:125 | fit progress: (7, 1.7862653732299805, {'accuracy': 0.8045, 'data_size': 10000}, 186.96328783600256)
INFO flwr 2024-04-26 20:57:18,372 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 20:57:18,372 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:57:41,349 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 20:57:42,875 | server.py:125 | fit progress: (8, 1.7520238161087036, {'accuracy': 0.8087, 'data_size': 10000}, 211.46634990200255)
INFO flwr 2024-04-26 20:57:42,875 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 20:57:42,875 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:58:10,277 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 20:58:11,784 | server.py:125 | fit progress: (9, 1.7258957624435425, {'accuracy': 0.8123, 'data_size': 10000}, 240.37531793699964)
INFO flwr 2024-04-26 20:58:11,784 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 20:58:11,784 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:58:34,583 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 20:58:36,127 | server.py:125 | fit progress: (10, 1.705180048942566, {'accuracy': 0.8165, 'data_size': 10000}, 264.71868821700264)
INFO flwr 2024-04-26 20:58:36,127 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 20:58:36,128 | server.py:153 | FL finished in 264.7191291859999
INFO flwr 2024-04-26 20:58:36,128 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 20:58:36,128 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 20:58:36,128 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 20:58:36,128 | app.py:229 | app_fit: losses_centralized [(0, 2.3044581413269043), (1, 2.250155448913574), (2, 2.1593868732452393), (3, 2.0568549633026123), (4, 1.9648398160934448), (5, 1.8900278806686401), (6, 1.8315839767456055), (7, 1.7862653732299805), (8, 1.7520238161087036), (9, 1.7258957624435425), (10, 1.705180048942566)]
INFO flwr 2024-04-26 20:58:36,128 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0625), (1, 0.4943), (2, 0.6518), (3, 0.7407), (4, 0.7683), (5, 0.7884), (6, 0.799), (7, 0.8045), (8, 0.8087), (9, 0.8123), (10, 0.8165)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.8165
wandb:     loss 1.70518
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_205349-ebidrou0
wandb: Find logs at: ./wandb/offline-run-20240426_205349-ebidrou0/logs
INFO flwr 2024-04-26 20:58:39,777 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 8
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 10
		Optimizer: FedAdam
			local: {'lr': 0.05}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: Logistic Regression
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=10, bias=True)
			    (1): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 20:58:40,432 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=333214)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=333214)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 20:58:45,432	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 20:58:45,771	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 20:58:46,152	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 20:58:46,153	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 20:58:57,342 | app.py:213 | Flower VCE: Ray initialized with resources: {'GPU': 1.0, 'CPU': 64.0, 'memory': 166557579879.0, 'accelerator_type:TITAN': 1.0, 'node:__internal_head__': 1.0, 'node:10.20.240.12': 1.0, 'object_store_memory': 75667534233.0}
INFO flwr 2024-04-26 20:58:57,342 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 20:58:57,342 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 20:58:57,357 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 20:58:57,358 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 20:58:57,358 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 20:58:57,359 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 20:59:00,381 | server.py:94 | initial parameters (loss, other metrics): 2.3048858642578125, {'accuracy': 0.0696, 'data_size': 10000}
INFO flwr 2024-04-26 20:59:00,382 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 20:59:00,383 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=340034)[0m 2024-04-26 20:59:03.570837: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=340034)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=340034)[0m 2024-04-26 20:59:05.893919: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=340035)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=340035)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=340035)[0m 2024-04-26 20:59:03.811850: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=340035)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=340024)[0m 2024-04-26 20:59:06.005905: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 20:59:22,413 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 20:59:23,676 | server.py:125 | fit progress: (1, 2.2429494857788086, {'accuracy': 0.5407, 'data_size': 10000}, 23.293358489001548)
INFO flwr 2024-04-26 20:59:23,676 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 20:59:23,676 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:59:33,441 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 20:59:34,694 | server.py:125 | fit progress: (2, 2.139049768447876, {'accuracy': 0.6239, 'data_size': 10000}, 34.311884511000244)
INFO flwr 2024-04-26 20:59:34,695 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 20:59:34,695 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:59:44,022 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 20:59:45,316 | server.py:125 | fit progress: (3, 2.02872371673584, {'accuracy': 0.7013, 'data_size': 10000}, 44.933504024000285)
INFO flwr 2024-04-26 20:59:45,316 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 20:59:45,317 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 20:59:53,890 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 20:59:55,358 | server.py:125 | fit progress: (4, 1.9305611848831177, {'accuracy': 0.7538, 'data_size': 10000}, 54.9751664050018)
INFO flwr 2024-04-26 20:59:55,358 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 20:59:55,358 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:00:04,160 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 21:00:05,690 | server.py:125 | fit progress: (5, 1.848357081413269, {'accuracy': 0.7822, 'data_size': 10000}, 65.30739109099886)
INFO flwr 2024-04-26 21:00:05,690 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 21:00:05,690 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:00:14,808 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 21:00:16,346 | server.py:125 | fit progress: (6, 1.7817509174346924, {'accuracy': 0.8066, 'data_size': 10000}, 75.963879283001)
INFO flwr 2024-04-26 21:00:16,347 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 21:00:16,347 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:00:25,297 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 21:00:26,800 | server.py:125 | fit progress: (7, 1.7307566404342651, {'accuracy': 0.8281, 'data_size': 10000}, 86.4175075589992)
INFO flwr 2024-04-26 21:00:26,800 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 21:00:26,801 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:00:35,513 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 21:00:36,988 | server.py:125 | fit progress: (8, 1.6932342052459717, {'accuracy': 0.8429, 'data_size': 10000}, 96.60527965599977)
INFO flwr 2024-04-26 21:00:36,988 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 21:00:36,988 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:00:45,818 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 21:00:47,346 | server.py:125 | fit progress: (9, 1.6664718389511108, {'accuracy': 0.8532, 'data_size': 10000}, 106.963322986001)
INFO flwr 2024-04-26 21:00:47,346 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 21:00:47,346 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:00:56,422 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 21:00:57,923 | server.py:125 | fit progress: (10, 1.6474123001098633, {'accuracy': 0.8651, 'data_size': 10000}, 117.54034562400193)
INFO flwr 2024-04-26 21:00:57,923 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 21:00:57,923 | server.py:153 | FL finished in 117.54080942600194
INFO flwr 2024-04-26 21:00:57,924 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 21:00:57,924 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 21:00:57,943 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 21:00:57,943 | app.py:229 | app_fit: losses_centralized [(0, 2.3048858642578125), (1, 2.2429494857788086), (2, 2.139049768447876), (3, 2.02872371673584), (4, 1.9305611848831177), (5, 1.848357081413269), (6, 1.7817509174346924), (7, 1.7307566404342651), (8, 1.6932342052459717), (9, 1.6664718389511108), (10, 1.6474123001098633)]
INFO flwr 2024-04-26 21:00:57,943 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0696), (1, 0.5407), (2, 0.6239), (3, 0.7013), (4, 0.7538), (5, 0.7822), (6, 0.8066), (7, 0.8281), (8, 0.8429), (9, 0.8532), (10, 0.8651)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.8651
wandb:     loss 1.64741
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_205840-evzmxvco
wandb: Find logs at: ./wandb/offline-run-20240426_205840-evzmxvco/logs
INFO flwr 2024-04-26 21:01:01,614 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 8
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 10
		Optimizer: FedAdam
			local: {'lr': 0.1}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: Logistic Regression
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=10, bias=True)
			    (1): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 21:01:02,396 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=340024)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=340024)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 21:01:07,082	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 21:01:07,472	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 21:01:07,807	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 21:01:07,809	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 21:01:18,977 | app.py:213 | Flower VCE: Ray initialized with resources: {'object_store_memory': 75620195942.0, 'accelerator_type:TITAN': 1.0, 'memory': 166447123866.0, 'CPU': 64.0, 'GPU': 1.0, 'node:__internal_head__': 1.0, 'node:10.20.240.12': 1.0}
INFO flwr 2024-04-26 21:01:18,977 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 21:01:18,977 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 21:01:18,993 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 21:01:18,996 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 21:01:18,996 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 21:01:18,996 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 21:01:21,843 | server.py:94 | initial parameters (loss, other metrics): 2.3002538681030273, {'accuracy': 0.1356, 'data_size': 10000}
INFO flwr 2024-04-26 21:01:21,844 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 21:01:21,844 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=343820)[0m 2024-04-26 21:01:25.256960: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=343820)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=343820)[0m 2024-04-26 21:01:27.599354: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=343823)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=343823)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=343826)[0m 2024-04-26 21:01:25.512237: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=343826)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=343826)[0m 2024-04-26 21:01:27.793866: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 21:01:44,380 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 21:01:45,691 | server.py:125 | fit progress: (1, 2.2388699054718018, {'accuracy': 0.5734, 'data_size': 10000}, 23.84692847200131)
INFO flwr 2024-04-26 21:01:45,692 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 21:01:45,692 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:01:55,230 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 21:01:56,700 | server.py:125 | fit progress: (2, 2.1310272216796875, {'accuracy': 0.69, 'data_size': 10000}, 34.856177974001184)
INFO flwr 2024-04-26 21:01:56,701 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 21:01:56,701 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:02:05,500 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 21:02:07,025 | server.py:125 | fit progress: (3, 2.01889967918396, {'accuracy': 0.7045, 'data_size': 10000}, 45.180633142997976)
INFO flwr 2024-04-26 21:02:07,025 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 21:02:07,025 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:02:15,591 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 21:02:17,055 | server.py:125 | fit progress: (4, 1.9267923831939697, {'accuracy': 0.7175, 'data_size': 10000}, 55.21040703900144)
INFO flwr 2024-04-26 21:02:17,055 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 21:02:17,055 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:02:25,721 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 21:02:27,255 | server.py:125 | fit progress: (5, 1.8559670448303223, {'accuracy': 0.7354, 'data_size': 10000}, 65.41088869899977)
INFO flwr 2024-04-26 21:02:27,256 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 21:02:27,256 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:02:36,560 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 21:02:38,049 | server.py:125 | fit progress: (6, 1.8014001846313477, {'accuracy': 0.7574, 'data_size': 10000}, 76.20434787599879)
INFO flwr 2024-04-26 21:02:38,049 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 21:02:38,049 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:02:46,954 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 21:02:48,218 | server.py:125 | fit progress: (7, 1.757222294807434, {'accuracy': 0.7807, 'data_size': 10000}, 86.3736627319995)
INFO flwr 2024-04-26 21:02:48,218 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 21:02:48,218 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:02:57,178 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 21:02:58,644 | server.py:125 | fit progress: (8, 1.7186037302017212, {'accuracy': 0.8077, 'data_size': 10000}, 96.79992176800079)
INFO flwr 2024-04-26 21:02:58,644 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 21:02:58,645 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:03:07,795 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 21:03:09,257 | server.py:125 | fit progress: (9, 1.6857990026474, {'accuracy': 0.8321, 'data_size': 10000}, 107.41292978400088)
INFO flwr 2024-04-26 21:03:09,257 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 21:03:09,258 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:03:18,473 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 21:03:19,947 | server.py:125 | fit progress: (10, 1.658843994140625, {'accuracy': 0.8523, 'data_size': 10000}, 118.10260900899812)
INFO flwr 2024-04-26 21:03:19,947 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 21:03:19,947 | server.py:153 | FL finished in 118.10314582800129
INFO flwr 2024-04-26 21:03:19,948 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 21:03:19,948 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 21:03:19,948 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 21:03:19,948 | app.py:229 | app_fit: losses_centralized [(0, 2.3002538681030273), (1, 2.2388699054718018), (2, 2.1310272216796875), (3, 2.01889967918396), (4, 1.9267923831939697), (5, 1.8559670448303223), (6, 1.8014001846313477), (7, 1.757222294807434), (8, 1.7186037302017212), (9, 1.6857990026474), (10, 1.658843994140625)]
INFO flwr 2024-04-26 21:03:19,948 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.1356), (1, 0.5734), (2, 0.69), (3, 0.7045), (4, 0.7175), (5, 0.7354), (6, 0.7574), (7, 0.7807), (8, 0.8077), (9, 0.8321), (10, 0.8523)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.8523
wandb:     loss 1.65884
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_210101-ss3g3dn5
wandb: Find logs at: ./wandb/offline-run-20240426_210101-ss3g3dn5/logs
INFO flwr 2024-04-26 21:03:23,597 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 8
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 10
		Optimizer: FedAdam
			local: {'lr': 0.2}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: Logistic Regression
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=10, bias=True)
			    (1): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 21:03:24,326 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=343820)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=343820)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 21:03:29,428	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 21:03:29,759	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 21:03:30,090	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 21:03:30,091	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 21:03:41,196 | app.py:213 | Flower VCE: Ray initialized with resources: {'object_store_memory': 75628056576.0, 'memory': 166465465344.0, 'accelerator_type:TITAN': 1.0, 'GPU': 1.0, 'CPU': 64.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0}
INFO flwr 2024-04-26 21:03:41,196 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 21:03:41,197 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 21:03:41,213 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 21:03:41,214 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 21:03:41,214 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 21:03:41,214 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 21:03:44,697 | server.py:94 | initial parameters (loss, other metrics): 2.3023762702941895, {'accuracy': 0.0925, 'data_size': 10000}
INFO flwr 2024-04-26 21:03:44,698 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 21:03:44,698 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=346968)[0m 2024-04-26 21:03:47.424812: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=346968)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=346968)[0m 2024-04-26 21:03:49.720197: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=346971)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=346971)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=346964)[0m 2024-04-26 21:03:47.771498: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=346964)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=346964)[0m 2024-04-26 21:03:50.135731: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 21:04:06,157 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 21:04:07,689 | server.py:125 | fit progress: (1, 2.2446250915527344, {'accuracy': 0.632, 'data_size': 10000}, 22.990869036999356)
INFO flwr 2024-04-26 21:04:07,690 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 21:04:07,690 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:04:16,979 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 21:04:18,484 | server.py:125 | fit progress: (2, 2.14520001411438, {'accuracy': 0.7063, 'data_size': 10000}, 33.78581250299976)
INFO flwr 2024-04-26 21:04:18,484 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 21:04:18,485 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:04:27,274 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 21:04:28,822 | server.py:125 | fit progress: (3, 2.0327770709991455, {'accuracy': 0.7371, 'data_size': 10000}, 44.12344320899865)
INFO flwr 2024-04-26 21:04:28,822 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 21:04:28,822 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:04:37,444 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 21:04:38,934 | server.py:125 | fit progress: (4, 1.934826135635376, {'accuracy': 0.7554, 'data_size': 10000}, 54.23592099400048)
INFO flwr 2024-04-26 21:04:38,934 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 21:04:38,935 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:04:47,975 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 21:04:49,487 | server.py:125 | fit progress: (5, 1.8548269271850586, {'accuracy': 0.7767, 'data_size': 10000}, 64.78841079499762)
INFO flwr 2024-04-26 21:04:49,487 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 21:04:49,487 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:04:58,279 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 21:04:59,817 | server.py:125 | fit progress: (6, 1.7954281568527222, {'accuracy': 0.7948, 'data_size': 10000}, 75.1190924629991)
INFO flwr 2024-04-26 21:04:59,818 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 21:04:59,818 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:05:09,125 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 21:05:10,649 | server.py:125 | fit progress: (7, 1.7494269609451294, {'accuracy': 0.8144, 'data_size': 10000}, 85.95109115299783)
INFO flwr 2024-04-26 21:05:10,650 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 21:05:10,650 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:05:19,587 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 21:05:21,125 | server.py:125 | fit progress: (8, 1.712412714958191, {'accuracy': 0.8307, 'data_size': 10000}, 96.42671025699747)
INFO flwr 2024-04-26 21:05:21,125 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 21:05:21,125 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:05:30,009 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 21:05:31,519 | server.py:125 | fit progress: (9, 1.6823877096176147, {'accuracy': 0.8437, 'data_size': 10000}, 106.82075486699978)
INFO flwr 2024-04-26 21:05:31,519 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 21:05:31,519 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:05:40,257 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 21:05:41,766 | server.py:125 | fit progress: (10, 1.6568771600723267, {'accuracy': 0.8578, 'data_size': 10000}, 117.06805988499764)
INFO flwr 2024-04-26 21:05:41,767 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 21:05:41,767 | server.py:153 | FL finished in 117.06848339099815
INFO flwr 2024-04-26 21:05:41,767 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 21:05:41,767 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 21:05:41,767 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 21:05:41,767 | app.py:229 | app_fit: losses_centralized [(0, 2.3023762702941895), (1, 2.2446250915527344), (2, 2.14520001411438), (3, 2.0327770709991455), (4, 1.934826135635376), (5, 1.8548269271850586), (6, 1.7954281568527222), (7, 1.7494269609451294), (8, 1.712412714958191), (9, 1.6823877096176147), (10, 1.6568771600723267)]
INFO flwr 2024-04-26 21:05:41,767 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0925), (1, 0.632), (2, 0.7063), (3, 0.7371), (4, 0.7554), (5, 0.7767), (6, 0.7948), (7, 0.8144), (8, 0.8307), (9, 0.8437), (10, 0.8578)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.8578
wandb:     loss 1.65688
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_210323-n4rtbb2n
wandb: Find logs at: ./wandb/offline-run-20240426_210323-n4rtbb2n/logs
INFO flwr 2024-04-26 21:05:45,429 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 8
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 20
		Optimizer: FedAdam
			local: {'lr': 0.05}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: Logistic Regression
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=10, bias=True)
			    (1): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 21:05:46,297 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=346964)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=346964)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 21:05:51,086	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 21:05:51,547	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 21:05:51,882	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 21:05:51,884	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 21:06:02,963 | app.py:213 | Flower VCE: Ray initialized with resources: {'object_store_memory': 75834612940.0, 'GPU': 1.0, 'CPU': 64.0, 'memory': 166947430196.0, 'accelerator_type:TITAN': 1.0, 'node:__internal_head__': 1.0, 'node:10.20.240.12': 1.0}
INFO flwr 2024-04-26 21:06:02,963 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 21:06:02,963 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 21:06:02,978 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 21:06:02,979 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 21:06:02,980 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 21:06:02,980 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 21:06:05,848 | server.py:94 | initial parameters (loss, other metrics): 2.3067264556884766, {'accuracy': 0.0637, 'data_size': 10000}
INFO flwr 2024-04-26 21:06:05,848 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 21:06:05,849 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=353679)[0m 2024-04-26 21:06:09.274879: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=353679)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=353681)[0m 2024-04-26 21:06:11.629244: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=353680)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=353680)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=353683)[0m 2024-04-26 21:06:09.438635: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=353683)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=353683)[0m 2024-04-26 21:06:11.740005: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 21:06:30,517 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 21:06:31,814 | server.py:125 | fit progress: (1, 2.249835252761841, {'accuracy': 0.4405, 'data_size': 10000}, 25.9660299840034)
INFO flwr 2024-04-26 21:06:31,815 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 21:06:31,815 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:06:43,358 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 21:06:44,642 | server.py:125 | fit progress: (2, 2.158450126647949, {'accuracy': 0.591, 'data_size': 10000}, 38.793260177000775)
INFO flwr 2024-04-26 21:06:44,642 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 21:06:44,642 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:06:54,507 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 21:06:56,051 | server.py:125 | fit progress: (3, 2.0533885955810547, {'accuracy': 0.6666, 'data_size': 10000}, 50.202805708002415)
INFO flwr 2024-04-26 21:06:56,051 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 21:06:56,052 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:07:06,853 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 21:07:08,315 | server.py:125 | fit progress: (4, 1.9524421691894531, {'accuracy': 0.7137, 'data_size': 10000}, 62.466191729003185)
INFO flwr 2024-04-26 21:07:08,315 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 21:07:08,315 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:07:18,595 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 21:07:20,103 | server.py:125 | fit progress: (5, 1.8673365116119385, {'accuracy': 0.7492, 'data_size': 10000}, 74.25414752300276)
INFO flwr 2024-04-26 21:07:20,103 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 21:07:20,103 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:07:30,405 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 21:07:31,946 | server.py:125 | fit progress: (6, 1.7982043027877808, {'accuracy': 0.7881, 'data_size': 10000}, 86.09719014800066)
INFO flwr 2024-04-26 21:07:31,946 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 21:07:31,946 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:07:42,767 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 21:07:44,298 | server.py:125 | fit progress: (7, 1.7459784746170044, {'accuracy': 0.8092, 'data_size': 10000}, 98.44962813700113)
INFO flwr 2024-04-26 21:07:44,298 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 21:07:44,299 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:07:54,174 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 21:07:55,684 | server.py:125 | fit progress: (8, 1.7063541412353516, {'accuracy': 0.8306, 'data_size': 10000}, 109.83587337200152)
INFO flwr 2024-04-26 21:07:55,685 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 21:07:55,685 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:08:05,663 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 21:08:07,193 | server.py:125 | fit progress: (9, 1.677578330039978, {'accuracy': 0.8453, 'data_size': 10000}, 121.34422233200166)
INFO flwr 2024-04-26 21:08:07,193 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 21:08:07,193 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:08:18,121 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 21:08:19,613 | server.py:125 | fit progress: (10, 1.6538257598876953, {'accuracy': 0.8592, 'data_size': 10000}, 133.76475791900157)
INFO flwr 2024-04-26 21:08:19,613 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 21:08:19,614 | server.py:153 | FL finished in 133.76518371000202
INFO flwr 2024-04-26 21:08:19,614 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 21:08:19,614 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 21:08:19,614 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 21:08:19,614 | app.py:229 | app_fit: losses_centralized [(0, 2.3067264556884766), (1, 2.249835252761841), (2, 2.158450126647949), (3, 2.0533885955810547), (4, 1.9524421691894531), (5, 1.8673365116119385), (6, 1.7982043027877808), (7, 1.7459784746170044), (8, 1.7063541412353516), (9, 1.677578330039978), (10, 1.6538257598876953)]
INFO flwr 2024-04-26 21:08:19,614 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0637), (1, 0.4405), (2, 0.591), (3, 0.6666), (4, 0.7137), (5, 0.7492), (6, 0.7881), (7, 0.8092), (8, 0.8306), (9, 0.8453), (10, 0.8592)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.8592
wandb:     loss 1.65383
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_210545-t15yzaya
wandb: Find logs at: ./wandb/offline-run-20240426_210545-t15yzaya/logs
INFO flwr 2024-04-26 21:08:23,273 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 8
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 20
		Optimizer: FedAdam
			local: {'lr': 0.1}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: Logistic Regression
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=10, bias=True)
			    (1): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 21:08:24,089 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=353678)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=353678)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 21:08:29,002	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 21:08:29,428	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 21:08:29,756	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 21:08:29,758	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 21:08:40,898 | app.py:213 | Flower VCE: Ray initialized with resources: {'accelerator_type:TITAN': 1.0, 'memory': 166458982605.0, 'GPU': 1.0, 'object_store_memory': 75625278259.0, 'CPU': 64.0, 'node:__internal_head__': 1.0, 'node:10.20.240.12': 1.0}
INFO flwr 2024-04-26 21:08:40,899 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 21:08:40,899 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 21:08:40,916 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 21:08:40,917 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 21:08:40,917 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 21:08:40,917 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 21:08:43,761 | server.py:94 | initial parameters (loss, other metrics): 2.3047380447387695, {'accuracy': 0.0849, 'data_size': 10000}
INFO flwr 2024-04-26 21:08:43,762 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 21:08:43,762 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=356838)[0m 2024-04-26 21:08:47.175351: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=356838)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=356837)[0m 2024-04-26 21:08:49.584073: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=356842)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=356842)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=356843)[0m 2024-04-26 21:08:47.369623: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=356843)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=356843)[0m 2024-04-26 21:08:49.646187: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 21:09:08,528 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 21:09:10,081 | server.py:125 | fit progress: (1, 2.248194456100464, {'accuracy': 0.5972, 'data_size': 10000}, 26.319095304002985)
INFO flwr 2024-04-26 21:09:10,082 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 21:09:10,082 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:09:21,273 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 21:09:22,803 | server.py:125 | fit progress: (2, 2.1523168087005615, {'accuracy': 0.6798, 'data_size': 10000}, 39.040772812000796)
INFO flwr 2024-04-26 21:09:22,803 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 21:09:22,804 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:09:33,471 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 21:09:34,996 | server.py:125 | fit progress: (3, 2.0433993339538574, {'accuracy': 0.703, 'data_size': 10000}, 51.23362739000004)
INFO flwr 2024-04-26 21:09:34,996 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 21:09:34,996 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:09:45,864 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 21:09:47,384 | server.py:125 | fit progress: (4, 1.9495290517807007, {'accuracy': 0.711, 'data_size': 10000}, 63.62164718200074)
INFO flwr 2024-04-26 21:09:47,384 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 21:09:47,384 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:09:56,743 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 21:09:58,251 | server.py:125 | fit progress: (5, 1.8780437707901, {'accuracy': 0.7165, 'data_size': 10000}, 74.48831956100184)
INFO flwr 2024-04-26 21:09:58,251 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 21:09:58,251 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:10:08,860 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 21:10:10,366 | server.py:125 | fit progress: (6, 1.8248937129974365, {'accuracy': 0.728, 'data_size': 10000}, 86.60384810300093)
INFO flwr 2024-04-26 21:10:10,366 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 21:10:10,367 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:10:21,222 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 21:10:22,712 | server.py:125 | fit progress: (7, 1.7817058563232422, {'accuracy': 0.748, 'data_size': 10000}, 98.94960246000119)
INFO flwr 2024-04-26 21:10:22,712 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 21:10:22,712 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:10:33,199 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 21:10:34,721 | server.py:125 | fit progress: (8, 1.7404274940490723, {'accuracy': 0.7788, 'data_size': 10000}, 110.9585364370032)
INFO flwr 2024-04-26 21:10:34,721 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 21:10:34,721 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:10:45,208 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 21:10:46,711 | server.py:125 | fit progress: (9, 1.7058035135269165, {'accuracy': 0.8097, 'data_size': 10000}, 122.94879665600092)
INFO flwr 2024-04-26 21:10:46,711 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 21:10:46,712 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:10:57,306 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 21:10:58,841 | server.py:125 | fit progress: (10, 1.6743782758712769, {'accuracy': 0.8351, 'data_size': 10000}, 135.07832018500267)
INFO flwr 2024-04-26 21:10:58,841 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 21:10:58,841 | server.py:153 | FL finished in 135.0787543510014
INFO flwr 2024-04-26 21:10:58,841 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 21:10:58,841 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 21:10:58,841 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 21:10:58,842 | app.py:229 | app_fit: losses_centralized [(0, 2.3047380447387695), (1, 2.248194456100464), (2, 2.1523168087005615), (3, 2.0433993339538574), (4, 1.9495290517807007), (5, 1.8780437707901), (6, 1.8248937129974365), (7, 1.7817058563232422), (8, 1.7404274940490723), (9, 1.7058035135269165), (10, 1.6743782758712769)]
INFO flwr 2024-04-26 21:10:58,842 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0849), (1, 0.5972), (2, 0.6798), (3, 0.703), (4, 0.711), (5, 0.7165), (6, 0.728), (7, 0.748), (8, 0.7788), (9, 0.8097), (10, 0.8351)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.8351
wandb:     loss 1.67438
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_210823-jl6vxcgr
wandb: Find logs at: ./wandb/offline-run-20240426_210823-jl6vxcgr/logs
INFO flwr 2024-04-26 21:11:02,561 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 8
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 20
		Optimizer: FedAdam
			local: {'lr': 0.2}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: Logistic Regression
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=10, bias=True)
			    (1): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 21:11:03,266 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=356834)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=356834)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 21:11:08,048	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 21:11:08,395	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 21:11:08,724	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 21:11:08,725	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 21:11:19,873 | app.py:213 | Flower VCE: Ray initialized with resources: {'CPU': 64.0, 'GPU': 1.0, 'object_store_memory': 75567353856.0, 'accelerator_type:TITAN': 1.0, 'memory': 166323825664.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0}
INFO flwr 2024-04-26 21:11:19,874 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 21:11:19,874 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 21:11:19,889 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 21:11:19,890 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 21:11:19,890 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 21:11:19,891 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 21:11:22,726 | server.py:94 | initial parameters (loss, other metrics): 2.3052616119384766, {'accuracy': 0.0876, 'data_size': 10000}
INFO flwr 2024-04-26 21:11:22,727 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 21:11:22,728 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=360976)[0m 2024-04-26 21:11:26.055925: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=360976)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=360976)[0m 2024-04-26 21:11:28.381336: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=360981)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=360981)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=360971)[0m 2024-04-26 21:11:26.284258: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=360971)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=360971)[0m 2024-04-26 21:11:28.578398: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 21:11:47,261 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 21:11:48,538 | server.py:125 | fit progress: (1, 2.249925136566162, {'accuracy': 0.4811, 'data_size': 10000}, 25.810575093997613)
INFO flwr 2024-04-26 21:11:48,538 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 21:11:48,538 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:11:59,948 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 21:12:01,479 | server.py:125 | fit progress: (2, 2.1560397148132324, {'accuracy': 0.7072, 'data_size': 10000}, 38.751229630001035)
INFO flwr 2024-04-26 21:12:01,479 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 21:12:01,479 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:12:12,424 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 21:12:13,913 | server.py:125 | fit progress: (3, 2.042959451675415, {'accuracy': 0.7604, 'data_size': 10000}, 51.18577188600102)
INFO flwr 2024-04-26 21:12:13,913 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 21:12:13,914 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:12:24,466 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 21:12:25,705 | server.py:125 | fit progress: (4, 1.9442384243011475, {'accuracy': 0.7662, 'data_size': 10000}, 62.9780806130002)
INFO flwr 2024-04-26 21:12:25,706 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 21:12:25,706 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:12:36,436 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 21:12:37,716 | server.py:125 | fit progress: (5, 1.8697096109390259, {'accuracy': 0.7753, 'data_size': 10000}, 74.98831549899842)
INFO flwr 2024-04-26 21:12:37,716 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 21:12:37,716 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:12:48,937 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 21:12:50,409 | server.py:125 | fit progress: (6, 1.813154697418213, {'accuracy': 0.7892, 'data_size': 10000}, 87.68114787599916)
INFO flwr 2024-04-26 21:12:50,409 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 21:12:50,409 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:13:01,426 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 21:13:02,891 | server.py:125 | fit progress: (7, 1.7689497470855713, {'accuracy': 0.803, 'data_size': 10000}, 100.16324285099836)
INFO flwr 2024-04-26 21:13:02,891 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 21:13:02,891 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:13:12,750 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 21:13:14,269 | server.py:125 | fit progress: (8, 1.7321397066116333, {'accuracy': 0.8175, 'data_size': 10000}, 111.54147569699853)
INFO flwr 2024-04-26 21:13:14,269 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 21:13:14,270 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:13:24,691 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 21:13:26,214 | server.py:125 | fit progress: (9, 1.70015287399292, {'accuracy': 0.8319, 'data_size': 10000}, 123.48691931099893)
INFO flwr 2024-04-26 21:13:26,215 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 21:13:26,215 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:13:37,224 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 21:13:38,756 | server.py:125 | fit progress: (10, 1.6750566959381104, {'accuracy': 0.8422, 'data_size': 10000}, 136.02835919000063)
INFO flwr 2024-04-26 21:13:38,756 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 21:13:38,756 | server.py:153 | FL finished in 136.02878896499897
INFO flwr 2024-04-26 21:13:38,756 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 21:13:38,756 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 21:13:38,757 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 21:13:38,757 | app.py:229 | app_fit: losses_centralized [(0, 2.3052616119384766), (1, 2.249925136566162), (2, 2.1560397148132324), (3, 2.042959451675415), (4, 1.9442384243011475), (5, 1.8697096109390259), (6, 1.813154697418213), (7, 1.7689497470855713), (8, 1.7321397066116333), (9, 1.70015287399292), (10, 1.6750566959381104)]
INFO flwr 2024-04-26 21:13:38,757 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0876), (1, 0.4811), (2, 0.7072), (3, 0.7604), (4, 0.7662), (5, 0.7753), (6, 0.7892), (7, 0.803), (8, 0.8175), (9, 0.8319), (10, 0.8422)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.8422
wandb:     loss 1.67506
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_211102-6pemhzfw
wandb: Find logs at: ./wandb/offline-run-20240426_211102-6pemhzfw/logs
INFO flwr 2024-04-26 21:13:42,461 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 32
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 10
		Optimizer: FedAdam
			local: {'lr': 0.05}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: Logistic Regression
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=10, bias=True)
			    (1): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 21:13:43,117 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=360966)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=360966)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 21:13:47,959	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 21:13:48,303	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 21:13:48,755	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 21:13:48,756	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 21:13:59,829 | app.py:213 | Flower VCE: Ray initialized with resources: {'object_store_memory': 76317018931.0, 'GPU': 1.0, 'memory': 168073044173.0, 'accelerator_type:TITAN': 1.0, 'CPU': 64.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0}
INFO flwr 2024-04-26 21:13:59,830 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 21:13:59,830 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 21:13:59,845 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 21:13:59,846 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 21:13:59,846 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 21:13:59,846 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 21:14:02,754 | server.py:94 | initial parameters (loss, other metrics): 2.3024184703826904, {'accuracy': 0.0784, 'data_size': 10000}
INFO flwr 2024-04-26 21:14:02,754 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 21:14:02,755 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=367106)[0m 2024-04-26 21:14:06.081829: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=367106)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=367106)[0m 2024-04-26 21:14:08.401084: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=367108)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=367108)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=367101)[0m 2024-04-26 21:14:06.241431: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=367101)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=367110)[0m 2024-04-26 21:14:08.640885: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 21:14:22,833 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 21:14:24,127 | server.py:125 | fit progress: (1, 2.247789144515991, {'accuracy': 0.3478, 'data_size': 10000}, 21.372159689999535)
INFO flwr 2024-04-26 21:14:24,127 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 21:14:24,127 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:14:32,860 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 21:14:34,165 | server.py:125 | fit progress: (2, 2.1531965732574463, {'accuracy': 0.5497, 'data_size': 10000}, 31.410689610998816)
INFO flwr 2024-04-26 21:14:34,165 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 21:14:34,166 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:14:42,333 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 21:14:43,616 | server.py:125 | fit progress: (3, 2.040074586868286, {'accuracy': 0.6842, 'data_size': 10000}, 40.86111548500048)
INFO flwr 2024-04-26 21:14:43,616 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 21:14:43,616 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:14:51,395 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 21:14:52,879 | server.py:125 | fit progress: (4, 1.9190374612808228, {'accuracy': 0.7674, 'data_size': 10000}, 50.124761224000395)
INFO flwr 2024-04-26 21:14:52,879 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 21:14:52,880 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:15:00,600 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 21:15:02,107 | server.py:125 | fit progress: (5, 1.8238494396209717, {'accuracy': 0.8009, 'data_size': 10000}, 59.352420320999954)
INFO flwr 2024-04-26 21:15:02,107 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 21:15:02,107 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:15:09,964 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 21:15:11,489 | server.py:125 | fit progress: (6, 1.761714220046997, {'accuracy': 0.8199, 'data_size': 10000}, 68.73438348900163)
INFO flwr 2024-04-26 21:15:11,489 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 21:15:11,489 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:15:19,262 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 21:15:20,788 | server.py:125 | fit progress: (7, 1.721771478652954, {'accuracy': 0.8311, 'data_size': 10000}, 78.03329582300285)
INFO flwr 2024-04-26 21:15:20,788 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 21:15:20,788 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:15:28,441 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 21:15:29,931 | server.py:125 | fit progress: (8, 1.6922169923782349, {'accuracy': 0.8401, 'data_size': 10000}, 87.17650071000025)
INFO flwr 2024-04-26 21:15:29,931 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 21:15:29,931 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:15:37,650 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 21:15:39,123 | server.py:125 | fit progress: (9, 1.6690162420272827, {'accuracy': 0.8515, 'data_size': 10000}, 96.36863454000195)
INFO flwr 2024-04-26 21:15:39,123 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 21:15:39,124 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:15:47,010 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 21:15:48,532 | server.py:125 | fit progress: (10, 1.6516969203948975, {'accuracy': 0.8599, 'data_size': 10000}, 105.77722987899688)
INFO flwr 2024-04-26 21:15:48,532 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 21:15:48,532 | server.py:153 | FL finished in 105.77778090999709
INFO flwr 2024-04-26 21:15:48,532 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 21:15:48,532 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 21:15:48,533 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 21:15:48,533 | app.py:229 | app_fit: losses_centralized [(0, 2.3024184703826904), (1, 2.247789144515991), (2, 2.1531965732574463), (3, 2.040074586868286), (4, 1.9190374612808228), (5, 1.8238494396209717), (6, 1.761714220046997), (7, 1.721771478652954), (8, 1.6922169923782349), (9, 1.6690162420272827), (10, 1.6516969203948975)]
INFO flwr 2024-04-26 21:15:48,533 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0784), (1, 0.3478), (2, 0.5497), (3, 0.6842), (4, 0.7674), (5, 0.8009), (6, 0.8199), (7, 0.8311), (8, 0.8401), (9, 0.8515), (10, 0.8599)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.8599
wandb:     loss 1.6517
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_211342-o10fkvf6
wandb: Find logs at: ./wandb/offline-run-20240426_211342-o10fkvf6/logs
INFO flwr 2024-04-26 21:15:52,190 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 32
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 10
		Optimizer: FedAdam
			local: {'lr': 0.1}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: Logistic Regression
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=10, bias=True)
			    (1): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 21:15:52,856 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=367095)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=367095)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 21:15:57,543	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 21:15:57,933	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 21:15:58,287	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 21:15:58,288	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 21:16:09,475 | app.py:213 | Flower VCE: Ray initialized with resources: {'object_store_memory': 75610070630.0, 'CPU': 64.0, 'GPU': 1.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0, 'accelerator_type:TITAN': 1.0, 'memory': 166423498138.0}
INFO flwr 2024-04-26 21:16:09,475 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 21:16:09,475 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 21:16:09,491 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 21:16:09,500 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 21:16:09,501 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 21:16:09,501 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 21:16:12,209 | server.py:94 | initial parameters (loss, other metrics): 2.3030407428741455, {'accuracy': 0.1123, 'data_size': 10000}
INFO flwr 2024-04-26 21:16:12,210 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 21:16:12,211 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=370857)[0m 2024-04-26 21:16:15.722085: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=370857)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=370857)[0m 2024-04-26 21:16:18.062311: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=370857)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=370857)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=370863)[0m 2024-04-26 21:16:16.014210: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=370863)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=370856)[0m 2024-04-26 21:16:18.244049: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 21:16:32,984 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 21:16:34,292 | server.py:125 | fit progress: (1, 2.242482900619507, {'accuracy': 0.5829, 'data_size': 10000}, 22.081816197998705)
INFO flwr 2024-04-26 21:16:34,293 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 21:16:34,293 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:16:43,093 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 21:16:44,631 | server.py:125 | fit progress: (2, 2.1365065574645996, {'accuracy': 0.6181, 'data_size': 10000}, 32.42002158499963)
INFO flwr 2024-04-26 21:16:44,631 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 21:16:44,631 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:16:52,484 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 21:16:53,955 | server.py:125 | fit progress: (3, 2.029754877090454, {'accuracy': 0.6405, 'data_size': 10000}, 41.74461191699811)
INFO flwr 2024-04-26 21:16:53,956 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 21:16:53,956 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:17:01,915 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 21:17:03,431 | server.py:125 | fit progress: (4, 1.9338304996490479, {'accuracy': 0.6906, 'data_size': 10000}, 51.21991056200204)
INFO flwr 2024-04-26 21:17:03,431 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 21:17:03,431 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:17:11,189 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 21:17:12,712 | server.py:125 | fit progress: (5, 1.8444151878356934, {'accuracy': 0.7623, 'data_size': 10000}, 60.501556800998515)
INFO flwr 2024-04-26 21:17:12,712 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 21:17:12,713 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:17:20,439 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 21:17:21,984 | server.py:125 | fit progress: (6, 1.773971676826477, {'accuracy': 0.8042, 'data_size': 10000}, 69.77321801899961)
INFO flwr 2024-04-26 21:17:21,984 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 21:17:21,984 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:17:29,728 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 21:17:31,025 | server.py:125 | fit progress: (7, 1.7225064039230347, {'accuracy': 0.8302, 'data_size': 10000}, 78.81476775900228)
INFO flwr 2024-04-26 21:17:31,026 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 21:17:31,026 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:17:38,912 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 21:17:40,450 | server.py:125 | fit progress: (8, 1.6856560707092285, {'accuracy': 0.848, 'data_size': 10000}, 88.23889957799838)
INFO flwr 2024-04-26 21:17:40,450 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 21:17:40,450 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:17:48,341 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 21:17:49,903 | server.py:125 | fit progress: (9, 1.661923885345459, {'accuracy': 0.8617, 'data_size': 10000}, 97.69217226599721)
INFO flwr 2024-04-26 21:17:49,903 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 21:17:49,903 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:17:57,748 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 21:17:59,269 | server.py:125 | fit progress: (10, 1.6458441019058228, {'accuracy': 0.8677, 'data_size': 10000}, 107.05790739000076)
INFO flwr 2024-04-26 21:17:59,269 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 21:17:59,269 | server.py:153 | FL finished in 107.05832749899855
INFO flwr 2024-04-26 21:17:59,269 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 21:17:59,269 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 21:17:59,269 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 21:17:59,269 | app.py:229 | app_fit: losses_centralized [(0, 2.3030407428741455), (1, 2.242482900619507), (2, 2.1365065574645996), (3, 2.029754877090454), (4, 1.9338304996490479), (5, 1.8444151878356934), (6, 1.773971676826477), (7, 1.7225064039230347), (8, 1.6856560707092285), (9, 1.661923885345459), (10, 1.6458441019058228)]
INFO flwr 2024-04-26 21:17:59,270 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.1123), (1, 0.5829), (2, 0.6181), (3, 0.6405), (4, 0.6906), (5, 0.7623), (6, 0.8042), (7, 0.8302), (8, 0.848), (9, 0.8617), (10, 0.8677)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.8677
wandb:     loss 1.64584
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_211552-dxmeyu9n
wandb: Find logs at: ./wandb/offline-run-20240426_211552-dxmeyu9n/logs
INFO flwr 2024-04-26 21:18:02,925 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 32
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 10
		Optimizer: FedAdam
			local: {'lr': 0.2}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: Logistic Regression
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=10, bias=True)
			    (1): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 21:18:03,616 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=370852)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=370852)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 21:18:08,491	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 21:18:08,821	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 21:18:09,205	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 21:18:09,207	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 21:18:20,348 | app.py:213 | Flower VCE: Ray initialized with resources: {'GPU': 1.0, 'CPU': 64.0, 'node:__internal_head__': 1.0, 'node:10.20.240.12': 1.0, 'object_store_memory': 75595458969.0, 'accelerator_type:TITAN': 1.0, 'memory': 166389404263.0}
INFO flwr 2024-04-26 21:18:20,349 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 21:18:20,349 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 21:18:20,364 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 21:18:20,365 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 21:18:20,365 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 21:18:20,365 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 21:18:23,642 | server.py:94 | initial parameters (loss, other metrics): 2.305694818496704, {'accuracy': 0.1165, 'data_size': 10000}
INFO flwr 2024-04-26 21:18:23,643 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 21:18:23,643 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=374004)[0m 2024-04-26 21:18:26.554660: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=374004)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=374003)[0m 2024-04-26 21:18:28.892984: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=374005)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=374005)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=374006)[0m 2024-04-26 21:18:26.804601: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=374006)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=374006)[0m 2024-04-26 21:18:29.112004: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 21:18:42,959 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 21:18:44,523 | server.py:125 | fit progress: (1, 2.2484467029571533, {'accuracy': 0.4247, 'data_size': 10000}, 20.88028725600452)
INFO flwr 2024-04-26 21:18:44,524 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 21:18:44,524 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:18:53,107 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 21:18:54,589 | server.py:125 | fit progress: (2, 2.1475210189819336, {'accuracy': 0.609, 'data_size': 10000}, 30.94572935600445)
INFO flwr 2024-04-26 21:18:54,589 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 21:18:54,589 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:19:02,386 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 21:19:03,893 | server.py:125 | fit progress: (3, 2.037653684616089, {'accuracy': 0.655, 'data_size': 10000}, 40.24945042000036)
INFO flwr 2024-04-26 21:19:03,893 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 21:19:03,893 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:19:11,607 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 21:19:13,060 | server.py:125 | fit progress: (4, 1.9404817819595337, {'accuracy': 0.6925, 'data_size': 10000}, 49.416693065999425)
INFO flwr 2024-04-26 21:19:13,060 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 21:19:13,060 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:19:20,935 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 21:19:22,455 | server.py:125 | fit progress: (5, 1.8603949546813965, {'accuracy': 0.7302, 'data_size': 10000}, 58.811386827001115)
INFO flwr 2024-04-26 21:19:22,455 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 21:19:22,455 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:19:30,058 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 21:19:31,557 | server.py:125 | fit progress: (6, 1.7988859415054321, {'accuracy': 0.7557, 'data_size': 10000}, 67.91397811600473)
INFO flwr 2024-04-26 21:19:31,558 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 21:19:31,558 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:19:39,159 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 21:19:40,707 | server.py:125 | fit progress: (7, 1.7543413639068604, {'accuracy': 0.7811, 'data_size': 10000}, 77.06413824500487)
INFO flwr 2024-04-26 21:19:40,708 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 21:19:40,708 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:19:48,494 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 21:19:49,983 | server.py:125 | fit progress: (8, 1.7164658308029175, {'accuracy': 0.8099, 'data_size': 10000}, 86.33983477199945)
INFO flwr 2024-04-26 21:19:49,983 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 21:19:49,984 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:19:57,973 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 21:19:59,467 | server.py:125 | fit progress: (9, 1.6847002506256104, {'accuracy': 0.8338, 'data_size': 10000}, 95.82347143700463)
INFO flwr 2024-04-26 21:19:59,467 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 21:19:59,467 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:20:07,417 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 21:20:08,926 | server.py:125 | fit progress: (10, 1.655766248703003, {'accuracy': 0.8563, 'data_size': 10000}, 105.28319455500605)
INFO flwr 2024-04-26 21:20:08,927 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 21:20:08,927 | server.py:153 | FL finished in 105.28375710399996
INFO flwr 2024-04-26 21:20:08,927 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 21:20:08,927 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 21:20:08,927 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 21:20:08,928 | app.py:229 | app_fit: losses_centralized [(0, 2.305694818496704), (1, 2.2484467029571533), (2, 2.1475210189819336), (3, 2.037653684616089), (4, 1.9404817819595337), (5, 1.8603949546813965), (6, 1.7988859415054321), (7, 1.7543413639068604), (8, 1.7164658308029175), (9, 1.6847002506256104), (10, 1.655766248703003)]
INFO flwr 2024-04-26 21:20:08,928 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.1165), (1, 0.4247), (2, 0.609), (3, 0.655), (4, 0.6925), (5, 0.7302), (6, 0.7557), (7, 0.7811), (8, 0.8099), (9, 0.8338), (10, 0.8563)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.8563
wandb:     loss 1.65577
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_211803-d0sr9kfg
wandb: Find logs at: ./wandb/offline-run-20240426_211803-d0sr9kfg/logs
INFO flwr 2024-04-26 21:20:12,589 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 32
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 20
		Optimizer: FedAdam
			local: {'lr': 0.05}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: Logistic Regression
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=10, bias=True)
			    (1): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 21:20:13,247 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=374000)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=374000)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 21:20:18,065	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 21:20:18,451	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 21:20:18,788	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 21:20:18,790	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 21:20:30,032 | app.py:213 | Flower VCE: Ray initialized with resources: {'accelerator_type:TITAN': 1.0, 'memory': 166423584154.0, 'GPU': 1.0, 'node:__internal_head__': 1.0, 'node:10.20.240.12': 1.0, 'object_store_memory': 75610107494.0, 'CPU': 64.0}
INFO flwr 2024-04-26 21:20:30,032 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 21:20:30,032 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 21:20:30,047 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 21:20:30,048 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 21:20:30,048 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 21:20:30,049 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 21:20:32,520 | server.py:94 | initial parameters (loss, other metrics): 2.2981507778167725, {'accuracy': 0.1221, 'data_size': 10000}
INFO flwr 2024-04-26 21:20:32,521 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 21:20:32,522 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=377481)[0m 2024-04-26 21:20:39.003285: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=377481)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=377475)[0m 2024-04-26 21:20:41.528932: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=377475)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=377475)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=377480)[0m 2024-04-26 21:20:39.209233: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=377480)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=377483)[0m 2024-04-26 21:20:41.508568: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 21:20:57,960 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 21:20:59,480 | server.py:125 | fit progress: (1, 2.235508441925049, {'accuracy': 0.6115, 'data_size': 10000}, 26.95887894000043)
INFO flwr 2024-04-26 21:20:59,481 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 21:20:59,481 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:21:08,916 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 21:21:10,470 | server.py:125 | fit progress: (2, 2.125579595565796, {'accuracy': 0.7124, 'data_size': 10000}, 37.9482087580036)
INFO flwr 2024-04-26 21:21:10,470 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 21:21:10,470 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:21:18,927 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 21:21:20,443 | server.py:125 | fit progress: (3, 2.005323886871338, {'accuracy': 0.7282, 'data_size': 10000}, 47.92197456500435)
INFO flwr 2024-04-26 21:21:20,444 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 21:21:20,444 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:21:28,792 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 21:21:30,344 | server.py:125 | fit progress: (4, 1.9045315980911255, {'accuracy': 0.7449, 'data_size': 10000}, 57.82221756299987)
INFO flwr 2024-04-26 21:21:30,344 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 21:21:30,344 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:21:38,686 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 21:21:40,231 | server.py:125 | fit progress: (5, 1.8293304443359375, {'accuracy': 0.7587, 'data_size': 10000}, 67.70934257000044)
INFO flwr 2024-04-26 21:21:40,231 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 21:21:40,231 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:21:48,449 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 21:21:50,011 | server.py:125 | fit progress: (6, 1.7693418264389038, {'accuracy': 0.7871, 'data_size': 10000}, 77.48911747700186)
INFO flwr 2024-04-26 21:21:50,011 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 21:21:50,011 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:21:58,514 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 21:22:00,011 | server.py:125 | fit progress: (7, 1.7207107543945312, {'accuracy': 0.8174, 'data_size': 10000}, 87.48934351700154)
INFO flwr 2024-04-26 21:22:00,011 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 21:22:00,011 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:22:08,162 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 21:22:09,668 | server.py:125 | fit progress: (8, 1.6848810911178589, {'accuracy': 0.84, 'data_size': 10000}, 97.14697091900598)
INFO flwr 2024-04-26 21:22:09,669 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 21:22:09,669 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:22:17,699 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 21:22:19,232 | server.py:125 | fit progress: (9, 1.6612426042556763, {'accuracy': 0.8561, 'data_size': 10000}, 106.7102085660008)
INFO flwr 2024-04-26 21:22:19,232 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 21:22:19,232 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:22:27,614 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 21:22:29,123 | server.py:125 | fit progress: (10, 1.647040605545044, {'accuracy': 0.8613, 'data_size': 10000}, 116.60144041800231)
INFO flwr 2024-04-26 21:22:29,123 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 21:22:29,123 | server.py:153 | FL finished in 116.6018652720013
INFO flwr 2024-04-26 21:22:29,123 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 21:22:29,124 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 21:22:29,124 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 21:22:29,124 | app.py:229 | app_fit: losses_centralized [(0, 2.2981507778167725), (1, 2.235508441925049), (2, 2.125579595565796), (3, 2.005323886871338), (4, 1.9045315980911255), (5, 1.8293304443359375), (6, 1.7693418264389038), (7, 1.7207107543945312), (8, 1.6848810911178589), (9, 1.6612426042556763), (10, 1.647040605545044)]
INFO flwr 2024-04-26 21:22:29,124 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.1221), (1, 0.6115), (2, 0.7124), (3, 0.7282), (4, 0.7449), (5, 0.7587), (6, 0.7871), (7, 0.8174), (8, 0.84), (9, 0.8561), (10, 0.8613)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.8613
wandb:     loss 1.64704
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_212012-i3sgd76p
wandb: Find logs at: ./wandb/offline-run-20240426_212012-i3sgd76p/logs
INFO flwr 2024-04-26 21:22:32,781 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 32
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 20
		Optimizer: FedAdam
			local: {'lr': 0.1}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: Logistic Regression
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=10, bias=True)
			    (1): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 21:22:33,533 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=377483)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=377483)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 21:22:38,471	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 21:22:38,906	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 21:22:39,242	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 21:22:39,243	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 21:22:50,311 | app.py:213 | Flower VCE: Ray initialized with resources: {'CPU': 64.0, 'GPU': 1.0, 'object_store_memory': 75649957478.0, 'memory': 166516567450.0, 'accelerator_type:TITAN': 1.0, 'node:__internal_head__': 1.0, 'node:10.20.240.12': 1.0}
INFO flwr 2024-04-26 21:22:50,312 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 21:22:50,312 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 21:22:50,327 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 21:22:50,328 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 21:22:50,328 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 21:22:50,328 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 21:22:53,071 | server.py:94 | initial parameters (loss, other metrics): 2.3058156967163086, {'accuracy': 0.102, 'data_size': 10000}
INFO flwr 2024-04-26 21:22:53,071 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 21:22:53,072 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=383893)[0m 2024-04-26 21:22:56.534313: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=383893)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=383889)[0m 2024-04-26 21:22:58.861610: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=383889)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=383889)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=383890)[0m 2024-04-26 21:22:56.630550: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=383890)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=383890)[0m 2024-04-26 21:22:58.990431: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 21:23:14,678 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 21:23:15,952 | server.py:125 | fit progress: (1, 2.246586799621582, {'accuracy': 0.4903, 'data_size': 10000}, 22.880546767999476)
INFO flwr 2024-04-26 21:23:15,953 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 21:23:15,953 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:23:25,080 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 21:23:26,607 | server.py:125 | fit progress: (2, 2.14039945602417, {'accuracy': 0.5866, 'data_size': 10000}, 33.53503576399817)
INFO flwr 2024-04-26 21:23:26,607 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 21:23:26,607 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:23:35,116 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 21:23:36,596 | server.py:125 | fit progress: (3, 2.028067111968994, {'accuracy': 0.6443, 'data_size': 10000}, 43.52427514699957)
INFO flwr 2024-04-26 21:23:36,596 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 21:23:36,597 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:23:45,033 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 21:23:46,287 | server.py:125 | fit progress: (4, 1.940562129020691, {'accuracy': 0.672, 'data_size': 10000}, 53.21525005000149)
INFO flwr 2024-04-26 21:23:46,287 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 21:23:46,288 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:23:54,580 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 21:23:55,879 | server.py:125 | fit progress: (5, 1.8666517734527588, {'accuracy': 0.7139, 'data_size': 10000}, 62.807196812995244)
INFO flwr 2024-04-26 21:23:55,879 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 21:23:55,880 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:24:04,351 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 21:24:05,844 | server.py:125 | fit progress: (6, 1.802884578704834, {'accuracy': 0.754, 'data_size': 10000}, 72.77268290000211)
INFO flwr 2024-04-26 21:24:05,845 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 21:24:05,845 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:24:13,938 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 21:24:15,464 | server.py:125 | fit progress: (7, 1.7497888803482056, {'accuracy': 0.7913, 'data_size': 10000}, 82.3926688079955)
INFO flwr 2024-04-26 21:24:15,465 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 21:24:15,465 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:24:23,400 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 21:24:24,896 | server.py:125 | fit progress: (8, 1.7046681642532349, {'accuracy': 0.8205, 'data_size': 10000}, 91.82436816099653)
INFO flwr 2024-04-26 21:24:24,896 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 21:24:24,897 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:24:33,062 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 21:24:34,565 | server.py:125 | fit progress: (9, 1.6706463098526, {'accuracy': 0.8471, 'data_size': 10000}, 101.49331582299783)
INFO flwr 2024-04-26 21:24:34,565 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 21:24:34,566 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:24:42,569 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 21:24:44,138 | server.py:125 | fit progress: (10, 1.6452982425689697, {'accuracy': 0.8665, 'data_size': 10000}, 111.06587345699518)
INFO flwr 2024-04-26 21:24:44,138 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 21:24:44,138 | server.py:153 | FL finished in 111.06643366199569
INFO flwr 2024-04-26 21:24:44,138 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 21:24:44,139 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 21:24:44,139 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 21:24:44,139 | app.py:229 | app_fit: losses_centralized [(0, 2.3058156967163086), (1, 2.246586799621582), (2, 2.14039945602417), (3, 2.028067111968994), (4, 1.940562129020691), (5, 1.8666517734527588), (6, 1.802884578704834), (7, 1.7497888803482056), (8, 1.7046681642532349), (9, 1.6706463098526), (10, 1.6452982425689697)]
INFO flwr 2024-04-26 21:24:44,139 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.102), (1, 0.4903), (2, 0.5866), (3, 0.6443), (4, 0.672), (5, 0.7139), (6, 0.754), (7, 0.7913), (8, 0.8205), (9, 0.8471), (10, 0.8665)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.8665
wandb:     loss 1.6453
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_212233-979nj8la
wandb: Find logs at: ./wandb/offline-run-20240426_212233-979nj8la/logs
INFO flwr 2024-04-26 21:24:47,781 | run_simulation.py:150 | 
Running with Config
	Simulation
		batch_size: 32
		client_count: 100
		fraction_fit: 0.1
		global_rounds: 10
		local_rounds: 20
		Optimizer: FedAdam
			local: {'lr': 0.2}
			global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 1e-09, 'weight_decay': 0.9999}
	Dataset
		name: MNIST
		preprocess_fn:
			def preprocess_fn(element):
			  return {
			    "x": element["image"].reshape(784) / 255.,
			    "y": element["label"]
			  }
			
		splitter:
			alpha: 1.0
			percent_non_iid: 25.0
	Model
		name: Logistic Regression
		criterion: CrossEntropyLoss()
		layers:
			Net(
			  (layers): Sequential(
			    (0): Linear(in_features=784, out_features=10, bias=True)
			    (1): Softmax(dim=-1)
			  )
			)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-26 21:24:48,447 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=383886)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=383886)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-26 21:24:53,217	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-26 21:24:53,550	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-26 21:24:53,882	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_67055d5255d84b59.zip' (0.20MiB) to Ray cluster...
2024-04-26 21:24:53,883	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_67055d5255d84b59.zip'.
INFO flwr 2024-04-26 21:25:05,006 | app.py:213 | Flower VCE: Ray initialized with resources: {'CPU': 64.0, 'accelerator_type:TITAN': 1.0, 'memory': 166337777460.0, 'object_store_memory': 75573333196.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0, 'GPU': 1.0}
INFO flwr 2024-04-26 21:25:05,006 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-26 21:25:05,007 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-26 21:25:05,027 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-26 21:25:05,029 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-26 21:25:05,029 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-26 21:25:05,029 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-26 21:25:07,987 | server.py:94 | initial parameters (loss, other metrics): 2.304542303085327, {'accuracy': 0.0715, 'data_size': 10000}
INFO flwr 2024-04-26 21:25:07,988 | server.py:104 | FL starting
DEBUG flwr 2024-04-26 21:25:07,989 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=387040)[0m 2024-04-26 21:25:11.208056: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=387040)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=387040)[0m 2024-04-26 21:25:13.530241: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=387038)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=387038)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=387036)[0m 2024-04-26 21:25:11.501116: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=387036)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=387036)[0m 2024-04-26 21:25:13.944378: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-26 21:25:28,258 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-26 21:25:29,533 | server.py:125 | fit progress: (1, 2.245774984359741, {'accuracy': 0.544, 'data_size': 10000}, 21.544322312998702)
INFO flwr 2024-04-26 21:25:29,533 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-26 21:25:29,533 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:25:39,028 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-26 21:25:40,306 | server.py:125 | fit progress: (2, 2.1430249214172363, {'accuracy': 0.6522, 'data_size': 10000}, 32.31714392499998)
INFO flwr 2024-04-26 21:25:40,306 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-26 21:25:40,306 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:25:49,105 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-26 21:25:50,431 | server.py:125 | fit progress: (3, 2.0295512676239014, {'accuracy': 0.6961, 'data_size': 10000}, 42.44217429400305)
INFO flwr 2024-04-26 21:25:50,431 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-26 21:25:50,431 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:25:58,424 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-26 21:25:59,915 | server.py:125 | fit progress: (4, 1.935076355934143, {'accuracy': 0.7165, 'data_size': 10000}, 51.926866687004804)
INFO flwr 2024-04-26 21:25:59,916 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-26 21:25:59,916 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:26:08,085 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-26 21:26:09,604 | server.py:125 | fit progress: (5, 1.8605855703353882, {'accuracy': 0.7394, 'data_size': 10000}, 61.61526397200214)
INFO flwr 2024-04-26 21:26:09,604 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-26 21:26:09,604 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:26:18,004 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-26 21:26:19,526 | server.py:125 | fit progress: (6, 1.8025224208831787, {'accuracy': 0.7639, 'data_size': 10000}, 71.5374509530011)
INFO flwr 2024-04-26 21:26:19,526 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-26 21:26:19,526 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:26:28,119 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-26 21:26:29,667 | server.py:125 | fit progress: (7, 1.7514853477478027, {'accuracy': 0.7956, 'data_size': 10000}, 81.67860707100044)
INFO flwr 2024-04-26 21:26:29,667 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-26 21:26:29,668 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:26:37,989 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-26 21:26:39,508 | server.py:125 | fit progress: (8, 1.7112008333206177, {'accuracy': 0.8209, 'data_size': 10000}, 91.51964001900342)
INFO flwr 2024-04-26 21:26:39,508 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-26 21:26:39,509 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:26:47,647 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-26 21:26:49,165 | server.py:125 | fit progress: (9, 1.677942156791687, {'accuracy': 0.8462, 'data_size': 10000}, 101.17627074399934)
INFO flwr 2024-04-26 21:26:49,165 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-26 21:26:49,165 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-26 21:26:57,732 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-26 21:26:59,220 | server.py:125 | fit progress: (10, 1.6537156105041504, {'accuracy': 0.8586, 'data_size': 10000}, 111.23135815800197)
INFO flwr 2024-04-26 21:26:59,220 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-26 21:26:59,220 | server.py:153 | FL finished in 111.23178359900339
INFO flwr 2024-04-26 21:26:59,220 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-26 21:26:59,220 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-26 21:26:59,221 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-26 21:26:59,221 | app.py:229 | app_fit: losses_centralized [(0, 2.304542303085327), (1, 2.245774984359741), (2, 2.1430249214172363), (3, 2.0295512676239014), (4, 1.935076355934143), (5, 1.8605855703353882), (6, 1.8025224208831787), (7, 1.7514853477478027), (8, 1.7112008333206177), (9, 1.677942156791687), (10, 1.6537156105041504)]
INFO flwr 2024-04-26 21:26:59,221 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0715), (1, 0.544), (2, 0.6522), (3, 0.6961), (4, 0.7165), (5, 0.7394), (6, 0.7639), (7, 0.7956), (8, 0.8209), (9, 0.8462), (10, 0.8586)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.8586
wandb:     loss 1.65372
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240426_212448-mxy4oij2
wandb: Find logs at: ./wandb/offline-run-20240426_212448-mxy4oij2/logs
[2m[36m(DefaultActor pid=387036)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=387036)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
