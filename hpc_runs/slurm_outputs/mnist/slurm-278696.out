ctit082
srun: Job 278696 step creation temporarily disabled, retrying
2024-04-03 12:01:27.054950: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-04-03 12:01:27.055510: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-04-03 12:02:19.439387: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-04-03 12:02:19.441314: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Using the latest cached version of the dataset since mnist couldn't be found on the Hugging Face Hub
Using the latest cached version of the dataset since mnist couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'mnist' at .cache/mnist/mnist/1.0.0/b06aab39e05f7bcd9635d18ed25d06eae523c574 (last modified on Tue Apr  2 18:09:57 2024).
Found the latest cached dataset configuration 'mnist' at .cache/mnist/mnist/1.0.0/b06aab39e05f7bcd9635d18ed25d06eae523c574 (last modified on Tue Apr  2 18:09:57 2024).
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-03 12:11:37,803 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
INFO flwr 2024-04-03 12:11:37,804 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
2024-04-03 12:11:46,891	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-03 12:11:46,892	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-03 12:11:58,234	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-03 12:11:58,235	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-03 12:11:58,532	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_a99f2a2b2ea9a898.zip' (7.03MiB) to Ray cluster...
2024-04-03 12:11:58,545	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_a99f2a2b2ea9a898.zip'.
2024-04-03 12:11:58,571	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_68ea009c63540408.zip' (7.03MiB) to Ray cluster...
2024-04-03 12:11:58,595	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_68ea009c63540408.zip'.
INFO flwr 2024-04-03 12:12:10,449 | app.py:213 | Flower VCE: Ray initialized with resources: {'CPU': 64.0, 'object_store_memory': 80678349619.0, 'accelerator_type:TITAN': 1.0, 'memory': 178249482445.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0, 'GPU': 1.0}
INFO flwr 2024-04-03 12:12:10,449 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-03 12:12:10,450 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-03 12:12:10,471 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-03 12:12:10,473 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-03 12:12:10,473 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-03 12:12:10,473 | server.py:91 | Evaluating initial parameters
[2m[36m(pid=5413)[0m 2024-04-03 12:12:16.399044: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=5413)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
INFO flwr 2024-04-03 12:12:21,504 | app.py:213 | Flower VCE: Ray initialized with resources: {'CPU': 128.0, 'node:__internal_head__': 1.0, 'node:10.20.240.17': 1.0, 'object_store_memory': 80471221862.0, 'memory': 177766184346.0, 'GPU': 1.0}
INFO flwr 2024-04-03 12:12:21,504 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-03 12:12:21,504 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-03 12:12:21,535 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-03 12:12:21,536 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-03 12:12:21,536 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-03 12:12:21,537 | server.py:91 | Evaluating initial parameters
[2m[36m(pid=5413)[0m 2024-04-03 12:12:25.890632: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(pid=5412)[0m 2024-04-03 12:12:16.459566: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)[0m
[2m[36m(pid=5412)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
INFO flwr 2024-04-03 12:12:28,715 | server.py:94 | initial parameters (loss, other metrics): 2.3044753074645996, {'accuracy': 0.0654, 'data_size': 10000}
INFO flwr 2024-04-03 12:12:28,715 | server.py:104 | FL starting
DEBUG flwr 2024-04-03 12:12:28,716 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
INFO flwr 2024-04-03 12:12:28,780 | server.py:94 | initial parameters (loss, other metrics): 2.3044753074645996, {'accuracy': 0.0654, 'data_size': 10000}
INFO flwr 2024-04-03 12:12:28,781 | server.py:104 | FL starting
DEBUG flwr 2024-04-03 12:12:28,781 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=40850)[0m 2024-04-03 12:12:30.190141: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=40850)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=40848)[0m 2024-04-03 12:12:33.015976: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=40848)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=40848)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=40848)[0m 2024-04-03 12:12:30.391021: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)[0m
[2m[36m(pid=40848)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=40846)[0m 2024-04-03 12:12:33.016148: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=5413)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=5413)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=5412)[0m 2024-04-03 12:12:25.890108: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-03 12:12:59,015 | server.py:236 | fit_round 1 received 10 results and 0 failures
WARNING flwr 2024-04-03 12:12:59,064 | fedavg.py:250 | No fit_metrics_aggregation_fn provided
DEBUG flwr 2024-04-03 12:12:59,434 | server.py:236 | fit_round 1 received 10 results and 0 failures
WARNING flwr 2024-04-03 12:12:59,511 | fedavg.py:250 | No fit_metrics_aggregation_fn provided
INFO flwr 2024-04-03 12:13:00,137 | server.py:125 | fit progress: (1, 2.3044614791870117, {'accuracy': 0.0654, 'data_size': 10000}, 31.42145280099976)
INFO flwr 2024-04-03 12:13:00,137 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-03 12:13:00,138 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
INFO flwr 2024-04-03 12:13:00,840 | server.py:125 | fit progress: (1, 2.304462194442749, {'accuracy': 0.0654, 'data_size': 10000}, 32.05963027000007)
INFO flwr 2024-04-03 12:13:00,841 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-03 12:13:00,841 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:13:06,013 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-03 12:13:07,160 | server.py:125 | fit progress: (2, 2.3044471740722656, {'accuracy': 0.0657, 'data_size': 10000}, 38.44469702199967)
INFO flwr 2024-04-03 12:13:07,160 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-03 12:13:07,161 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:13:08,407 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-03 12:13:09,898 | server.py:125 | fit progress: (2, 2.3044493198394775, {'accuracy': 0.0653, 'data_size': 10000}, 41.11701874300002)
INFO flwr 2024-04-03 12:13:09,898 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-03 12:13:09,898 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:13:12,765 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-03 12:13:13,980 | server.py:125 | fit progress: (3, 2.3044347763061523, {'accuracy': 0.0659, 'data_size': 10000}, 45.264936231998945)
INFO flwr 2024-04-03 12:13:13,981 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-03 12:13:13,981 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:13:16,554 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-03 12:13:18,122 | server.py:125 | fit progress: (3, 2.3044352531433105, {'accuracy': 0.0659, 'data_size': 10000}, 49.34067368700005)
INFO flwr 2024-04-03 12:13:18,122 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-03 12:13:18,122 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:13:19,492 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-03 12:13:20,770 | server.py:125 | fit progress: (4, 2.3044180870056152, {'accuracy': 0.066, 'data_size': 10000}, 52.05484827299915)
INFO flwr 2024-04-03 12:13:20,771 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-03 12:13:20,771 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:13:24,872 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-03 12:13:26,268 | server.py:125 | fit progress: (4, 2.3044188022613525, {'accuracy': 0.0662, 'data_size': 10000}, 57.48679638099998)
INFO flwr 2024-04-03 12:13:26,268 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-03 12:13:26,268 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:13:26,323 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-03 12:13:27,494 | server.py:125 | fit progress: (5, 2.3044018745422363, {'accuracy': 0.0662, 'data_size': 10000}, 58.77876584899968)
INFO flwr 2024-04-03 12:13:27,494 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-03 12:13:27,495 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:13:33,064 | server.py:236 | fit_round 6 received 10 results and 0 failures
DEBUG flwr 2024-04-03 12:13:33,379 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-03 12:13:34,203 | server.py:125 | fit progress: (6, 2.304384231567383, {'accuracy': 0.0665, 'data_size': 10000}, 65.48732376799853)
INFO flwr 2024-04-03 12:13:34,203 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-03 12:13:34,203 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
INFO flwr 2024-04-03 12:13:34,928 | server.py:125 | fit progress: (5, 2.3044042587280273, {'accuracy': 0.0661, 'data_size': 10000}, 66.14686075099996)
INFO flwr 2024-04-03 12:13:34,928 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-03 12:13:34,928 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:13:39,817 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-03 12:13:41,242 | server.py:125 | fit progress: (7, 2.3043713569641113, {'accuracy': 0.0665, 'data_size': 10000}, 72.52646993999952)
INFO flwr 2024-04-03 12:13:41,242 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-03 12:13:41,242 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:13:42,087 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-03 12:13:43,675 | server.py:125 | fit progress: (6, 2.304384469985962, {'accuracy': 0.0665, 'data_size': 10000}, 74.89381184399997)
INFO flwr 2024-04-03 12:13:43,675 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-03 12:13:43,675 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:13:46,886 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-03 12:13:48,377 | server.py:125 | fit progress: (8, 2.3043551445007324, {'accuracy': 0.0667, 'data_size': 10000}, 79.66193084799852)
INFO flwr 2024-04-03 12:13:48,378 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-03 12:13:48,378 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:13:50,416 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-03 12:13:52,297 | server.py:125 | fit progress: (7, 2.3043718338012695, {'accuracy': 0.0665, 'data_size': 10000}, 83.51580756300007)
INFO flwr 2024-04-03 12:13:52,297 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-03 12:13:52,297 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:13:53,881 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-03 12:13:55,435 | server.py:125 | fit progress: (9, 2.3043389320373535, {'accuracy': 0.067, 'data_size': 10000}, 86.71988690799844)
INFO flwr 2024-04-03 12:13:55,436 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-03 12:13:55,436 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:13:59,263 | server.py:236 | fit_round 8 received 10 results and 0 failures
DEBUG flwr 2024-04-03 12:14:00,911 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-03 12:14:01,400 | server.py:125 | fit progress: (8, 2.30435848236084, {'accuracy': 0.0667, 'data_size': 10000}, 92.61874384600003)
INFO flwr 2024-04-03 12:14:01,400 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-03 12:14:01,400 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
INFO flwr 2024-04-03 12:14:07,307 | server.py:125 | fit progress: (10, 2.304326295852661, {'accuracy': 0.067, 'data_size': 10000}, 98.59193300499828)
INFO flwr 2024-04-03 12:14:07,308 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-03 12:14:07,308 | server.py:153 | FL finished in 98.59222505199978
INFO flwr 2024-04-03 12:14:07,308 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-03 12:14:07,308 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-03 12:14:07,308 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-03 12:14:07,308 | app.py:229 | app_fit: losses_centralized [(0, 2.3044753074645996), (1, 2.3044614791870117), (2, 2.3044471740722656), (3, 2.3044347763061523), (4, 2.3044180870056152), (5, 2.3044018745422363), (6, 2.304384231567383), (7, 2.3043713569641113), (8, 2.3043551445007324), (9, 2.3043389320373535), (10, 2.304326295852661)]
INFO flwr 2024-04-03 12:14:07,308 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0654), (1, 0.0654), (2, 0.0657), (3, 0.0659), (4, 0.066), (5, 0.0662), (6, 0.0665), (7, 0.0665), (8, 0.0667), (9, 0.067), (10, 0.067)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.067
wandb:     loss 2.30433
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240403_121132-pxnm6pud
wandb: Find logs at: ./wandb/offline-run-20240403_121132-pxnm6pud/logs
DEBUG flwr 2024-04-03 12:14:08,499 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-03 12:14:11,477 | server.py:125 | fit progress: (9, 2.3043415546417236, {'accuracy': 0.067, 'data_size': 10000}, 102.69573977300001)
INFO flwr 2024-04-03 12:14:11,477 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-03 12:14:11,477 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:14:18,183 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-03 12:14:20,197 | server.py:125 | fit progress: (10, 2.304327964782715, {'accuracy': 0.067, 'data_size': 10000}, 111.41647147000003)
INFO flwr 2024-04-03 12:14:20,198 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-03 12:14:20,198 | server.py:153 | FL finished in 111.41696777699997
INFO flwr 2024-04-03 12:14:20,198 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-03 12:14:20,198 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-03 12:14:20,199 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-03 12:14:20,199 | app.py:229 | app_fit: losses_centralized [(0, 2.3044753074645996), (1, 2.304462194442749), (2, 2.3044493198394775), (3, 2.3044352531433105), (4, 2.3044188022613525), (5, 2.3044042587280273), (6, 2.304384469985962), (7, 2.3043718338012695), (8, 2.30435848236084), (9, 2.3043415546417236), (10, 2.304327964782715)]
INFO flwr 2024-04-03 12:14:20,199 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0654), (1, 0.0654), (2, 0.0653), (3, 0.0659), (4, 0.0662), (5, 0.0661), (6, 0.0665), (7, 0.0665), (8, 0.0667), (9, 0.067), (10, 0.067)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.067
wandb:     loss 2.30433
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240403_121134-kha7pnjt
wandb: Find logs at: ./wandb/offline-run-20240403_121134-kha7pnjt/logs
Using the latest cached version of the dataset since mnist couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'mnist' at .cache/mnist/mnist/1.0.0/b06aab39e05f7bcd9635d18ed25d06eae523c574 (last modified on Tue Apr  2 18:09:57 2024).
Using the latest cached version of the dataset since mnist couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'mnist' at .cache/mnist/mnist/1.0.0/b06aab39e05f7bcd9635d18ed25d06eae523c574 (last modified on Tue Apr  2 18:09:57 2024).
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-03 12:21:13,292 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=40846)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=40846)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-03 12:21:18,424	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-03 12:21:18,712	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-03 12:21:18,991	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_05f4bdb5430472fd.zip' (7.05MiB) to Ray cluster...
2024-04-03 12:21:19,002	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_05f4bdb5430472fd.zip'.
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-03 12:21:32,055 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=5412)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=5412)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
INFO flwr 2024-04-03 12:21:35,811 | app.py:213 | Flower VCE: Ray initialized with resources: {'node:__internal_head__': 1.0, 'CPU': 128.0, 'GPU': 1.0, 'memory': 176544493364.0, 'object_store_memory': 79947640012.0, 'node:10.20.240.17': 1.0}
INFO flwr 2024-04-03 12:21:35,812 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-03 12:21:35,812 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-03 12:21:35,824 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-03 12:21:35,825 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-03 12:21:35,825 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-03 12:21:35,826 | server.py:91 | Evaluating initial parameters
2024-04-03 12:21:36,670	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-03 12:21:36,988	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-03 12:21:37,286	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_19cb896ed2f50e03.zip' (7.05MiB) to Ray cluster...
2024-04-03 12:21:37,305	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_19cb896ed2f50e03.zip'.
INFO flwr 2024-04-03 12:21:37,862 | server.py:94 | initial parameters (loss, other metrics): 2.3059661388397217, {'accuracy': 0.072, 'data_size': 10000}
INFO flwr 2024-04-03 12:21:37,863 | server.py:104 | FL starting
DEBUG flwr 2024-04-03 12:21:37,863 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=47354)[0m 2024-04-03 12:21:40.954416: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=47354)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=47352)[0m 2024-04-03 12:21:42.616659: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
INFO flwr 2024-04-03 12:21:49,700 | app.py:213 | Flower VCE: Ray initialized with resources: {'CPU': 64.0, 'object_store_memory': 80119889510.0, 'accelerator_type:TITAN': 1.0, 'memory': 176946408858.0, 'GPU': 1.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0}
INFO flwr 2024-04-03 12:21:49,700 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-03 12:21:49,701 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-03 12:21:49,716 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-03 12:21:49,717 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-03 12:21:49,717 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-03 12:21:49,717 | server.py:91 | Evaluating initial parameters
[2m[36m(DefaultActor pid=47351)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=47351)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=47345)[0m 2024-04-03 12:21:41.058745: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=47345)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=47351)[0m 2024-04-03 12:21:42.713914: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-03 12:21:52,706 | server.py:236 | fit_round 1 received 10 results and 0 failures
INFO flwr 2024-04-03 12:21:52,732 | server.py:94 | initial parameters (loss, other metrics): 2.3059661388397217, {'accuracy': 0.072, 'data_size': 10000}
INFO flwr 2024-04-03 12:21:52,732 | server.py:104 | FL starting
DEBUG flwr 2024-04-03 12:21:52,733 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
WARNING flwr 2024-04-03 12:21:52,774 | fedavg.py:250 | No fit_metrics_aggregation_fn provided
INFO flwr 2024-04-03 12:21:53,854 | server.py:125 | fit progress: (1, 2.3058829307556152, {'accuracy': 0.0723, 'data_size': 10000}, 15.990732324000419)
INFO flwr 2024-04-03 12:21:53,854 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-03 12:21:53,854 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
[2m[36m(pid=9898)[0m 2024-04-03 12:21:55.927944: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=9898)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=9913)[0m 2024-04-03 12:21:58.300400: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
DEBUG flwr 2024-04-03 12:21:59,531 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-03 12:22:00,657 | server.py:125 | fit progress: (2, 2.305800676345825, {'accuracy': 0.0738, 'data_size': 10000}, 22.793680868999218)
INFO flwr 2024-04-03 12:22:00,657 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-03 12:22:00,657 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:22:06,142 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-03 12:22:07,298 | server.py:125 | fit progress: (3, 2.3057143688201904, {'accuracy': 0.0747, 'data_size': 10000}, 29.435046422000596)
INFO flwr 2024-04-03 12:22:07,298 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-03 12:22:07,298 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
[2m[36m(DefaultActor pid=9900)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=9900)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=9900)[0m 2024-04-03 12:21:56.192828: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=9900)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=9909)[0m 2024-04-03 12:21:58.468675: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-03 12:22:10,112 | server.py:236 | fit_round 1 received 10 results and 0 failures
WARNING flwr 2024-04-03 12:22:10,273 | fedavg.py:250 | No fit_metrics_aggregation_fn provided
INFO flwr 2024-04-03 12:22:11,603 | server.py:125 | fit progress: (1, 2.305884599685669, {'accuracy': 0.0722, 'data_size': 10000}, 18.87075774999994)
INFO flwr 2024-04-03 12:22:11,604 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-03 12:22:11,604 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:22:12,867 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-03 12:22:13,942 | server.py:125 | fit progress: (4, 2.3056390285491943, {'accuracy': 0.0754, 'data_size': 10000}, 36.07930343699991)
INFO flwr 2024-04-03 12:22:13,942 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-03 12:22:13,943 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:22:19,310 | server.py:236 | fit_round 2 received 10 results and 0 failures
DEBUG flwr 2024-04-03 12:22:19,822 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-03 12:22:20,642 | server.py:125 | fit progress: (2, 2.30580735206604, {'accuracy': 0.0732, 'data_size': 10000}, 27.909474032999924)
INFO flwr 2024-04-03 12:22:20,642 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-03 12:22:20,643 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
INFO flwr 2024-04-03 12:22:20,946 | server.py:125 | fit progress: (5, 2.305558204650879, {'accuracy': 0.0759, 'data_size': 10000}, 43.08295409099992)
INFO flwr 2024-04-03 12:22:20,946 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-03 12:22:20,946 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:22:26,809 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-03 12:22:27,901 | server.py:125 | fit progress: (6, 2.3054816722869873, {'accuracy': 0.0762, 'data_size': 10000}, 50.03782977099945)
INFO flwr 2024-04-03 12:22:27,901 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-03 12:22:27,901 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:22:27,922 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-03 12:22:29,381 | server.py:125 | fit progress: (3, 2.305718183517456, {'accuracy': 0.0746, 'data_size': 10000}, 36.6481837849999)
INFO flwr 2024-04-03 12:22:29,381 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-03 12:22:29,381 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:22:33,618 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-03 12:22:34,999 | server.py:125 | fit progress: (7, 2.305396795272827, {'accuracy': 0.0758, 'data_size': 10000}, 57.135745277999376)
INFO flwr 2024-04-03 12:22:34,999 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-03 12:22:34,999 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:22:36,253 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-03 12:22:37,979 | server.py:125 | fit progress: (4, 2.3056416511535645, {'accuracy': 0.0751, 'data_size': 10000}, 45.24636359399983)
INFO flwr 2024-04-03 12:22:37,979 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-03 12:22:37,980 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:22:40,633 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-03 12:22:42,051 | server.py:125 | fit progress: (8, 2.3053171634674072, {'accuracy': 0.0762, 'data_size': 10000}, 64.18766671999947)
INFO flwr 2024-04-03 12:22:42,051 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-03 12:22:42,051 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:22:45,122 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-03 12:22:46,918 | server.py:125 | fit progress: (5, 2.305565357208252, {'accuracy': 0.0759, 'data_size': 10000}, 54.185609527)
INFO flwr 2024-04-03 12:22:46,919 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-03 12:22:46,919 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:22:47,655 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-03 12:22:49,126 | server.py:125 | fit progress: (9, 2.305223226547241, {'accuracy': 0.0766, 'data_size': 10000}, 71.26283550299922)
INFO flwr 2024-04-03 12:22:49,126 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-03 12:22:49,126 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:22:54,057 | server.py:236 | fit_round 6 received 10 results and 0 failures
DEBUG flwr 2024-04-03 12:22:54,803 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-03 12:22:55,950 | server.py:125 | fit progress: (6, 2.3054752349853516, {'accuracy': 0.0763, 'data_size': 10000}, 63.21723428799987)
INFO flwr 2024-04-03 12:22:55,950 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-03 12:22:55,950 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
INFO flwr 2024-04-03 12:22:56,146 | server.py:125 | fit progress: (10, 2.3051490783691406, {'accuracy': 0.0767, 'data_size': 10000}, 78.28327874299976)
INFO flwr 2024-04-03 12:22:56,146 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-03 12:22:56,146 | server.py:153 | FL finished in 78.28357517800032
INFO flwr 2024-04-03 12:22:56,147 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-03 12:22:56,147 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-03 12:22:56,147 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-03 12:22:56,147 | app.py:229 | app_fit: losses_centralized [(0, 2.3059661388397217), (1, 2.3058829307556152), (2, 2.305800676345825), (3, 2.3057143688201904), (4, 2.3056390285491943), (5, 2.305558204650879), (6, 2.3054816722869873), (7, 2.305396795272827), (8, 2.3053171634674072), (9, 2.305223226547241), (10, 2.3051490783691406)]
INFO flwr 2024-04-03 12:22:56,147 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.072), (1, 0.0723), (2, 0.0738), (3, 0.0747), (4, 0.0754), (5, 0.0759), (6, 0.0762), (7, 0.0758), (8, 0.0762), (9, 0.0766), (10, 0.0767)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.0767
wandb:     loss 2.30515
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240403_122112-fbllunl9
wandb: Find logs at: ./wandb/offline-run-20240403_122112-fbllunl9/logs
DEBUG flwr 2024-04-03 12:23:03,061 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-03 12:23:04,850 | server.py:125 | fit progress: (7, 2.3053970336914062, {'accuracy': 0.0757, 'data_size': 10000}, 72.1177525139999)
INFO flwr 2024-04-03 12:23:04,851 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-03 12:23:04,851 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:23:12,146 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-03 12:23:13,773 | server.py:125 | fit progress: (8, 2.3053171634674072, {'accuracy': 0.0762, 'data_size': 10000}, 81.04015189200004)
INFO flwr 2024-04-03 12:23:13,773 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-03 12:23:13,773 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:23:20,842 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-03 12:23:22,743 | server.py:125 | fit progress: (9, 2.3052315711975098, {'accuracy': 0.0764, 'data_size': 10000}, 90.00998050499993)
INFO flwr 2024-04-03 12:23:22,743 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-03 12:23:22,743 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:23:29,515 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-03 12:23:31,432 | server.py:125 | fit progress: (10, 2.3051459789276123, {'accuracy': 0.0765, 'data_size': 10000}, 98.69933222400005)
INFO flwr 2024-04-03 12:23:31,432 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-03 12:23:31,432 | server.py:153 | FL finished in 98.69984242600003
INFO flwr 2024-04-03 12:23:31,433 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-03 12:23:31,433 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-03 12:23:31,433 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-03 12:23:31,433 | app.py:229 | app_fit: losses_centralized [(0, 2.3059661388397217), (1, 2.305884599685669), (2, 2.30580735206604), (3, 2.305718183517456), (4, 2.3056416511535645), (5, 2.305565357208252), (6, 2.3054752349853516), (7, 2.3053970336914062), (8, 2.3053171634674072), (9, 2.3052315711975098), (10, 2.3051459789276123)]
INFO flwr 2024-04-03 12:23:31,434 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.072), (1, 0.0722), (2, 0.0732), (3, 0.0746), (4, 0.0751), (5, 0.0759), (6, 0.0763), (7, 0.0757), (8, 0.0762), (9, 0.0764), (10, 0.0765)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.0765
wandb:     loss 2.30515
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240403_122131-v0kasaev
wandb: Find logs at: ./wandb/offline-run-20240403_122131-v0kasaev/logs
Using the latest cached version of the dataset since mnist couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'mnist' at .cache/mnist/mnist/1.0.0/b06aab39e05f7bcd9635d18ed25d06eae523c574 (last modified on Tue Apr  2 18:09:57 2024).
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-03 12:30:01,960 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=47358)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=47358)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-03 12:30:06,642	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-03 12:30:06,927	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-03 12:30:07,211	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_820f6cce21a40281.zip' (7.07MiB) to Ray cluster...
2024-04-03 12:30:07,223	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_820f6cce21a40281.zip'.
Using the latest cached version of the dataset since mnist couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'mnist' at .cache/mnist/mnist/1.0.0/b06aab39e05f7bcd9635d18ed25d06eae523c574 (last modified on Tue Apr  2 18:09:57 2024).
INFO flwr 2024-04-03 12:30:23,904 | app.py:213 | Flower VCE: Ray initialized with resources: {'memory': 176358039348.0, 'CPU': 128.0, 'node:__internal_head__': 1.0, 'GPU': 1.0, 'object_store_memory': 79867731148.0, 'node:10.20.240.17': 1.0}
INFO flwr 2024-04-03 12:30:23,904 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-03 12:30:23,905 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-03 12:30:23,925 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-03 12:30:23,926 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-03 12:30:23,926 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-03 12:30:23,927 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-03 12:30:25,925 | server.py:94 | initial parameters (loss, other metrics): 2.305924892425537, {'accuracy': 0.0699, 'data_size': 10000}
INFO flwr 2024-04-03 12:30:25,926 | server.py:104 | FL starting
DEBUG flwr 2024-04-03 12:30:25,926 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=53238)[0m 2024-04-03 12:30:28.909462: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=53238)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=53235)[0m 2024-04-03 12:30:30.533590: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=53225)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=53225)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=53229)[0m 2024-04-03 12:30:29.119863: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=53229)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=53229)[0m 2024-04-03 12:30:30.611684: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-03 12:30:39,631 | server.py:236 | fit_round 1 received 10 results and 0 failures
WARNING flwr 2024-04-03 12:30:39,663 | fedavg.py:250 | No fit_metrics_aggregation_fn provided
INFO flwr 2024-04-03 12:30:40,745 | server.py:125 | fit progress: (1, 2.3057732582092285, {'accuracy': 0.0714, 'data_size': 10000}, 14.819497160999163)
INFO flwr 2024-04-03 12:30:40,745 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-03 12:30:40,746 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-03 12:30:43,221 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=9899)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=9899)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-03 12:30:46,761 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-03 12:30:47,902 | server.py:125 | fit progress: (2, 2.305636405944824, {'accuracy': 0.0734, 'data_size': 10000}, 21.976371379998454)
INFO flwr 2024-04-03 12:30:47,902 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-03 12:30:47,902 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
2024-04-03 12:30:47,903	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-03 12:30:48,185	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-03 12:30:48,518	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_3b11589eb907ee13.zip' (7.08MiB) to Ray cluster...
2024-04-03 12:30:48,536	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_3b11589eb907ee13.zip'.
DEBUG flwr 2024-04-03 12:30:53,627 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-03 12:30:54,630 | server.py:125 | fit progress: (3, 2.3054966926574707, {'accuracy': 0.074, 'data_size': 10000}, 28.703850262998458)
INFO flwr 2024-04-03 12:30:54,630 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-03 12:30:54,630 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
INFO flwr 2024-04-03 12:30:59,643 | app.py:213 | Flower VCE: Ray initialized with resources: {'accelerator_type:TITAN': 1.0, 'memory': 176791247463.0, 'GPU': 1.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0, 'CPU': 64.0, 'object_store_memory': 80053391769.0}
INFO flwr 2024-04-03 12:30:59,644 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-03 12:30:59,644 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-03 12:30:59,666 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-03 12:30:59,668 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-03 12:30:59,668 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-03 12:30:59,668 | server.py:91 | Evaluating initial parameters
DEBUG flwr 2024-04-03 12:31:00,488 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-03 12:31:01,492 | server.py:125 | fit progress: (4, 2.3053154945373535, {'accuracy': 0.0754, 'data_size': 10000}, 35.56647354799861)
INFO flwr 2024-04-03 12:31:01,492 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-03 12:31:01,493 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
INFO flwr 2024-04-03 12:31:02,848 | server.py:94 | initial parameters (loss, other metrics): 2.305924892425537, {'accuracy': 0.0699, 'data_size': 10000}
INFO flwr 2024-04-03 12:31:02,848 | server.py:104 | FL starting
DEBUG flwr 2024-04-03 12:31:02,849 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=14633)[0m 2024-04-03 12:31:05.812679: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=14633)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
DEBUG flwr 2024-04-03 12:31:07,304 | server.py:236 | fit_round 5 received 10 results and 0 failures
[2m[36m(pid=14633)[0m 2024-04-03 12:31:08.048643: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
INFO flwr 2024-04-03 12:31:08,522 | server.py:125 | fit progress: (5, 2.305140495300293, {'accuracy': 0.0767, 'data_size': 10000}, 42.59668849599984)
INFO flwr 2024-04-03 12:31:08,523 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-03 12:31:08,523 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:31:14,211 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-03 12:31:15,449 | server.py:125 | fit progress: (6, 2.305006742477417, {'accuracy': 0.0787, 'data_size': 10000}, 49.52334765999876)
INFO flwr 2024-04-03 12:31:15,449 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-03 12:31:15,449 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
[2m[36m(DefaultActor pid=14633)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=14633)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=14628)[0m 2024-04-03 12:31:06.206820: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=14628)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=14628)[0m 2024-04-03 12:31:08.578891: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-03 12:31:19,306 | server.py:236 | fit_round 1 received 10 results and 0 failures
WARNING flwr 2024-04-03 12:31:19,544 | fedavg.py:250 | No fit_metrics_aggregation_fn provided
INFO flwr 2024-04-03 12:31:20,658 | server.py:125 | fit progress: (1, 2.3057644367218018, {'accuracy': 0.0716, 'data_size': 10000}, 17.809611681999968)
INFO flwr 2024-04-03 12:31:20,658 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-03 12:31:20,659 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:31:21,165 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-03 12:31:22,475 | server.py:125 | fit progress: (7, 2.304821729660034, {'accuracy': 0.0818, 'data_size': 10000}, 56.54938030099947)
INFO flwr 2024-04-03 12:31:22,475 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-03 12:31:22,475 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:31:28,171 | server.py:236 | fit_round 8 received 10 results and 0 failures
DEBUG flwr 2024-04-03 12:31:28,300 | server.py:236 | fit_round 2 received 10 results and 0 failures
ERROR flwr 2024-04-03 12:31:28,306 | app.py:313 | No data left in file
INFO flwr 2024-04-03 12:31:29,473 | server.py:125 | fit progress: (8, 2.304655075073242, {'accuracy': 0.0841, 'data_size': 10000}, 63.54681550599889)
INFO flwr 2024-04-03 12:31:29,473 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-03 12:31:29,473 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
ERROR flwr 2024-04-03 12:31:33,249 | app.py:314 | Traceback (most recent call last):
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/app.py", line 308, in start_simulation
    hist = run_fl(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/server/app.py", line 225, in run_fl
    hist = server.fit(num_rounds=config.num_rounds, timeout=config.round_timeout)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/server/server.py", line 109, in fit
    res_fit = self.fit_round(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/server/server.py", line 248, in fit_round
    ] = self.strategy.aggregate_fit(server_round, results, failures)
  File "/home/s2240084/conFEDential/src/server_aggregation_strategies/capture_generator.py", line 82, in aggregate_fit
    self._capture_parameters(captured_parameters)
  File "/home/s2240084/conFEDential/src/server_aggregation_strategies/capture_generator.py", line 35, in _capture_parameters
    captures = self._load_npz_file(captured_parameters)
  File "/home/s2240084/conFEDential/src/server_aggregation_strategies/capture_generator.py", line 64, in _load_npz_file
    npz_file = np.load(self.output_path)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/numpy/lib/npyio.py", line 436, in load
    raise EOFError("No data left in file")
EOFError: No data left in file

ERROR flwr 2024-04-03 12:31:33,249 | app.py:315 | Your simulation crashed :(. This could be because of several reasons. The most common are: 
	 > Sometimes, issues in the simulation code itself can cause crashes. It's always a good idea to double-check your code for any potential bugs or inconsistencies that might be contributing to the problem. For example: 
		 - You might be using a class attribute in your clients that hasn't been defined.
		 - There could be an incorrect method call to a 3rd party library (e.g., PyTorch).
		 - The return types of methods in your clients/strategies might be incorrect.
	 > Your system couldn't fit a single VirtualClient: try lowering `client_resources`.
	 > All the actors in your pool crashed. This could be because: 
		 - You clients hit an out-of-memory (OOM) error and actors couldn't recover from it. Try launching your simulation with more generous `client_resources` setting (i.e. it seems {'num_cpus': 8, 'num_gpus': 0.125} is not enough for your run). Use fewer concurrent actors. 
		 - You were running a multi-node simulation and all worker nodes disconnected. The head node might still be alive but cannot accommodate any actor with resources: {'num_cpus': 8, 'num_gpus': 0.125}.
Take a look at the Flower simulation examples for guidance <https://flower.dev/docs/framework/how-to-run-simulations.html>.
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.0716
wandb:     loss 2.30576
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240403_123042-992hkphp
wandb: Find logs at: ./wandb/offline-run-20240403_123042-992hkphp/logs
DEBUG flwr 2024-04-03 12:31:35,196 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-03 12:31:36,502 | server.py:125 | fit progress: (9, 2.30448579788208, {'accuracy': 0.0873, 'data_size': 10000}, 70.57579234900004)
INFO flwr 2024-04-03 12:31:36,502 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-03 12:31:36,502 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:31:42,017 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-03 12:31:43,373 | server.py:125 | fit progress: (10, 2.3043105602264404, {'accuracy': 0.089, 'data_size': 10000}, 77.44691212899852)
INFO flwr 2024-04-03 12:31:43,373 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-03 12:31:43,373 | server.py:153 | FL finished in 77.44727327699911
INFO flwr 2024-04-03 12:31:43,373 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-03 12:31:43,373 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-03 12:31:43,373 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-03 12:31:43,373 | app.py:229 | app_fit: losses_centralized [(0, 2.305924892425537), (1, 2.3057732582092285), (2, 2.305636405944824), (3, 2.3054966926574707), (4, 2.3053154945373535), (5, 2.305140495300293), (6, 2.305006742477417), (7, 2.304821729660034), (8, 2.304655075073242), (9, 2.30448579788208), (10, 2.3043105602264404)]
INFO flwr 2024-04-03 12:31:43,374 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0699), (1, 0.0714), (2, 0.0734), (3, 0.074), (4, 0.0754), (5, 0.0767), (6, 0.0787), (7, 0.0818), (8, 0.0841), (9, 0.0873), (10, 0.089)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.089
wandb:     loss 2.30431
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240403_123001-yw0scaku
wandb: Find logs at: ./wandb/offline-run-20240403_123001-yw0scaku/logs
Using the latest cached version of the dataset since mnist couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'mnist' at .cache/mnist/mnist/1.0.0/b06aab39e05f7bcd9635d18ed25d06eae523c574 (last modified on Tue Apr  2 18:09:57 2024).
Using the latest cached version of the dataset since mnist couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'mnist' at .cache/mnist/mnist/1.0.0/b06aab39e05f7bcd9635d18ed25d06eae523c574 (last modified on Tue Apr  2 18:09:57 2024).
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-03 12:38:44,513 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=14628)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=14628)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
2024-04-03 12:38:49,284	INFO worker.py:1621 -- Started a local Ray instance.
INFO flwr 2024-04-03 12:38:49,531 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=53229)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=53229)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-03 12:38:49,748	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-03 12:38:50,038	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_b492779346c167cb.zip' (7.09MiB) to Ray cluster...
2024-04-03 12:38:50,054	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_b492779346c167cb.zip'.
2024-04-03 12:38:54,262	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-03 12:38:54,582	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-03 12:38:54,867	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_9cc1f0cc4cf60bf5.zip' (7.09MiB) to Ray cluster...
2024-04-03 12:38:54,877	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_9cc1f0cc4cf60bf5.zip'.
INFO flwr 2024-04-03 12:39:01,523 | app.py:213 | Flower VCE: Ray initialized with resources: {'CPU': 64.0, 'object_store_memory': 80027444428.0, 'GPU': 1.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0, 'accelerator_type:TITAN': 1.0, 'memory': 176730703668.0}
INFO flwr 2024-04-03 12:39:01,523 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-03 12:39:01,523 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-03 12:39:01,540 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-03 12:39:01,541 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-03 12:39:01,541 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-03 12:39:01,542 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-03 12:39:04,126 | server.py:94 | initial parameters (loss, other metrics): 2.3023934364318848, {'accuracy': 0.1184, 'data_size': 10000}
INFO flwr 2024-04-03 12:39:04,126 | server.py:104 | FL starting
DEBUG flwr 2024-04-03 12:39:04,127 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=18905)[0m 2024-04-03 12:39:08.140433: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=18905)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=18905)[0m 2024-04-03 12:39:10.394522: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
INFO flwr 2024-04-03 12:39:14,212 | app.py:213 | Flower VCE: Ray initialized with resources: {'memory': 176255307572.0, 'node:10.20.240.17': 1.0, 'object_store_memory': 79823703244.0, 'node:__internal_head__': 1.0, 'CPU': 128.0, 'GPU': 1.0}
INFO flwr 2024-04-03 12:39:14,213 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-03 12:39:14,213 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-03 12:39:14,229 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-03 12:39:14,230 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-03 12:39:14,230 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-03 12:39:14,231 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-03 12:39:16,448 | server.py:94 | initial parameters (loss, other metrics): 2.3039772510528564, {'accuracy': 0.0858, 'data_size': 10000}
INFO flwr 2024-04-03 12:39:16,448 | server.py:104 | FL starting
DEBUG flwr 2024-04-03 12:39:16,448 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=59426)[0m 2024-04-03 12:39:19.172661: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=59426)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(DefaultActor pid=18902)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=18902)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=18903)[0m 2024-04-03 12:39:08.415003: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=18903)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=18903)[0m 2024-04-03 12:39:10.923536: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
[2m[36m(pid=59426)[0m 2024-04-03 12:39:20.798369: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
DEBUG flwr 2024-04-03 12:39:22,609 | server.py:236 | fit_round 1 received 10 results and 0 failures
WARNING flwr 2024-04-03 12:39:22,648 | fedavg.py:250 | No fit_metrics_aggregation_fn provided
INFO flwr 2024-04-03 12:39:23,992 | server.py:125 | fit progress: (1, 2.3020565509796143, {'accuracy': 0.1243, 'data_size': 10000}, 19.865853958000116)
INFO flwr 2024-04-03 12:39:23,993 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-03 12:39:23,993 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
[2m[36m(DefaultActor pid=59426)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=59426)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=59425)[0m 2024-04-03 12:39:19.446367: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=59425)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=59422)[0m 2024-04-03 12:39:20.952996: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-03 12:39:30,250 | server.py:236 | fit_round 1 received 10 results and 0 failures
WARNING flwr 2024-04-03 12:39:30,317 | fedavg.py:250 | No fit_metrics_aggregation_fn provided
INFO flwr 2024-04-03 12:39:31,201 | server.py:125 | fit progress: (1, 2.30364727973938, {'accuracy': 0.0875, 'data_size': 10000}, 14.753040237999812)
INFO flwr 2024-04-03 12:39:31,202 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-03 12:39:31,202 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:39:31,726 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-03 12:39:33,462 | server.py:125 | fit progress: (2, 2.3017163276672363, {'accuracy': 0.1284, 'data_size': 10000}, 29.335797252999782)
INFO flwr 2024-04-03 12:39:33,463 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-03 12:39:33,463 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:39:37,515 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-03 12:39:38,515 | server.py:125 | fit progress: (2, 2.3032991886138916, {'accuracy': 0.0891, 'data_size': 10000}, 22.06664940799965)
INFO flwr 2024-04-03 12:39:38,515 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-03 12:39:38,515 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:39:40,336 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-03 12:39:41,848 | server.py:125 | fit progress: (3, 2.3013813495635986, {'accuracy': 0.1317, 'data_size': 10000}, 37.721354491000056)
INFO flwr 2024-04-03 12:39:41,848 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-03 12:39:41,848 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:39:44,334 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-03 12:39:45,599 | server.py:125 | fit progress: (3, 2.3029911518096924, {'accuracy': 0.0898, 'data_size': 10000}, 29.150835229000222)
INFO flwr 2024-04-03 12:39:45,599 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-03 12:39:45,600 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:39:48,902 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-03 12:39:50,312 | server.py:125 | fit progress: (4, 2.301072359085083, {'accuracy': 0.1317, 'data_size': 10000}, 46.18590125599985)
INFO flwr 2024-04-03 12:39:50,313 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-03 12:39:50,313 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:39:51,278 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-03 12:39:53,508 | server.py:125 | fit progress: (4, 2.3027355670928955, {'accuracy': 0.0918, 'data_size': 10000}, 37.05912585099941)
INFO flwr 2024-04-03 12:39:53,508 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-03 12:39:53,508 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:39:57,794 | server.py:236 | fit_round 5 received 10 results and 0 failures
DEBUG flwr 2024-04-03 12:39:59,117 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-03 12:39:59,246 | server.py:125 | fit progress: (5, 2.3007638454437256, {'accuracy': 0.1339, 'data_size': 10000}, 55.119891601999825)
INFO flwr 2024-04-03 12:39:59,247 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-03 12:39:59,247 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
INFO flwr 2024-04-03 12:40:00,502 | server.py:125 | fit progress: (5, 2.3023860454559326, {'accuracy': 0.0948, 'data_size': 10000}, 44.05372645699936)
INFO flwr 2024-04-03 12:40:00,502 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-03 12:40:00,502 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:40:06,270 | server.py:236 | fit_round 6 received 10 results and 0 failures
DEBUG flwr 2024-04-03 12:40:06,621 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-03 12:40:07,633 | server.py:125 | fit progress: (6, 2.3020262718200684, {'accuracy': 0.0962, 'data_size': 10000}, 51.185061987000154)
INFO flwr 2024-04-03 12:40:07,634 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-03 12:40:07,634 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
INFO flwr 2024-04-03 12:40:08,232 | server.py:125 | fit progress: (6, 2.300494909286499, {'accuracy': 0.139, 'data_size': 10000}, 64.10508194800013)
INFO flwr 2024-04-03 12:40:08,232 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-03 12:40:08,232 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:40:13,466 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-03 12:40:14,798 | server.py:125 | fit progress: (7, 2.3016903400421143, {'accuracy': 0.0986, 'data_size': 10000}, 58.3497577800008)
INFO flwr 2024-04-03 12:40:14,798 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-03 12:40:14,799 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:40:15,321 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-03 12:40:17,210 | server.py:125 | fit progress: (7, 2.3001387119293213, {'accuracy': 0.1426, 'data_size': 10000}, 73.0832257359998)
INFO flwr 2024-04-03 12:40:17,210 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-03 12:40:17,210 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:40:20,815 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-03 12:40:22,157 | server.py:125 | fit progress: (8, 2.301401138305664, {'accuracy': 0.0998, 'data_size': 10000}, 65.70869174499967)
INFO flwr 2024-04-03 12:40:22,157 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-03 12:40:22,157 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:40:24,336 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-03 12:40:26,250 | server.py:125 | fit progress: (8, 2.2997941970825195, {'accuracy': 0.1452, 'data_size': 10000}, 82.12301357099977)
INFO flwr 2024-04-03 12:40:26,250 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-03 12:40:26,250 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:40:28,060 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-03 12:40:29,611 | server.py:125 | fit progress: (9, 2.3010573387145996, {'accuracy': 0.1005, 'data_size': 10000}, 73.16276060000018)
INFO flwr 2024-04-03 12:40:29,611 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-03 12:40:29,612 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:40:33,461 | server.py:236 | fit_round 9 received 10 results and 0 failures
DEBUG flwr 2024-04-03 12:40:35,370 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-03 12:40:35,469 | server.py:125 | fit progress: (9, 2.299424171447754, {'accuracy': 0.1544, 'data_size': 10000}, 91.34210820299995)
INFO flwr 2024-04-03 12:40:35,469 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-03 12:40:35,469 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
INFO flwr 2024-04-03 12:40:37,083 | server.py:125 | fit progress: (10, 2.3007335662841797, {'accuracy': 0.1017, 'data_size': 10000}, 80.63414890099921)
INFO flwr 2024-04-03 12:40:37,083 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-03 12:40:37,083 | server.py:153 | FL finished in 80.63445298999977
INFO flwr 2024-04-03 12:40:37,083 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-03 12:40:37,083 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-03 12:40:37,083 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-03 12:40:37,083 | app.py:229 | app_fit: losses_centralized [(0, 2.3039772510528564), (1, 2.30364727973938), (2, 2.3032991886138916), (3, 2.3029911518096924), (4, 2.3027355670928955), (5, 2.3023860454559326), (6, 2.3020262718200684), (7, 2.3016903400421143), (8, 2.301401138305664), (9, 2.3010573387145996), (10, 2.3007335662841797)]
INFO flwr 2024-04-03 12:40:37,083 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0858), (1, 0.0875), (2, 0.0891), (3, 0.0898), (4, 0.0918), (5, 0.0948), (6, 0.0962), (7, 0.0986), (8, 0.0998), (9, 0.1005), (10, 0.1017)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.1017
wandb:     loss 2.30073
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240403_123849-dl7akq5l
wandb: Find logs at: ./wandb/offline-run-20240403_123849-dl7akq5l/logs
DEBUG flwr 2024-04-03 12:40:42,633 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-03 12:40:44,604 | server.py:125 | fit progress: (10, 2.2990598678588867, {'accuracy': 0.1602, 'data_size': 10000}, 100.47764935199984)
INFO flwr 2024-04-03 12:40:44,605 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-03 12:40:44,605 | server.py:153 | FL finished in 100.47831891799979
INFO flwr 2024-04-03 12:40:44,605 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-03 12:40:44,605 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-03 12:40:44,606 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-03 12:40:44,606 | app.py:229 | app_fit: losses_centralized [(0, 2.3023934364318848), (1, 2.3020565509796143), (2, 2.3017163276672363), (3, 2.3013813495635986), (4, 2.301072359085083), (5, 2.3007638454437256), (6, 2.300494909286499), (7, 2.3001387119293213), (8, 2.2997941970825195), (9, 2.299424171447754), (10, 2.2990598678588867)]
INFO flwr 2024-04-03 12:40:44,606 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.1184), (1, 0.1243), (2, 0.1284), (3, 0.1317), (4, 0.1317), (5, 0.1339), (6, 0.139), (7, 0.1426), (8, 0.1452), (9, 0.1544), (10, 0.1602)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.1602
wandb:     loss 2.29906
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240403_123844-v9ccq024
wandb: Find logs at: ./wandb/offline-run-20240403_123844-v9ccq024/logs
Using the latest cached version of the dataset since mnist couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'mnist' at .cache/mnist/mnist/1.0.0/b06aab39e05f7bcd9635d18ed25d06eae523c574 (last modified on Tue Apr  2 18:09:57 2024).
Using the latest cached version of the dataset since mnist couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'mnist' at .cache/mnist/mnist/1.0.0/b06aab39e05f7bcd9635d18ed25d06eae523c574 (last modified on Tue Apr  2 18:09:57 2024).
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-03 12:47:42,683 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=59416)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=59416)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-03 12:47:47,511	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-03 12:47:47,790	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-03 12:47:48,069	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_dc2163a04a59a257.zip' (7.11MiB) to Ray cluster...
2024-04-03 12:47:48,080	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_dc2163a04a59a257.zip'.
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-03 12:47:56,298 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=18899)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=18899)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-03 12:48:00,940	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-03 12:48:01,237	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-03 12:48:01,539	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_bae0e7fe3b46bec8.zip' (7.11MiB) to Ray cluster...
2024-04-03 12:48:01,557	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_bae0e7fe3b46bec8.zip'.
INFO flwr 2024-04-03 12:48:05,564 | app.py:213 | Flower VCE: Ray initialized with resources: {'CPU': 128.0, 'node:__internal_head__': 1.0, 'GPU': 1.0, 'node:10.20.240.17': 1.0, 'object_store_memory': 79780694016.0, 'memory': 176154952704.0}
INFO flwr 2024-04-03 12:48:05,564 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-03 12:48:05,564 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-03 12:48:05,579 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-03 12:48:05,580 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-03 12:48:05,581 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-03 12:48:05,581 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-03 12:48:07,540 | server.py:94 | initial parameters (loss, other metrics): 2.301401138305664, {'accuracy': 0.1012, 'data_size': 10000}
INFO flwr 2024-04-03 12:48:07,540 | server.py:104 | FL starting
DEBUG flwr 2024-04-03 12:48:07,541 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=65905)[0m 2024-04-03 12:48:10.761028: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=65905)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=65905)[0m 2024-04-03 12:48:12.395818: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
INFO flwr 2024-04-03 12:48:13,494 | app.py:213 | Flower VCE: Ray initialized with resources: {'GPU': 1.0, 'node:__internal_head__': 1.0, 'node:10.20.240.12': 1.0, 'CPU': 64.0, 'object_store_memory': 80021606400.0, 'memory': 176717081600.0, 'accelerator_type:TITAN': 1.0}
INFO flwr 2024-04-03 12:48:13,494 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-03 12:48:13,494 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-03 12:48:13,510 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-03 12:48:13,512 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-03 12:48:13,513 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-03 12:48:13,513 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-03 12:48:16,986 | server.py:94 | initial parameters (loss, other metrics): 2.304647207260132, {'accuracy': 0.0807, 'data_size': 10000}
INFO flwr 2024-04-03 12:48:16,987 | server.py:104 | FL starting
DEBUG flwr 2024-04-03 12:48:16,987 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=23290)[0m 2024-04-03 12:48:19.461356: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=23290)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(DefaultActor pid=65905)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=65905)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=65908)[0m 2024-04-03 12:48:10.915442: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=65908)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=65902)[0m 2024-04-03 12:48:12.539363: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-03 12:48:21,643 | server.py:236 | fit_round 1 received 10 results and 0 failures
WARNING flwr 2024-04-03 12:48:21,714 | fedavg.py:250 | No fit_metrics_aggregation_fn provided
[2m[36m(pid=23286)[0m 2024-04-03 12:48:21.749606: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
INFO flwr 2024-04-03 12:48:22,804 | server.py:125 | fit progress: (1, 2.3004043102264404, {'accuracy': 0.121, 'data_size': 10000}, 15.263253785000416)
INFO flwr 2024-04-03 12:48:22,804 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-03 12:48:22,804 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:48:28,737 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-03 12:48:29,673 | server.py:125 | fit progress: (2, 2.299384832382202, {'accuracy': 0.1473, 'data_size': 10000}, 22.13302232500064)
INFO flwr 2024-04-03 12:48:29,674 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-03 12:48:29,674 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
[2m[36m(DefaultActor pid=23291)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=23291)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=23288)[0m 2024-04-03 12:48:19.622050: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=23288)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=23288)[0m 2024-04-03 12:48:21.910448: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-03 12:48:32,836 | server.py:236 | fit_round 1 received 10 results and 0 failures
WARNING flwr 2024-04-03 12:48:32,939 | fedavg.py:250 | No fit_metrics_aggregation_fn provided
INFO flwr 2024-04-03 12:48:34,308 | server.py:125 | fit progress: (1, 2.3037612438201904, {'accuracy': 0.0866, 'data_size': 10000}, 17.321137615000225)
INFO flwr 2024-04-03 12:48:34,309 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-03 12:48:34,309 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:48:35,283 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-03 12:48:36,331 | server.py:125 | fit progress: (3, 2.2984354496002197, {'accuracy': 0.1646, 'data_size': 10000}, 28.79026084600082)
INFO flwr 2024-04-03 12:48:36,331 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-03 12:48:36,331 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:48:41,995 | server.py:236 | fit_round 2 received 10 results and 0 failures
DEBUG flwr 2024-04-03 12:48:42,104 | server.py:236 | fit_round 4 received 10 results and 0 failures
ERROR flwr 2024-04-03 12:48:42,110 | app.py:313 | No data left in file
ERROR flwr 2024-04-03 12:48:42,131 | app.py:314 | Traceback (most recent call last):
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/app.py", line 308, in start_simulation
    hist = run_fl(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/server/app.py", line 225, in run_fl
    hist = server.fit(num_rounds=config.num_rounds, timeout=config.round_timeout)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/server/server.py", line 109, in fit
    res_fit = self.fit_round(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/server/server.py", line 248, in fit_round
    ] = self.strategy.aggregate_fit(server_round, results, failures)
  File "/home/s2240084/conFEDential/src/server_aggregation_strategies/capture_generator.py", line 82, in aggregate_fit
    self._capture_parameters(captured_parameters)
  File "/home/s2240084/conFEDential/src/server_aggregation_strategies/capture_generator.py", line 35, in _capture_parameters
    captures = self._load_npz_file(captured_parameters)
  File "/home/s2240084/conFEDential/src/server_aggregation_strategies/capture_generator.py", line 64, in _load_npz_file
    npz_file = np.load(self.output_path)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/numpy/lib/npyio.py", line 436, in load
    raise EOFError("No data left in file")
EOFError: No data left in file

ERROR flwr 2024-04-03 12:48:42,132 | app.py:315 | Your simulation crashed :(. This could be because of several reasons. The most common are: 
	 > Sometimes, issues in the simulation code itself can cause crashes. It's always a good idea to double-check your code for any potential bugs or inconsistencies that might be contributing to the problem. For example: 
		 - You might be using a class attribute in your clients that hasn't been defined.
		 - There could be an incorrect method call to a 3rd party library (e.g., PyTorch).
		 - The return types of methods in your clients/strategies might be incorrect.
	 > Your system couldn't fit a single VirtualClient: try lowering `client_resources`.
	 > All the actors in your pool crashed. This could be because: 
		 - You clients hit an out-of-memory (OOM) error and actors couldn't recover from it. Try launching your simulation with more generous `client_resources` setting (i.e. it seems {'num_cpus': 8, 'num_gpus': 0.125} is not enough for your run). Use fewer concurrent actors. 
		 - You were running a multi-node simulation and all worker nodes disconnected. The head node might still be alive but cannot accommodate any actor with resources: {'num_cpus': 8, 'num_gpus': 0.125}.
Take a look at the Flower simulation examples for guidance <https://flower.dev/docs/framework/how-to-run-simulations.html>.
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.1646
wandb:     loss 2.29844
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240403_124742-e701wf0a
wandb: Find logs at: ./wandb/offline-run-20240403_124742-e701wf0a/logs
INFO flwr 2024-04-03 12:48:43,515 | server.py:125 | fit progress: (2, 2.3028438091278076, {'accuracy': 0.092, 'data_size': 10000}, 26.52752736100001)
INFO flwr 2024-04-03 12:48:43,515 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-03 12:48:43,515 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:48:50,278 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-03 12:48:51,579 | server.py:125 | fit progress: (3, 2.301943063735962, {'accuracy': 0.0994, 'data_size': 10000}, 34.59164358499993)
INFO flwr 2024-04-03 12:48:51,579 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-03 12:48:51,579 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:48:58,739 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-03 12:49:00,103 | server.py:125 | fit progress: (4, 2.301018714904785, {'accuracy': 0.1111, 'data_size': 10000}, 43.11548899399986)
INFO flwr 2024-04-03 12:49:00,103 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-03 12:49:00,103 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:49:07,137 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-03 12:49:08,712 | server.py:125 | fit progress: (5, 2.3000476360321045, {'accuracy': 0.1292, 'data_size': 10000}, 51.724592034000125)
INFO flwr 2024-04-03 12:49:08,712 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-03 12:49:08,712 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:49:15,773 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-03 12:49:17,400 | server.py:125 | fit progress: (6, 2.29923415184021, {'accuracy': 0.1404, 'data_size': 10000}, 60.41260619000013)
INFO flwr 2024-04-03 12:49:17,400 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-03 12:49:17,400 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:49:24,136 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-03 12:49:25,783 | server.py:125 | fit progress: (7, 2.298532724380493, {'accuracy': 0.1493, 'data_size': 10000}, 68.79610346400023)
INFO flwr 2024-04-03 12:49:25,783 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-03 12:49:25,784 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:49:32,908 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-03 12:49:36,992 | server.py:125 | fit progress: (8, 2.297240972518921, {'accuracy': 0.1695, 'data_size': 10000}, 80.00461217400016)
INFO flwr 2024-04-03 12:49:36,992 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-03 12:49:36,992 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:49:43,978 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-03 12:49:45,669 | server.py:125 | fit progress: (9, 2.296128511428833, {'accuracy': 0.1868, 'data_size': 10000}, 88.68151944400006)
INFO flwr 2024-04-03 12:49:45,669 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-03 12:49:45,669 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 12:49:52,752 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-03 12:49:54,608 | server.py:125 | fit progress: (10, 2.2950923442840576, {'accuracy': 0.1961, 'data_size': 10000}, 97.62096742299991)
INFO flwr 2024-04-03 12:49:54,608 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-03 12:49:54,609 | server.py:153 | FL finished in 97.62151147099985
INFO flwr 2024-04-03 12:49:54,609 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-03 12:49:54,609 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-03 12:49:54,609 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-03 12:49:54,609 | app.py:229 | app_fit: losses_centralized [(0, 2.304647207260132), (1, 2.3037612438201904), (2, 2.3028438091278076), (3, 2.301943063735962), (4, 2.301018714904785), (5, 2.3000476360321045), (6, 2.29923415184021), (7, 2.298532724380493), (8, 2.297240972518921), (9, 2.296128511428833), (10, 2.2950923442840576)]
INFO flwr 2024-04-03 12:49:54,609 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0807), (1, 0.0866), (2, 0.092), (3, 0.0994), (4, 0.1111), (5, 0.1292), (6, 0.1404), (7, 0.1493), (8, 0.1695), (9, 0.1868), (10, 0.1961)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.1961
wandb:     loss 2.29509
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240403_124755-b477iqpu
wandb: Find logs at: ./wandb/offline-run-20240403_124755-b477iqpu/logs
Using the latest cached version of the dataset since mnist couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'mnist' at .cache/mnist/mnist/1.0.0/b06aab39e05f7bcd9635d18ed25d06eae523c574 (last modified on Tue Apr  2 18:09:57 2024).
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-03 12:56:05,862 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=65903)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=65903)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-03 12:56:28,656	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-03 12:56:30,577	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-03 12:56:32,329	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_00b04a324b08000a.zip' (7.13MiB) to Ray cluster...
2024-04-03 12:56:32,340	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_00b04a324b08000a.zip'.
Using the latest cached version of the dataset since mnist couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'mnist' at .cache/mnist/mnist/1.0.0/b06aab39e05f7bcd9635d18ed25d06eae523c574 (last modified on Tue Apr  2 18:09:57 2024).
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-03 12:57:22,147 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=23283)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=23283)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-03 12:57:40,464	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-03 12:57:43,999	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-03 12:57:47,061	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_612b0be243abee02.zip' (7.13MiB) to Ray cluster...
2024-04-03 12:57:47,078	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_612b0be243abee02.zip'.
INFO flwr 2024-04-03 12:58:30,061 | app.py:213 | Flower VCE: Ray initialized with resources: {'GPU': 1.0, 'object_store_memory': 80002133606.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0, 'memory': 176671645082.0, 'accelerator_type:TITAN': 1.0, 'CPU': 64.0}
INFO flwr 2024-04-03 12:58:30,061 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-03 12:58:30,061 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-03 12:58:30,080 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-03 12:58:30,081 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-03 12:58:30,081 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-03 12:58:30,082 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-03 12:58:32,805 | server.py:94 | initial parameters (loss, other metrics): 2.302874803543091, {'accuracy': 0.1004, 'data_size': 10000}
INFO flwr 2024-04-03 12:58:32,806 | server.py:104 | FL starting
DEBUG flwr 2024-04-03 12:58:32,806 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=28016)[0m 2024-04-03 12:59:05.612498: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=28016)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=28016)[0m 2024-04-03 12:59:24.501922: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(pid=28014)[0m 2024-04-03 12:59:05.614191: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=28014)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=28016)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=28016)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=28014)[0m 2024-04-03 12:59:24.501368: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-03 13:00:10,648 | server.py:236 | fit_round 1 received 10 results and 0 failures
WARNING flwr 2024-04-03 13:00:10,690 | fedavg.py:250 | No fit_metrics_aggregation_fn provided
INFO flwr 2024-04-03 13:00:11,825 | server.py:125 | fit progress: (1, 2.29577898979187, {'accuracy': 0.128, 'data_size': 10000}, 99.01907136)
INFO flwr 2024-04-03 13:00:11,825 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-03 13:00:11,825 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:00:19,716 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-03 13:00:22,392 | server.py:125 | fit progress: (2, 2.288989782333374, {'accuracy': 0.1467, 'data_size': 10000}, 109.58618873800015)
INFO flwr 2024-04-03 13:00:22,393 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-03 13:00:22,393 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:00:29,234 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-03 13:00:30,744 | server.py:125 | fit progress: (3, 2.281754970550537, {'accuracy': 0.1433, 'data_size': 10000}, 117.93831687700003)
INFO flwr 2024-04-03 13:00:30,745 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-03 13:00:30,745 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:00:37,557 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-03 13:00:39,087 | server.py:125 | fit progress: (4, 2.274744987487793, {'accuracy': 0.2038, 'data_size': 10000}, 126.28066860799981)
INFO flwr 2024-04-03 13:00:39,087 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-03 13:00:39,087 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:00:46,203 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-03 13:00:47,758 | server.py:125 | fit progress: (5, 2.2655112743377686, {'accuracy': 0.2431, 'data_size': 10000}, 134.95165932700002)
INFO flwr 2024-04-03 13:00:47,758 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-03 13:00:47,758 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:00:54,789 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-03 13:00:56,382 | server.py:125 | fit progress: (6, 2.2526731491088867, {'accuracy': 0.2135, 'data_size': 10000}, 143.57650719000003)
INFO flwr 2024-04-03 13:00:56,383 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-03 13:00:56,383 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:01:03,524 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-03 13:01:05,124 | server.py:125 | fit progress: (7, 2.2451117038726807, {'accuracy': 0.2636, 'data_size': 10000}, 152.31806979800012)
INFO flwr 2024-04-03 13:01:05,124 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-03 13:01:05,124 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:01:11,880 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-03 13:01:13,575 | server.py:125 | fit progress: (8, 2.2355666160583496, {'accuracy': 0.2554, 'data_size': 10000}, 160.7688224550002)
INFO flwr 2024-04-03 13:01:13,575 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-03 13:01:13,575 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:01:20,513 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-03 13:01:23,332 | server.py:125 | fit progress: (9, 2.228618621826172, {'accuracy': 0.324, 'data_size': 10000}, 170.52653858299982)
INFO flwr 2024-04-03 13:01:23,333 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-03 13:01:23,333 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:01:30,381 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-03 13:01:31,982 | server.py:125 | fit progress: (10, 2.217986822128296, {'accuracy': 0.3741, 'data_size': 10000}, 179.17634536900005)
INFO flwr 2024-04-03 13:01:31,983 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-03 13:01:31,983 | server.py:153 | FL finished in 179.17682804600008
INFO flwr 2024-04-03 13:01:31,983 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-03 13:01:31,983 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-03 13:01:31,983 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-03 13:01:31,983 | app.py:229 | app_fit: losses_centralized [(0, 2.302874803543091), (1, 2.29577898979187), (2, 2.288989782333374), (3, 2.281754970550537), (4, 2.274744987487793), (5, 2.2655112743377686), (6, 2.2526731491088867), (7, 2.2451117038726807), (8, 2.2355666160583496), (9, 2.228618621826172), (10, 2.217986822128296)]
INFO flwr 2024-04-03 13:01:31,983 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.1004), (1, 0.128), (2, 0.1467), (3, 0.1433), (4, 0.2038), (5, 0.2431), (6, 0.2135), (7, 0.2636), (8, 0.2554), (9, 0.324), (10, 0.3741)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.3741
wandb:     loss 2.21799
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240403_125706-edejopg2
wandb: Find logs at: ./wandb/offline-run-20240403_125706-edejopg2/logs
Using the latest cached version of the dataset since mnist couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'mnist' at .cache/mnist/mnist/1.0.0/b06aab39e05f7bcd9635d18ed25d06eae523c574 (last modified on Tue Apr  2 18:09:57 2024).
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-03 13:08:45,719 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=28015)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=28015)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-03 13:08:53,459	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-03 13:08:54,946	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-03 13:08:56,158	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_3ddfc7d0fdacf4f5.zip' (7.14MiB) to Ray cluster...
2024-04-03 13:08:56,173	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_3ddfc7d0fdacf4f5.zip'.
INFO flwr 2024-04-03 13:09:11,177 | app.py:213 | Flower VCE: Ray initialized with resources: {'CPU': 64.0, 'object_store_memory': 80079506227.0, 'accelerator_type:TITAN': 1.0, 'memory': 176852181197.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0, 'GPU': 1.0}
INFO flwr 2024-04-03 13:09:11,177 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-03 13:09:11,178 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-03 13:09:11,197 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-03 13:09:11,199 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-03 13:09:11,199 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-03 13:09:11,199 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-03 13:09:14,126 | server.py:94 | initial parameters (loss, other metrics): 2.3034138679504395, {'accuracy': 0.0628, 'data_size': 10000}
INFO flwr 2024-04-03 13:09:14,142 | server.py:104 | FL starting
DEBUG flwr 2024-04-03 13:09:14,142 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=32952)[0m 2024-04-03 13:09:19.731177: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=32952)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=32952)[0m 2024-04-03 13:09:22.897131: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=32952)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=32952)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=32951)[0m 2024-04-03 13:09:19.842006: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=32951)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=32951)[0m 2024-04-03 13:09:22.890707: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-03 13:09:49,340 | server.py:236 | fit_round 1 received 10 results and 0 failures
WARNING flwr 2024-04-03 13:09:49,376 | fedavg.py:250 | No fit_metrics_aggregation_fn provided
INFO flwr 2024-04-03 13:09:50,528 | server.py:125 | fit progress: (1, 2.2892932891845703, {'accuracy': 0.1895, 'data_size': 10000}, 36.38565828400078)
INFO flwr 2024-04-03 13:09:50,528 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-03 13:09:50,528 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:09:58,221 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-03 13:09:59,628 | server.py:125 | fit progress: (2, 2.277730703353882, {'accuracy': 0.1542, 'data_size': 10000}, 45.485474389000046)
INFO flwr 2024-04-03 13:09:59,628 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-03 13:09:59,628 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:10:06,447 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-03 13:10:07,904 | server.py:125 | fit progress: (3, 2.259077548980713, {'accuracy': 0.331, 'data_size': 10000}, 53.761982927000645)
INFO flwr 2024-04-03 13:10:07,904 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-03 13:10:07,905 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:10:14,860 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-03 13:10:16,305 | server.py:125 | fit progress: (4, 2.2404379844665527, {'accuracy': 0.2646, 'data_size': 10000}, 62.16246910800055)
INFO flwr 2024-04-03 13:10:16,305 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-03 13:10:16,305 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:10:23,329 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-03 13:10:24,806 | server.py:125 | fit progress: (5, 2.227097511291504, {'accuracy': 0.2771, 'data_size': 10000}, 70.66366449500038)
INFO flwr 2024-04-03 13:10:24,813 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-03 13:10:24,813 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:10:31,858 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-03 13:10:36,842 | server.py:125 | fit progress: (6, 2.1969616413116455, {'accuracy': 0.4545, 'data_size': 10000}, 82.6995274840001)
INFO flwr 2024-04-03 13:10:36,842 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-03 13:10:36,842 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:10:43,833 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-03 13:10:45,446 | server.py:125 | fit progress: (7, 2.176804780960083, {'accuracy': 0.5065, 'data_size': 10000}, 91.30379246400025)
INFO flwr 2024-04-03 13:10:45,446 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-03 13:10:45,447 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:10:52,745 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-03 13:10:54,407 | server.py:125 | fit progress: (8, 2.1553375720977783, {'accuracy': 0.4772, 'data_size': 10000}, 100.26513416800026)
INFO flwr 2024-04-03 13:10:54,408 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-03 13:10:54,408 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:11:01,357 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-03 13:11:02,962 | server.py:125 | fit progress: (9, 2.1321589946746826, {'accuracy': 0.6036, 'data_size': 10000}, 108.8196634800006)
INFO flwr 2024-04-03 13:11:02,962 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-03 13:11:02,963 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:11:10,147 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-03 13:11:11,602 | server.py:125 | fit progress: (10, 2.1079230308532715, {'accuracy': 0.6642, 'data_size': 10000}, 117.46009214800051)
INFO flwr 2024-04-03 13:11:11,603 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-03 13:11:11,603 | server.py:153 | FL finished in 117.4606427080007
INFO flwr 2024-04-03 13:11:11,603 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-03 13:11:11,603 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-03 13:11:11,603 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-03 13:11:11,604 | app.py:229 | app_fit: losses_centralized [(0, 2.3034138679504395), (1, 2.2892932891845703), (2, 2.277730703353882), (3, 2.259077548980713), (4, 2.2404379844665527), (5, 2.227097511291504), (6, 2.1969616413116455), (7, 2.176804780960083), (8, 2.1553375720977783), (9, 2.1321589946746826), (10, 2.1079230308532715)]
INFO flwr 2024-04-03 13:11:11,604 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0628), (1, 0.1895), (2, 0.1542), (3, 0.331), (4, 0.2646), (5, 0.2771), (6, 0.4545), (7, 0.5065), (8, 0.4772), (9, 0.6036), (10, 0.6642)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.6642
wandb:     loss 2.10792
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240403_130842-cgsltc73
wandb: Find logs at: ./wandb/offline-run-20240403_130842-cgsltc73/logs
Using the latest cached version of the dataset since mnist couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'mnist' at .cache/mnist/mnist/1.0.0/b06aab39e05f7bcd9635d18ed25d06eae523c574 (last modified on Tue Apr  2 18:09:57 2024).
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-03 13:18:22,875 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=32951)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=32951)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-03 13:18:29,939	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-03 13:18:30,247	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-03 13:18:30,540	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_99131eed02cbeb84.zip' (7.15MiB) to Ray cluster...
2024-04-03 13:18:30,559	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_99131eed02cbeb84.zip'.
INFO flwr 2024-04-03 13:18:41,652 | app.py:213 | Flower VCE: Ray initialized with resources: {'object_store_memory': 80079946137.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0, 'GPU': 1.0, 'CPU': 64.0, 'memory': 176853207655.0, 'accelerator_type:TITAN': 1.0}
INFO flwr 2024-04-03 13:18:41,653 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-03 13:18:41,653 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-03 13:18:41,674 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-03 13:18:41,679 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-03 13:18:41,679 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-03 13:18:41,679 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-03 13:18:44,369 | server.py:94 | initial parameters (loss, other metrics): 2.3037753105163574, {'accuracy': 0.1063, 'data_size': 10000}
INFO flwr 2024-04-03 13:18:44,369 | server.py:104 | FL starting
DEBUG flwr 2024-04-03 13:18:44,369 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=37324)[0m 2024-04-03 13:18:48.180487: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=37324)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=37324)[0m 2024-04-03 13:18:50.473707: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=37324)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=37324)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=37317)[0m 2024-04-03 13:18:48.286559: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=37317)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=37322)[0m 2024-04-03 13:18:50.611709: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-03 13:19:05,237 | server.py:236 | fit_round 1 received 10 results and 0 failures
WARNING flwr 2024-04-03 13:19:05,269 | fedavg.py:250 | No fit_metrics_aggregation_fn provided
INFO flwr 2024-04-03 13:19:06,410 | server.py:125 | fit progress: (1, 2.28332257270813, {'accuracy': 0.1776, 'data_size': 10000}, 22.040865390000363)
INFO flwr 2024-04-03 13:19:06,410 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-03 13:19:06,411 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:19:14,214 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-03 13:19:15,625 | server.py:125 | fit progress: (2, 2.244490385055542, {'accuracy': 0.3354, 'data_size': 10000}, 31.25535833899994)
INFO flwr 2024-04-03 13:19:15,625 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-03 13:19:15,625 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:19:22,668 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-03 13:19:24,097 | server.py:125 | fit progress: (3, 2.2038047313690186, {'accuracy': 0.3856, 'data_size': 10000}, 39.72815281500061)
INFO flwr 2024-04-03 13:19:24,098 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-03 13:19:24,098 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:19:31,292 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-03 13:19:32,754 | server.py:125 | fit progress: (4, 2.1595542430877686, {'accuracy': 0.501, 'data_size': 10000}, 48.385206885000116)
INFO flwr 2024-04-03 13:19:32,755 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-03 13:19:32,755 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:19:39,970 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-03 13:19:41,475 | server.py:125 | fit progress: (5, 2.113434076309204, {'accuracy': 0.5956, 'data_size': 10000}, 57.105401714000436)
INFO flwr 2024-04-03 13:19:41,475 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-03 13:19:41,475 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:19:48,533 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-03 13:19:50,114 | server.py:125 | fit progress: (6, 2.0701112747192383, {'accuracy': 0.552, 'data_size': 10000}, 65.74509478000073)
INFO flwr 2024-04-03 13:19:50,115 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-03 13:19:50,115 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:19:57,347 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-03 13:19:58,907 | server.py:125 | fit progress: (7, 2.035151958465576, {'accuracy': 0.5776, 'data_size': 10000}, 74.53724465800042)
INFO flwr 2024-04-03 13:19:58,907 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-03 13:19:58,907 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:20:06,064 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-03 13:20:07,671 | server.py:125 | fit progress: (8, 2.0101053714752197, {'accuracy': 0.6544, 'data_size': 10000}, 83.3012615180005)
INFO flwr 2024-04-03 13:20:07,671 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-03 13:20:07,671 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:20:14,797 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-03 13:20:16,394 | server.py:125 | fit progress: (9, 1.9894870519638062, {'accuracy': 0.6758, 'data_size': 10000}, 92.02452056200036)
INFO flwr 2024-04-03 13:20:16,394 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-03 13:20:16,394 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:20:23,526 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-03 13:20:25,599 | server.py:125 | fit progress: (10, 1.9692002534866333, {'accuracy': 0.6759, 'data_size': 10000}, 101.22933892000037)
INFO flwr 2024-04-03 13:20:25,599 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-03 13:20:25,599 | server.py:153 | FL finished in 101.2298340110001
INFO flwr 2024-04-03 13:20:25,599 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-03 13:20:25,599 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-03 13:20:25,600 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-03 13:20:25,600 | app.py:229 | app_fit: losses_centralized [(0, 2.3037753105163574), (1, 2.28332257270813), (2, 2.244490385055542), (3, 2.2038047313690186), (4, 2.1595542430877686), (5, 2.113434076309204), (6, 2.0701112747192383), (7, 2.035151958465576), (8, 2.0101053714752197), (9, 1.9894870519638062), (10, 1.9692002534866333)]
INFO flwr 2024-04-03 13:20:25,600 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.1063), (1, 0.1776), (2, 0.3354), (3, 0.3856), (4, 0.501), (5, 0.5956), (6, 0.552), (7, 0.5776), (8, 0.6544), (9, 0.6758), (10, 0.6759)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.6759
wandb:     loss 1.9692
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240403_131822-y73ixqj5
wandb: Find logs at: ./wandb/offline-run-20240403_131822-y73ixqj5/logs
Using the latest cached version of the dataset since mnist couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'mnist' at .cache/mnist/mnist/1.0.0/b06aab39e05f7bcd9635d18ed25d06eae523c574 (last modified on Tue Apr  2 18:09:57 2024).
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-03 13:27:39,288 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=37317)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=37317)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-03 13:27:45,068	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-03 13:27:48,050	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-03 13:27:48,373	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_068ab652d951551f.zip' (7.16MiB) to Ray cluster...
2024-04-03 13:27:48,393	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_068ab652d951551f.zip'.
INFO flwr 2024-04-03 13:28:01,226 | app.py:213 | Flower VCE: Ray initialized with resources: {'CPU': 64.0, 'GPU': 1.0, 'object_store_memory': 80002086912.0, 'accelerator_type:TITAN': 1.0, 'memory': 176671536128.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0}
INFO flwr 2024-04-03 13:28:01,226 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-03 13:28:01,227 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-03 13:28:01,248 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-03 13:28:01,249 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-03 13:28:01,249 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-03 13:28:01,249 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-03 13:28:04,102 | server.py:94 | initial parameters (loss, other metrics): 2.3049116134643555, {'accuracy': 0.0765, 'data_size': 10000}
INFO flwr 2024-04-03 13:28:04,102 | server.py:104 | FL starting
DEBUG flwr 2024-04-03 13:28:04,103 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=41934)[0m 2024-04-03 13:28:10.597055: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=41934)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=41927)[0m 2024-04-03 13:28:16.246253: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(pid=41932)[0m 2024-04-03 13:28:10.715936: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=41932)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=41927)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=41927)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=41922)[0m 2024-04-03 13:28:16.246965: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-03 13:28:38,252 | server.py:236 | fit_round 1 received 10 results and 0 failures
WARNING flwr 2024-04-03 13:28:38,298 | fedavg.py:250 | No fit_metrics_aggregation_fn provided
INFO flwr 2024-04-03 13:28:39,438 | server.py:125 | fit progress: (1, 2.3031041622161865, {'accuracy': 0.1162, 'data_size': 10000}, 35.3358712270001)
INFO flwr 2024-04-03 13:28:39,439 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-03 13:28:39,439 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:28:47,147 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-03 13:28:48,560 | server.py:125 | fit progress: (2, 2.3015639781951904, {'accuracy': 0.1495, 'data_size': 10000}, 44.45778226699986)
INFO flwr 2024-04-03 13:28:48,561 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-03 13:28:48,561 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:28:55,541 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-03 13:28:56,969 | server.py:125 | fit progress: (3, 2.2995693683624268, {'accuracy': 0.1663, 'data_size': 10000}, 52.866571356999884)
INFO flwr 2024-04-03 13:28:56,969 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-03 13:28:56,970 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:29:03,877 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-03 13:29:05,974 | server.py:125 | fit progress: (4, 2.2982089519500732, {'accuracy': 0.1947, 'data_size': 10000}, 61.87134456700005)
INFO flwr 2024-04-03 13:29:05,974 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-03 13:29:05,974 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:29:12,987 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-03 13:29:14,463 | server.py:125 | fit progress: (5, 2.2965288162231445, {'accuracy': 0.2038, 'data_size': 10000}, 70.36076082499949)
INFO flwr 2024-04-03 13:29:14,464 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-03 13:29:14,464 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:29:21,387 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-03 13:29:22,675 | server.py:125 | fit progress: (6, 2.2947041988372803, {'accuracy': 0.2108, 'data_size': 10000}, 78.57230217599954)
INFO flwr 2024-04-03 13:29:22,675 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-03 13:29:22,675 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:29:29,949 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-03 13:29:31,321 | server.py:125 | fit progress: (7, 2.2932517528533936, {'accuracy': 0.2391, 'data_size': 10000}, 87.2183088189995)
INFO flwr 2024-04-03 13:29:31,321 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-03 13:29:31,321 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:29:38,386 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-03 13:29:39,984 | server.py:125 | fit progress: (8, 2.2912402153015137, {'accuracy': 0.2824, 'data_size': 10000}, 95.88142313099979)
INFO flwr 2024-04-03 13:29:39,984 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-03 13:29:39,984 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:29:47,020 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-03 13:29:48,637 | server.py:125 | fit progress: (9, 2.289580821990967, {'accuracy': 0.2973, 'data_size': 10000}, 104.53443639699981)
INFO flwr 2024-04-03 13:29:48,637 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-03 13:29:48,637 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:29:55,603 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-03 13:29:57,263 | server.py:125 | fit progress: (10, 2.2868473529815674, {'accuracy': 0.3006, 'data_size': 10000}, 113.16031020500031)
INFO flwr 2024-04-03 13:29:57,263 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-03 13:29:57,263 | server.py:153 | FL finished in 113.16075662899948
INFO flwr 2024-04-03 13:29:57,263 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-03 13:29:57,264 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-03 13:29:57,264 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-03 13:29:57,264 | app.py:229 | app_fit: losses_centralized [(0, 2.3049116134643555), (1, 2.3031041622161865), (2, 2.3015639781951904), (3, 2.2995693683624268), (4, 2.2982089519500732), (5, 2.2965288162231445), (6, 2.2947041988372803), (7, 2.2932517528533936), (8, 2.2912402153015137), (9, 2.289580821990967), (10, 2.2868473529815674)]
INFO flwr 2024-04-03 13:29:57,264 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0765), (1, 0.1162), (2, 0.1495), (3, 0.1663), (4, 0.1947), (5, 0.2038), (6, 0.2108), (7, 0.2391), (8, 0.2824), (9, 0.2973), (10, 0.3006)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.3006
wandb:     loss 2.28685
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240403_132736-zo84pjx9
wandb: Find logs at: ./wandb/offline-run-20240403_132736-zo84pjx9/logs
Using the latest cached version of the dataset since mnist couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'mnist' at .cache/mnist/mnist/1.0.0/b06aab39e05f7bcd9635d18ed25d06eae523c574 (last modified on Tue Apr  2 18:09:57 2024).
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-03 13:37:08,976 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=41922)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=41922)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-03 13:37:13,577	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-03 13:37:13,946	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-03 13:37:14,252	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_e299ed99c36d7344.zip' (7.17MiB) to Ray cluster...
2024-04-03 13:37:14,268	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_e299ed99c36d7344.zip'.
INFO flwr 2024-04-03 13:37:25,464 | app.py:213 | Flower VCE: Ray initialized with resources: {'node:__internal_head__': 1.0, 'node:10.20.240.12': 1.0, 'GPU': 1.0, 'CPU': 64.0, 'memory': 176668365005.0, 'accelerator_type:TITAN': 1.0, 'object_store_memory': 80000727859.0}
INFO flwr 2024-04-03 13:37:25,465 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-03 13:37:25,465 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-03 13:37:25,487 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-03 13:37:25,488 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-03 13:37:25,489 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-03 13:37:25,489 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-03 13:37:29,510 | server.py:94 | initial parameters (loss, other metrics): 2.3034422397613525, {'accuracy': 0.0742, 'data_size': 10000}
INFO flwr 2024-04-03 13:37:29,510 | server.py:104 | FL starting
DEBUG flwr 2024-04-03 13:37:29,512 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=45826)[0m 2024-04-03 13:37:31.407586: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=45826)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=45826)[0m 2024-04-03 13:37:33.706461: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=45825)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=45825)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=45821)[0m 2024-04-03 13:37:31.648070: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=45821)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=45822)[0m 2024-04-03 13:37:33.853843: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-03 13:37:45,475 | server.py:236 | fit_round 1 received 10 results and 0 failures
WARNING flwr 2024-04-03 13:37:45,512 | fedavg.py:250 | No fit_metrics_aggregation_fn provided
INFO flwr 2024-04-03 13:37:46,887 | server.py:125 | fit progress: (1, 2.292041540145874, {'accuracy': 0.2533, 'data_size': 10000}, 17.375073834999966)
INFO flwr 2024-04-03 13:37:46,887 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-03 13:37:46,887 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:37:54,256 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-03 13:37:55,693 | server.py:125 | fit progress: (2, 2.2803540229797363, {'accuracy': 0.3304, 'data_size': 10000}, 26.181682397999793)
INFO flwr 2024-04-03 13:37:55,693 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-03 13:37:55,694 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:38:02,750 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-03 13:38:04,208 | server.py:125 | fit progress: (3, 2.2638721466064453, {'accuracy': 0.3704, 'data_size': 10000}, 34.69684865999989)
INFO flwr 2024-04-03 13:38:04,209 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-03 13:38:04,209 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:38:11,321 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-03 13:38:12,621 | server.py:125 | fit progress: (4, 2.247626543045044, {'accuracy': 0.4307, 'data_size': 10000}, 43.10947523199957)
INFO flwr 2024-04-03 13:38:12,621 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-03 13:38:12,621 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:38:19,879 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-03 13:38:21,164 | server.py:125 | fit progress: (5, 2.22274112701416, {'accuracy': 0.4703, 'data_size': 10000}, 51.65268379400004)
INFO flwr 2024-04-03 13:38:21,165 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-03 13:38:21,165 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:38:28,278 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-03 13:38:29,813 | server.py:125 | fit progress: (6, 2.202894926071167, {'accuracy': 0.4519, 'data_size': 10000}, 60.30114584399962)
INFO flwr 2024-04-03 13:38:29,813 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-03 13:38:29,813 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:38:36,914 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-03 13:38:38,506 | server.py:125 | fit progress: (7, 2.1768100261688232, {'accuracy': 0.4584, 'data_size': 10000}, 68.99452259600002)
INFO flwr 2024-04-03 13:38:38,506 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-03 13:38:38,506 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:38:45,346 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-03 13:38:46,948 | server.py:125 | fit progress: (8, 2.1508543491363525, {'accuracy': 0.4665, 'data_size': 10000}, 77.43650910399992)
INFO flwr 2024-04-03 13:38:46,948 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-03 13:38:46,948 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:38:54,120 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-03 13:38:55,568 | server.py:125 | fit progress: (9, 2.1289467811584473, {'accuracy': 0.4619, 'data_size': 10000}, 86.05634026299958)
INFO flwr 2024-04-03 13:38:55,568 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-03 13:38:55,568 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:39:02,916 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-03 13:39:04,391 | server.py:125 | fit progress: (10, 2.1069629192352295, {'accuracy': 0.4894, 'data_size': 10000}, 94.87975000299957)
INFO flwr 2024-04-03 13:39:04,391 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-03 13:39:04,392 | server.py:153 | FL finished in 94.88025862299946
INFO flwr 2024-04-03 13:39:04,392 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-03 13:39:04,392 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-03 13:39:04,392 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-03 13:39:04,392 | app.py:229 | app_fit: losses_centralized [(0, 2.3034422397613525), (1, 2.292041540145874), (2, 2.2803540229797363), (3, 2.2638721466064453), (4, 2.247626543045044), (5, 2.22274112701416), (6, 2.202894926071167), (7, 2.1768100261688232), (8, 2.1508543491363525), (9, 2.1289467811584473), (10, 2.1069629192352295)]
INFO flwr 2024-04-03 13:39:04,393 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0742), (1, 0.2533), (2, 0.3304), (3, 0.3704), (4, 0.4307), (5, 0.4703), (6, 0.4519), (7, 0.4584), (8, 0.4665), (9, 0.4619), (10, 0.4894)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.4894
wandb:     loss 2.10696
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240403_133708-855xxaf7
wandb: Find logs at: ./wandb/offline-run-20240403_133708-855xxaf7/logs
Using the latest cached version of the dataset since mnist couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'mnist' at .cache/mnist/mnist/1.0.0/b06aab39e05f7bcd9635d18ed25d06eae523c574 (last modified on Tue Apr  2 18:09:57 2024).
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-03 13:46:15,641 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=45817)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=45817)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-03 13:46:20,389	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-03 13:46:20,718	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-03 13:46:21,060	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_4847e7231a2052cf.zip' (7.18MiB) to Ray cluster...
2024-04-03 13:46:21,077	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_4847e7231a2052cf.zip'.
INFO flwr 2024-04-03 13:46:33,620 | app.py:213 | Flower VCE: Ray initialized with resources: {'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0, 'GPU': 1.0, 'accelerator_type:TITAN': 1.0, 'memory': 176662885786.0, 'CPU': 64.0, 'object_store_memory': 79998379622.0}
INFO flwr 2024-04-03 13:46:33,620 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-03 13:46:33,620 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-03 13:46:33,641 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-03 13:46:33,642 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-03 13:46:33,643 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-03 13:46:33,643 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-03 13:46:36,725 | server.py:94 | initial parameters (loss, other metrics): 2.299699544906616, {'accuracy': 0.1121, 'data_size': 10000}
INFO flwr 2024-04-03 13:46:36,726 | server.py:104 | FL starting
DEBUG flwr 2024-04-03 13:46:36,726 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=50206)[0m 2024-04-03 13:46:39.842009: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=50206)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=50199)[0m 2024-04-03 13:46:42.257600: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=50205)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=50205)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=50210)[0m 2024-04-03 13:46:39.944369: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=50210)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=50210)[0m 2024-04-03 13:46:42.348103: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-03 13:46:55,182 | server.py:236 | fit_round 1 received 10 results and 0 failures
WARNING flwr 2024-04-03 13:46:56,410 | fedavg.py:250 | No fit_metrics_aggregation_fn provided
INFO flwr 2024-04-03 13:46:57,539 | server.py:125 | fit progress: (1, 2.27278208732605, {'accuracy': 0.1747, 'data_size': 10000}, 20.812925524000093)
INFO flwr 2024-04-03 13:46:57,539 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-03 13:46:57,540 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:47:05,437 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-03 13:47:06,699 | server.py:125 | fit progress: (2, 2.230414390563965, {'accuracy': 0.4077, 'data_size': 10000}, 29.972778843000015)
INFO flwr 2024-04-03 13:47:06,699 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-03 13:47:06,700 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:47:13,816 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-03 13:47:15,021 | server.py:125 | fit progress: (3, 2.1908979415893555, {'accuracy': 0.4212, 'data_size': 10000}, 38.295192737000434)
INFO flwr 2024-04-03 13:47:15,022 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-03 13:47:15,022 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:47:22,050 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-03 13:47:23,522 | server.py:125 | fit progress: (4, 2.153437376022339, {'accuracy': 0.4011, 'data_size': 10000}, 46.79563227699964)
INFO flwr 2024-04-03 13:47:23,522 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-03 13:47:23,522 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:47:30,541 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-03 13:47:32,102 | server.py:125 | fit progress: (5, 2.1081955432891846, {'accuracy': 0.49, 'data_size': 10000}, 55.37548148099995)
INFO flwr 2024-04-03 13:47:32,102 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-03 13:47:32,102 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:47:39,205 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-03 13:47:41,084 | server.py:125 | fit progress: (6, 2.068955183029175, {'accuracy': 0.5904, 'data_size': 10000}, 64.35810704300002)
INFO flwr 2024-04-03 13:47:41,085 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-03 13:47:41,085 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:47:48,049 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-03 13:47:49,394 | server.py:125 | fit progress: (7, 2.03475284576416, {'accuracy': 0.6116, 'data_size': 10000}, 72.66769699999986)
INFO flwr 2024-04-03 13:47:49,394 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-03 13:47:49,394 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:47:56,389 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-03 13:47:57,981 | server.py:125 | fit progress: (8, 2.0104737281799316, {'accuracy': 0.6456, 'data_size': 10000}, 81.25494619900019)
INFO flwr 2024-04-03 13:47:57,982 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-03 13:47:57,982 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:48:05,106 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-03 13:48:06,730 | server.py:125 | fit progress: (9, 1.9785401821136475, {'accuracy': 0.657, 'data_size': 10000}, 90.0036112810003)
INFO flwr 2024-04-03 13:48:06,730 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-03 13:48:06,730 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:48:13,801 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-03 13:48:15,471 | server.py:125 | fit progress: (10, 1.9509761333465576, {'accuracy': 0.6696, 'data_size': 10000}, 98.74446682500002)
INFO flwr 2024-04-03 13:48:15,471 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-03 13:48:15,471 | server.py:153 | FL finished in 98.7449291339999
INFO flwr 2024-04-03 13:48:15,471 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-03 13:48:15,471 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-03 13:48:15,472 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-03 13:48:15,472 | app.py:229 | app_fit: losses_centralized [(0, 2.299699544906616), (1, 2.27278208732605), (2, 2.230414390563965), (3, 2.1908979415893555), (4, 2.153437376022339), (5, 2.1081955432891846), (6, 2.068955183029175), (7, 2.03475284576416), (8, 2.0104737281799316), (9, 1.9785401821136475), (10, 1.9509761333465576)]
INFO flwr 2024-04-03 13:48:15,472 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.1121), (1, 0.1747), (2, 0.4077), (3, 0.4212), (4, 0.4011), (5, 0.49), (6, 0.5904), (7, 0.6116), (8, 0.6456), (9, 0.657), (10, 0.6696)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.6696
wandb:     loss 1.95098
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240403_134615-mn2thqo7
wandb: Find logs at: ./wandb/offline-run-20240403_134615-mn2thqo7/logs
Using the latest cached version of the dataset since mnist couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'mnist' at .cache/mnist/mnist/1.0.0/b06aab39e05f7bcd9635d18ed25d06eae523c574 (last modified on Tue Apr  2 18:09:57 2024).
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-03 13:55:26,620 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=50199)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=50199)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-03 13:55:32,170	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-03 13:55:32,610	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-03 13:55:32,930	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_0044fd9868927514.zip' (7.19MiB) to Ray cluster...
2024-04-03 13:55:32,947	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_0044fd9868927514.zip'.
INFO flwr 2024-04-03 13:55:45,907 | app.py:213 | Flower VCE: Ray initialized with resources: {'GPU': 1.0, 'object_store_memory': 79979296358.0, 'CPU': 64.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0, 'accelerator_type:TITAN': 1.0, 'memory': 176618358170.0}
INFO flwr 2024-04-03 13:55:45,907 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-03 13:55:45,907 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-03 13:55:45,926 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-03 13:55:45,927 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-03 13:55:45,928 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-03 13:55:45,928 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-03 13:55:49,184 | server.py:94 | initial parameters (loss, other metrics): 2.301147937774658, {'accuracy': 0.0482, 'data_size': 10000}
INFO flwr 2024-04-03 13:55:49,184 | server.py:104 | FL starting
DEBUG flwr 2024-04-03 13:55:49,185 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=54558)[0m 2024-04-03 13:55:51.893669: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=54558)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=54554)[0m 2024-04-03 13:55:54.234896: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=54559)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=54559)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=54559)[0m 2024-04-03 13:55:52.109656: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=54559)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=54556)[0m 2024-04-03 13:55:54.383057: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-03 13:56:06,020 | server.py:236 | fit_round 1 received 10 results and 0 failures
WARNING flwr 2024-04-03 13:56:06,194 | fedavg.py:250 | No fit_metrics_aggregation_fn provided
INFO flwr 2024-04-03 13:56:07,328 | server.py:125 | fit progress: (1, 2.251255750656128, {'accuracy': 0.4077, 'data_size': 10000}, 18.14381191299981)
INFO flwr 2024-04-03 13:56:07,329 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-03 13:56:07,329 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:56:15,287 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-03 13:56:16,699 | server.py:125 | fit progress: (2, 2.156243085861206, {'accuracy': 0.39, 'data_size': 10000}, 27.514760609000405)
INFO flwr 2024-04-03 13:56:16,700 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-03 13:56:16,700 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:56:23,571 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-03 13:56:24,772 | server.py:125 | fit progress: (3, 2.087036609649658, {'accuracy': 0.4877, 'data_size': 10000}, 35.58782890099974)
INFO flwr 2024-04-03 13:56:24,773 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-03 13:56:24,773 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:56:31,922 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-03 13:56:33,181 | server.py:125 | fit progress: (4, 2.0152387619018555, {'accuracy': 0.6483, 'data_size': 10000}, 43.99648466300005)
INFO flwr 2024-04-03 13:56:33,181 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-03 13:56:33,182 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:56:40,625 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-03 13:56:41,894 | server.py:125 | fit progress: (5, 1.9595080614089966, {'accuracy': 0.7093, 'data_size': 10000}, 52.70922830000018)
INFO flwr 2024-04-03 13:56:41,894 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-03 13:56:41,894 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:56:49,094 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-03 13:56:50,629 | server.py:125 | fit progress: (6, 1.9269022941589355, {'accuracy': 0.6789, 'data_size': 10000}, 61.444357833999675)
INFO flwr 2024-04-03 13:56:50,629 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-03 13:56:50,630 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:56:57,769 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-03 13:56:59,310 | server.py:125 | fit progress: (7, 1.8929128646850586, {'accuracy': 0.7298, 'data_size': 10000}, 70.12555546000021)
INFO flwr 2024-04-03 13:56:59,310 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-03 13:56:59,311 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:57:06,454 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-03 13:57:08,165 | server.py:125 | fit progress: (8, 1.869728684425354, {'accuracy': 0.7052, 'data_size': 10000}, 78.98084362999998)
INFO flwr 2024-04-03 13:57:08,166 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-03 13:57:08,166 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:57:15,335 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-03 13:57:16,942 | server.py:125 | fit progress: (9, 1.845382571220398, {'accuracy': 0.749, 'data_size': 10000}, 87.75737499099978)
INFO flwr 2024-04-03 13:57:16,942 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-03 13:57:16,943 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 13:57:24,196 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-03 13:57:25,641 | server.py:125 | fit progress: (10, 1.83107328414917, {'accuracy': 0.7576, 'data_size': 10000}, 96.4563503469999)
INFO flwr 2024-04-03 13:57:25,641 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-03 13:57:25,641 | server.py:153 | FL finished in 96.45685668999977
INFO flwr 2024-04-03 13:57:25,642 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-03 13:57:25,642 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-03 13:57:25,642 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-03 13:57:25,642 | app.py:229 | app_fit: losses_centralized [(0, 2.301147937774658), (1, 2.251255750656128), (2, 2.156243085861206), (3, 2.087036609649658), (4, 2.0152387619018555), (5, 1.9595080614089966), (6, 1.9269022941589355), (7, 1.8929128646850586), (8, 1.869728684425354), (9, 1.845382571220398), (10, 1.83107328414917)]
INFO flwr 2024-04-03 13:57:25,642 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0482), (1, 0.4077), (2, 0.39), (3, 0.4877), (4, 0.6483), (5, 0.7093), (6, 0.6789), (7, 0.7298), (8, 0.7052), (9, 0.749), (10, 0.7576)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.7576
wandb:     loss 1.83107
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240403_135526-xv2wk9oe
wandb: Find logs at: ./wandb/offline-run-20240403_135526-xv2wk9oe/logs
Using the latest cached version of the dataset since mnist couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'mnist' at .cache/mnist/mnist/1.0.0/b06aab39e05f7bcd9635d18ed25d06eae523c574 (last modified on Tue Apr  2 18:09:57 2024).
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-03 14:04:42,399 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=54553)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=54553)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-03 14:04:59,805	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-03 14:05:07,602	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-03 14:05:09,921	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_2622b633d231dcd0.zip' (7.20MiB) to Ray cluster...
2024-04-03 14:05:09,948	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_2622b633d231dcd0.zip'.
INFO flwr 2024-04-03 14:05:42,475 | app.py:213 | Flower VCE: Ray initialized with resources: {'node:__internal_head__': 1.0, 'node:10.20.240.12': 1.0, 'CPU': 64.0, 'object_store_memory': 80058046464.0, 'memory': 176802108416.0, 'accelerator_type:TITAN': 1.0, 'GPU': 1.0}
INFO flwr 2024-04-03 14:05:42,475 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-03 14:05:42,475 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-03 14:05:42,501 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-03 14:05:42,503 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-03 14:05:42,503 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-03 14:05:42,504 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-03 14:05:44,927 | server.py:94 | initial parameters (loss, other metrics): 2.3026657104492188, {'accuracy': 0.1027, 'data_size': 10000}
INFO flwr 2024-04-03 14:05:44,928 | server.py:104 | FL starting
DEBUG flwr 2024-04-03 14:05:44,928 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=59311)[0m 2024-04-03 14:06:04.629067: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=59311)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=59311)[0m 2024-04-03 14:06:12.172815: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(pid=59304)[0m 2024-04-03 14:06:04.629067: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=59304)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=59311)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=59311)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=59304)[0m 2024-04-03 14:06:12.180652: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-03 14:06:36,822 | server.py:236 | fit_round 1 received 10 results and 0 failures
WARNING flwr 2024-04-03 14:06:36,862 | fedavg.py:250 | No fit_metrics_aggregation_fn provided
INFO flwr 2024-04-03 14:06:38,028 | server.py:125 | fit progress: (1, 2.2998454570770264, {'accuracy': 0.1284, 'data_size': 10000}, 53.09999128599975)
INFO flwr 2024-04-03 14:06:38,028 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-03 14:06:38,028 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:06:45,696 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-03 14:06:47,104 | server.py:125 | fit progress: (2, 2.297422409057617, {'accuracy': 0.1445, 'data_size': 10000}, 62.175703445999716)
INFO flwr 2024-04-03 14:06:47,104 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-03 14:06:47,104 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:06:54,114 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-03 14:06:55,548 | server.py:125 | fit progress: (3, 2.2948460578918457, {'accuracy': 0.1708, 'data_size': 10000}, 70.61976080899967)
INFO flwr 2024-04-03 14:06:55,548 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-03 14:06:55,548 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:07:02,383 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-03 14:07:03,893 | server.py:125 | fit progress: (4, 2.291691303253174, {'accuracy': 0.2211, 'data_size': 10000}, 78.96493093800018)
INFO flwr 2024-04-03 14:07:03,893 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-03 14:07:03,893 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:07:10,976 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-03 14:07:12,568 | server.py:125 | fit progress: (5, 2.2880496978759766, {'accuracy': 0.2787, 'data_size': 10000}, 87.64014698699975)
INFO flwr 2024-04-03 14:07:12,568 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-03 14:07:12,569 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:07:19,550 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-03 14:07:20,878 | server.py:125 | fit progress: (6, 2.284733533859253, {'accuracy': 0.3168, 'data_size': 10000}, 95.94982741500007)
INFO flwr 2024-04-03 14:07:20,878 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-03 14:07:20,878 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:07:28,012 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-03 14:07:29,429 | server.py:125 | fit progress: (7, 2.28071928024292, {'accuracy': 0.356, 'data_size': 10000}, 104.50121184)
INFO flwr 2024-04-03 14:07:29,429 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-03 14:07:29,430 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:07:36,479 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-03 14:07:38,088 | server.py:125 | fit progress: (8, 2.2766621112823486, {'accuracy': 0.3946, 'data_size': 10000}, 113.16054709399941)
INFO flwr 2024-04-03 14:07:38,089 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-03 14:07:38,089 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:07:45,033 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-03 14:07:46,781 | server.py:125 | fit progress: (9, 2.2705655097961426, {'accuracy': 0.4011, 'data_size': 10000}, 121.85261616400021)
INFO flwr 2024-04-03 14:07:46,781 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-03 14:07:46,781 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:07:53,816 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-03 14:07:55,607 | server.py:125 | fit progress: (10, 2.266709566116333, {'accuracy': 0.4185, 'data_size': 10000}, 130.67864226999973)
INFO flwr 2024-04-03 14:07:55,607 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-03 14:07:55,607 | server.py:153 | FL finished in 130.67908554199948
INFO flwr 2024-04-03 14:07:55,607 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-03 14:07:55,607 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-03 14:07:55,607 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-03 14:07:55,608 | app.py:229 | app_fit: losses_centralized [(0, 2.3026657104492188), (1, 2.2998454570770264), (2, 2.297422409057617), (3, 2.2948460578918457), (4, 2.291691303253174), (5, 2.2880496978759766), (6, 2.284733533859253), (7, 2.28071928024292), (8, 2.2766621112823486), (9, 2.2705655097961426), (10, 2.266709566116333)]
INFO flwr 2024-04-03 14:07:55,608 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.1027), (1, 0.1284), (2, 0.1445), (3, 0.1708), (4, 0.2211), (5, 0.2787), (6, 0.3168), (7, 0.356), (8, 0.3946), (9, 0.4011), (10, 0.4185)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.4185
wandb:     loss 2.26671
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240403_140437-jei2xnr2
wandb: Find logs at: ./wandb/offline-run-20240403_140437-jei2xnr2/logs
Loaded 168 configs, running...
{'simulation': {'batch_size': -1, 'client_count': 100, 'fraction_fit': 0.1, 'global_rounds': 10, 'learning_method': {'optimizer': 'SGD', 'lr': 0.001}, 'local_rounds': 1}, 'dataset': {'name': 'MNIST', 'preprocess_fn': 'def preprocess_fn(element):\n  return {\n    "x": element["image"].reshape(784) / 255.,\n    "y": element["label"]\n  }\n', 'splitter': {'alpha': 1, 'percent_non_iid': 25}}, 'model': {'name': 'Logistic Regression', 'criterion': 'CrossEntropyLoss', 'layers': [{'type': 'Linear', 'in_features': 784, 'out_features': 10}, {'type': 'Softmax', 'dim': -1}]}}
Finished
{'simulation': {'batch_size': -1, 'client_count': 100, 'fraction_fit': 0.1, 'global_rounds': 10, 'learning_method': {'optimizer': 'SGD', 'lr': 0.001}, 'local_rounds': 5}, 'dataset': {'name': 'MNIST', 'preprocess_fn': 'def preprocess_fn(element):\n  return {\n    "x": element["image"].reshape(784) / 255.,\n    "y": element["label"]\n  }\n', 'splitter': {'alpha': 1, 'percent_non_iid': 25}}, 'model': {'name': 'Logistic Regression', 'criterion': 'CrossEntropyLoss', 'layers': [{'type': 'Linear', 'in_features': 784, 'out_features': 10}, {'type': 'Softmax', 'dim': -1}]}}
Finished
{'simulation': {'batch_size': -1, 'client_count': 100, 'fraction_fit': 0.1, 'global_rounds': 10, 'learning_method': {'optimizer': 'SGD', 'lr': 0.001}, 'local_rounds': 10}, 'dataset': {'name': 'MNIST', 'preprocess_fn': 'def preprocess_fn(element):\n  return {\n    "x": element["image"].reshape(784) / 255.,\n    "y": element["label"]\n  }\n', 'splitter': {'alpha': 1, 'percent_non_iid': 25}}, 'model': {'name': 'Logistic Regression', 'criterion': 'CrossEntropyLoss', 'layers': [{'type': 'Linear', 'in_features': 784, 'out_features': 10}, {'type': 'Softmax', 'dim': -1}]}}
Finished
{'simulation': {'batch_size': -1, 'client_count': 100, 'fraction_fit': 0.1, 'global_rounds': 10, 'learning_method': {'optimizer': 'SGD', 'lr': 0.001}, 'local_rounds': 20}, 'dataset': {'name': 'MNIST', 'preprocess_fn': 'def preprocess_fn(element):\n  return {\n    "x": element["image"].reshape(784) / 255.,\n    "y": element["label"]\n  }\n', 'splitter': {'alpha': 1, 'percent_non_iid': 25}}, 'model': {'name': 'Logistic Regression', 'criterion': 'CrossEntropyLoss', 'layers': [{'type': 'Linear', 'in_features': 784, 'out_features': 10}, {'type': 'Softmax', 'dim': -1}]}}
Finished
{'simulation': {'batch_size': -1, 'client_count': 100, 'fraction_fit': 0.1, 'global_rounds': 10, 'learning_method': {'optimizer': 'SGD', 'lr': 0.051000000000000004}, 'local_rounds': 1}, 'dataset': {'name': 'MNIST', 'preprocess_fn': 'def preprocess_fn(element):\n  return {\n    "x": element["image"].reshape(784) / 255.,\n    "y": element["label"]\n  }\n', 'splitter': {'alpha': 1, 'percent_non_iid': 25}}, 'model': {'name': 'Logistic Regression', 'criterion': 'CrossEntropyLoss', 'layers': [{'type': 'Linear', 'in_features': 784, 'out_features': 10}, {'type': 'Softmax', 'dim': -1}]}}
Finished
{'simulation': {'batch_size': -1, 'client_count': 100, 'fraction_fit': 0.1, 'global_rounds': 10, 'learning_method': {'optimizer': 'SGD', 'lr': 0.051000000000000004}, 'local_rounds': 5}, 'dataset': {'name': 'MNIST', 'preprocess_fn': 'def preprocess_fn(element):\n  return {\n    "x": element["image"].reshape(784) / 255.,\n    "y": element["label"]\n  }\n', 'splitter': {'alpha': 1, 'percent_non_iid': 25}}, 'model': {'name': 'Logistic Regression', 'criterion': 'CrossEntropyLoss', 'layers': [{'type': 'Linear', 'in_features': 784, 'out_features': 10}, {'type': 'Softmax', 'dim': -1}]}}
Finished
{'simulation': {'batch_size': -1, 'client_count': 100, 'fraction_fit': 0.1, 'global_rounds': 10, 'learning_method': {'optimizer': 'SGD', 'lr': 0.051000000000000004}, 'local_rounds': 10}, 'dataset': {'name': 'MNIST', 'preprocess_fn': 'def preprocess_fn(element):\n  return {\n    "x": element["image"].reshape(784) / 255.,\n    "y": element["label"]\n  }\n', 'splitter': {'alpha': 1, 'percent_non_iid': 25}}, 'model': {'name': 'Logistic Regression', 'criterion': 'CrossEntropyLoss', 'layers': [{'type': 'Linear', 'in_features': 784, 'out_features': 10}, {'type': 'Softmax', 'dim': -1}]}}
Finished
{'simulation': {'batch_size': -1, 'client_count': 100, 'fraction_fit': 0.1, 'global_rounds': 10, 'learning_method': {'optimizer': 'SGD', 'lr': 0.051000000000000004}, 'local_rounds': 20}, 'dataset': {'name': 'MNIST', 'preprocess_fn': 'def preprocess_fn(element):\n  return {\n    "x": element["image"].reshape(784) / 255.,\n    "y": element["label"]\n  }\n', 'splitter': {'alpha': 1, 'percent_non_iid': 25}}, 'model': {'name': 'Logistic Regression', 'criterion': 'CrossEntropyLoss', 'layers': [{'type': 'Linear', 'in_features': 784, 'out_features': 10}, {'type': 'Softmax', 'dim': -1}]}}
Finished
{'simulation': {'batch_size': -1, 'client_count': 100, 'fraction_fit': 0.1, 'global_rounds': 10, 'learning_method': {'optimizer': 'SGD', 'lr': 0.101}, 'local_rounds': 1}, 'dataset': {'name': 'MNIST', 'preprocess_fn': 'def preprocess_fn(element):\n  return {\n    "x": element["image"].reshape(784) / 255.,\n    "y": element["label"]\n  }\n', 'splitter': {'alpha': 1, 'percent_non_iid': 25}}, 'model': {'name': 'Logistic Regression', 'criterion': 'CrossEntropyLoss', 'layers': [{'type': 'Linear', 'in_features': 784, 'out_features': 10}, {'type': 'Softmax', 'dim': -1}]}}
Finished
{'simulation': {'batch_size': -1, 'client_count': 100, 'fraction_fit': 0.1, 'global_rounds': 10, 'learning_method': {'optimizer': 'SGD', 'lr': 0.101}, 'local_rounds': 5}, 'dataset': {'name': 'MNIST', 'preprocess_fn': 'def preprocess_fn(element):\n  return {\n    "x": element["image"].reshape(784) / 255.,\n    "y": element["label"]\n  }\n', 'splitter': {'alpha': 1, 'percent_non_iid': 25}}, 'model': {'name': 'Logistic Regression', 'criterion': 'CrossEntropyLoss', 'layers': [{'type': 'Linear', 'in_features': 784, 'out_features': 10}, {'type': 'Softmax', 'dim': -1}]}}
Finished
{'simulation': {'batch_size': -1, 'client_count': 100, 'fraction_fit': 0.1, 'global_rounds': 10, 'learning_method': {'optimizer': 'SGD', 'lr': 0.101}, 'local_rounds': 10}, 'dataset': {'name': 'MNIST', 'preprocess_fn': 'def preprocess_fn(element):\n  return {\n    "x": element["image"].reshape(784) / 255.,\n    "y": element["label"]\n  }\n', 'splitter': {'alpha': 1, 'percent_non_iid': 25}}, 'model': {'name': 'Logistic Regression', 'criterion': 'CrossEntropyLoss', 'layers': [{'type': 'Linear', 'in_features': 784, 'out_features': 10}, {'type': 'Softmax', 'dim': -1}]}}
Finished
{'simulation': {'batch_size': -1, 'client_count': 100, 'fraction_fit': 0.1, 'global_rounds': 10, 'learning_method': {'optimizer': 'SGD', 'lr': 0.101}, 'local_rounds': 20}, 'dataset': {'name': 'MNIST', 'preprocess_fn': 'def preprocess_fn(element):\n  return {\n    "x": element["image"].reshape(784) / 255.,\n    "y": element["label"]\n  }\n', 'splitter': {'alpha': 1, 'percent_non_iid': 25}}, 'model': {'name': 'Logistic Regression', 'criterion': 'CrossEntropyLoss', 'layers': [{'type': 'Linear', 'in_features': 784, 'out_features': 10}, {'type': 'Softmax', 'dim': -1}]}}
Finished
{'simulation': {'batch_size': -1, 'client_count': 100, 'fraction_fit': 0.1, 'global_rounds': 10, 'learning_method': {'optimizer': 'SGD', 'lr': 0.15100000000000002}, 'local_rounds': 1}, 'dataset': {'name': 'MNIST', 'preprocess_fn': 'def preprocess_fn(element):\n  return {\n    "x": element["image"].reshape(784) / 255.,\n    "y": element["label"]\n  }\n', 'splitter': {'alpha': 1, 'percent_non_iid': 25}}, 'model': {'name': 'Logistic Regression', 'criterion': 'CrossEntropyLoss', 'layers': [{'type': 'Linear', 'in_features': 784, 'out_features': 10}, {'type': 'Softmax', 'dim': -1}]}}
Finished
Using the latest cached version of the dataset since mnist couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'mnist' at .cache/mnist/mnist/1.0.0/b06aab39e05f7bcd9635d18ed25d06eae523c574 (last modified on Tue Apr  2 18:09:57 2024).
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-03 14:15:12,407 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=59304)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=59304)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-03 14:15:35,786	ERROR services.py:1207 -- Failed to start the dashboard 
2024-04-03 14:15:35,787	ERROR services.py:1232 -- Error should be written to 'dashboard.log' or 'dashboard.err'. We are printing the last 20 lines for you. See 'https://docs.ray.io/en/master/ray-observability/ray-logging.html#logging-directory-structure' to find where the log file is.
2024-04-03 14:15:35,788	ERROR services.py:1276 -- 
The last 20 lines of /tmp/ray/session_2024-04-03_14-15-14_443491_2335/logs/dashboard.log (it contains the error message from the dashboard): 
2024-04-03 14:15:36,035	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-03 14:15:47,259	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-03 14:15:48,097	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_c1547e2c71f4640a.zip' (7.22MiB) to Ray cluster...
2024-04-03 14:15:48,123	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_c1547e2c71f4640a.zip'.
INFO flwr 2024-04-03 14:15:59,212 | app.py:213 | Flower VCE: Ray initialized with resources: {'CPU': 64.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0, 'object_store_memory': 80169483878.0, 'memory': 177062129050.0, 'accelerator_type:TITAN': 1.0, 'GPU': 1.0}
INFO flwr 2024-04-03 14:15:59,212 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-03 14:15:59,212 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-03 14:15:59,231 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-03 14:15:59,233 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-03 14:15:59,233 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-03 14:15:59,233 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-03 14:16:04,308 | server.py:94 | initial parameters (loss, other metrics): 2.3013179302215576, {'accuracy': 0.1216, 'data_size': 10000}
INFO flwr 2024-04-03 14:16:04,309 | server.py:104 | FL starting
DEBUG flwr 2024-04-03 14:16:04,309 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=63732)[0m 2024-04-03 14:16:15.561242: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=63732)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=63732)[0m 2024-04-03 14:16:41.218369: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(pid=63742)[0m 2024-04-03 14:16:15.560564: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=63742)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=63732)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=63732)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=63742)[0m 2024-04-03 14:16:41.218371: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-03 14:18:18,825 | server.py:236 | fit_round 1 received 10 results and 0 failures
WARNING flwr 2024-04-03 14:18:19,444 | fedavg.py:250 | No fit_metrics_aggregation_fn provided
INFO flwr 2024-04-03 14:18:20,767 | server.py:125 | fit progress: (1, 2.282097339630127, {'accuracy': 0.1237, 'data_size': 10000}, 136.45811125900036)
INFO flwr 2024-04-03 14:18:20,767 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-03 14:18:20,768 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:18:28,384 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-03 14:18:29,783 | server.py:125 | fit progress: (2, 2.2620291709899902, {'accuracy': 0.2739, 'data_size': 10000}, 145.47458797800027)
INFO flwr 2024-04-03 14:18:29,784 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-03 14:18:29,784 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:18:36,571 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-03 14:18:37,994 | server.py:125 | fit progress: (3, 2.2393059730529785, {'accuracy': 0.3934, 'data_size': 10000}, 153.6852629240002)
INFO flwr 2024-04-03 14:18:37,994 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-03 14:18:37,995 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:18:45,077 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-03 14:18:46,520 | server.py:125 | fit progress: (4, 2.2100112438201904, {'accuracy': 0.4379, 'data_size': 10000}, 162.2113863170016)
INFO flwr 2024-04-03 14:18:46,521 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-03 14:18:46,521 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:18:53,489 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-03 14:18:54,776 | server.py:125 | fit progress: (5, 2.1794114112854004, {'accuracy': 0.5562, 'data_size': 10000}, 170.467036086)
INFO flwr 2024-04-03 14:18:54,776 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-03 14:18:54,777 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:19:02,003 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-03 14:19:03,291 | server.py:125 | fit progress: (6, 2.149282693862915, {'accuracy': 0.614, 'data_size': 10000}, 178.98229080700003)
INFO flwr 2024-04-03 14:19:03,291 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-03 14:19:03,292 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:19:10,477 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-03 14:19:12,108 | server.py:125 | fit progress: (7, 2.115694046020508, {'accuracy': 0.6329, 'data_size': 10000}, 187.79951463100042)
INFO flwr 2024-04-03 14:19:12,109 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-03 14:19:12,109 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:19:19,021 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-03 14:19:20,649 | server.py:125 | fit progress: (8, 2.0829060077667236, {'accuracy': 0.6064, 'data_size': 10000}, 196.34019829000135)
INFO flwr 2024-04-03 14:19:20,649 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-03 14:19:20,650 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:19:27,735 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-03 14:19:29,378 | server.py:125 | fit progress: (9, 2.0503976345062256, {'accuracy': 0.6352, 'data_size': 10000}, 205.0693114630012)
INFO flwr 2024-04-03 14:19:29,379 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-03 14:19:29,379 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:19:36,309 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-03 14:19:37,733 | server.py:125 | fit progress: (10, 2.0209290981292725, {'accuracy': 0.6672, 'data_size': 10000}, 213.42365747200165)
INFO flwr 2024-04-03 14:19:37,733 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-03 14:19:37,733 | server.py:153 | FL finished in 213.42410040800132
INFO flwr 2024-04-03 14:19:37,733 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-03 14:19:37,733 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-03 14:19:37,733 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-03 14:19:37,734 | app.py:229 | app_fit: losses_centralized [(0, 2.3013179302215576), (1, 2.282097339630127), (2, 2.2620291709899902), (3, 2.2393059730529785), (4, 2.2100112438201904), (5, 2.1794114112854004), (6, 2.149282693862915), (7, 2.115694046020508), (8, 2.0829060077667236), (9, 2.0503976345062256), (10, 2.0209290981292725)]
INFO flwr 2024-04-03 14:19:37,734 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.1216), (1, 0.1237), (2, 0.2739), (3, 0.3934), (4, 0.4379), (5, 0.5562), (6, 0.614), (7, 0.6329), (8, 0.6064), (9, 0.6352), (10, 0.6672)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.6672
wandb:     loss 2.02093
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240403_141507-gm3kzhni
wandb: Find logs at: ./wandb/offline-run-20240403_141507-gm3kzhni/logs
Using the latest cached version of the dataset since mnist couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'mnist' at .cache/mnist/mnist/1.0.0/b06aab39e05f7bcd9635d18ed25d06eae523c574 (last modified on Tue Apr  2 18:09:57 2024).
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-03 14:27:08,708 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=63742)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=63742)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-03 14:27:23,748	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-03 14:27:25,467	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-03 14:27:26,373	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_1ae960b82ad8957a.zip' (7.23MiB) to Ray cluster...
2024-04-03 14:27:26,399	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_1ae960b82ad8957a.zip'.
INFO flwr 2024-04-03 14:27:48,153 | app.py:213 | Flower VCE: Ray initialized with resources: {'node:__internal_head__': 1.0, 'node:10.20.240.12': 1.0, 'GPU': 1.0, 'accelerator_type:TITAN': 1.0, 'memory': 165552359629.0, 'object_store_memory': 75236725555.0, 'CPU': 64.0}
INFO flwr 2024-04-03 14:27:48,154 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-03 14:27:48,154 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-03 14:27:48,177 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-03 14:27:48,178 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-03 14:27:48,179 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-03 14:27:48,179 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-03 14:27:51,212 | server.py:94 | initial parameters (loss, other metrics): 2.3037707805633545, {'accuracy': 0.0876, 'data_size': 10000}
INFO flwr 2024-04-03 14:27:51,213 | server.py:104 | FL starting
DEBUG flwr 2024-04-03 14:27:51,213 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=72761)[0m 2024-04-03 14:27:58.490635: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=72761)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=72761)[0m 2024-04-03 14:28:03.369507: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=72761)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=72761)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=72759)[0m 2024-04-03 14:27:58.578706: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=72759)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=72755)[0m 2024-04-03 14:28:03.369507: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-03 14:28:26,535 | server.py:236 | fit_round 1 received 10 results and 0 failures
WARNING flwr 2024-04-03 14:28:26,576 | fedavg.py:250 | No fit_metrics_aggregation_fn provided
INFO flwr 2024-04-03 14:28:27,715 | server.py:125 | fit progress: (1, 2.2632009983062744, {'accuracy': 0.3448, 'data_size': 10000}, 36.502307794000444)
INFO flwr 2024-04-03 14:28:27,716 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-03 14:28:27,716 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:28:35,417 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-03 14:28:36,849 | server.py:125 | fit progress: (2, 2.1999831199645996, {'accuracy': 0.392, 'data_size': 10000}, 45.6356133900008)
INFO flwr 2024-04-03 14:28:36,849 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-03 14:28:36,849 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:28:43,752 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-03 14:28:45,299 | server.py:125 | fit progress: (3, 2.1383140087127686, {'accuracy': 0.5191, 'data_size': 10000}, 54.08593725399987)
INFO flwr 2024-04-03 14:28:45,299 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-03 14:28:45,299 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:28:52,342 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-03 14:28:53,849 | server.py:125 | fit progress: (4, 2.075547456741333, {'accuracy': 0.6631, 'data_size': 10000}, 62.63580316700063)
INFO flwr 2024-04-03 14:28:53,849 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-03 14:28:53,849 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:29:01,057 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-03 14:29:02,583 | server.py:125 | fit progress: (5, 2.0236542224884033, {'accuracy': 0.6933, 'data_size': 10000}, 71.37052636699991)
INFO flwr 2024-04-03 14:29:02,584 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-03 14:29:02,584 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:29:09,718 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-03 14:29:11,315 | server.py:125 | fit progress: (6, 1.9812480211257935, {'accuracy': 0.7225, 'data_size': 10000}, 80.10223586400025)
INFO flwr 2024-04-03 14:29:11,316 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-03 14:29:11,316 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:29:18,178 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-03 14:29:19,883 | server.py:125 | fit progress: (7, 1.9374773502349854, {'accuracy': 0.7257, 'data_size': 10000}, 88.67005536600118)
INFO flwr 2024-04-03 14:29:19,883 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-03 14:29:19,884 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:29:27,081 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-03 14:29:28,739 | server.py:125 | fit progress: (8, 1.9089441299438477, {'accuracy': 0.7548, 'data_size': 10000}, 97.52564502800124)
INFO flwr 2024-04-03 14:29:28,739 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-03 14:29:28,739 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:29:35,828 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-03 14:29:37,688 | server.py:125 | fit progress: (9, 1.878109335899353, {'accuracy': 0.7857, 'data_size': 10000}, 106.4745579090013)
INFO flwr 2024-04-03 14:29:37,688 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-03 14:29:37,688 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:29:44,820 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-03 14:29:46,439 | server.py:125 | fit progress: (10, 1.8580169677734375, {'accuracy': 0.7852, 'data_size': 10000}, 115.22572547300115)
INFO flwr 2024-04-03 14:29:46,439 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-03 14:29:46,439 | server.py:153 | FL finished in 115.22619266900074
INFO flwr 2024-04-03 14:29:46,439 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-03 14:29:46,439 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-03 14:29:46,440 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-03 14:29:46,440 | app.py:229 | app_fit: losses_centralized [(0, 2.3037707805633545), (1, 2.2632009983062744), (2, 2.1999831199645996), (3, 2.1383140087127686), (4, 2.075547456741333), (5, 2.0236542224884033), (6, 1.9812480211257935), (7, 1.9374773502349854), (8, 1.9089441299438477), (9, 1.878109335899353), (10, 1.8580169677734375)]
INFO flwr 2024-04-03 14:29:46,440 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0876), (1, 0.3448), (2, 0.392), (3, 0.5191), (4, 0.6631), (5, 0.6933), (6, 0.7225), (7, 0.7257), (8, 0.7548), (9, 0.7857), (10, 0.7852)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.7852
wandb:     loss 1.85802
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240403_142707-okj9614l
wandb: Find logs at: ./wandb/offline-run-20240403_142707-okj9614l/logs
Using the latest cached version of the dataset since mnist couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'mnist' at .cache/mnist/mnist/1.0.0/b06aab39e05f7bcd9635d18ed25d06eae523c574 (last modified on Tue Apr  2 18:09:57 2024).
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-03 14:36:58,319 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=72755)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=72755)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-03 14:37:03,652	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-03 14:37:03,998	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-03 14:37:04,423	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_f8292141d0ee5a69.zip' (7.27MiB) to Ray cluster...
2024-04-03 14:37:04,446	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_f8292141d0ee5a69.zip'.
INFO flwr 2024-04-03 14:37:19,195 | app.py:213 | Flower VCE: Ray initialized with resources: {'CPU': 64.0, 'GPU': 1.0, 'object_store_memory': 79854216806.0, 'node:__internal_head__': 1.0, 'node:10.20.240.12': 1.0, 'memory': 176326505882.0, 'accelerator_type:TITAN': 1.0}
INFO flwr 2024-04-03 14:37:19,196 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-03 14:37:19,196 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-03 14:37:19,214 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-03 14:37:19,217 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-03 14:37:19,217 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-03 14:37:19,217 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-03 14:37:21,977 | server.py:94 | initial parameters (loss, other metrics): 2.301785469055176, {'accuracy': 0.1134, 'data_size': 10000}
INFO flwr 2024-04-03 14:37:21,977 | server.py:104 | FL starting
DEBUG flwr 2024-04-03 14:37:21,978 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=80504)[0m 2024-04-03 14:37:25.194789: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=80504)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=80504)[0m 2024-04-03 14:37:27.445143: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=80498)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=80498)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=80500)[0m 2024-04-03 14:37:25.515946: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=80500)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=80500)[0m 2024-04-03 14:37:27.896261: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-03 14:37:39,457 | server.py:236 | fit_round 1 received 10 results and 0 failures
WARNING flwr 2024-04-03 14:37:39,495 | fedavg.py:250 | No fit_metrics_aggregation_fn provided
INFO flwr 2024-04-03 14:37:40,639 | server.py:125 | fit progress: (1, 2.2341997623443604, {'accuracy': 0.3486, 'data_size': 10000}, 18.66173724700093)
INFO flwr 2024-04-03 14:37:40,640 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-03 14:37:40,640 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:37:48,410 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-03 14:37:49,817 | server.py:125 | fit progress: (2, 2.1219866275787354, {'accuracy': 0.536, 'data_size': 10000}, 27.839404103999186)
INFO flwr 2024-04-03 14:37:49,817 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-03 14:37:49,817 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:37:56,940 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-03 14:37:58,430 | server.py:125 | fit progress: (3, 2.0182549953460693, {'accuracy': 0.5125, 'data_size': 10000}, 36.45253594099995)
INFO flwr 2024-04-03 14:37:58,430 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-03 14:37:58,431 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:38:05,328 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-03 14:38:06,806 | server.py:125 | fit progress: (4, 1.948380708694458, {'accuracy': 0.6806, 'data_size': 10000}, 44.828072186999634)
INFO flwr 2024-04-03 14:38:06,806 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-03 14:38:06,806 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:38:13,812 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-03 14:38:15,361 | server.py:125 | fit progress: (5, 1.9088722467422485, {'accuracy': 0.7173, 'data_size': 10000}, 53.38362225200035)
INFO flwr 2024-04-03 14:38:15,361 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-03 14:38:15,362 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:38:22,489 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-03 14:38:24,065 | server.py:125 | fit progress: (6, 1.861946702003479, {'accuracy': 0.752, 'data_size': 10000}, 62.08706153899948)
INFO flwr 2024-04-03 14:38:24,065 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-03 14:38:24,065 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:38:31,242 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-03 14:38:34,215 | server.py:125 | fit progress: (7, 1.827425241470337, {'accuracy': 0.7824, 'data_size': 10000}, 72.2378551189995)
INFO flwr 2024-04-03 14:38:34,216 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-03 14:38:34,216 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:38:41,322 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-03 14:38:42,916 | server.py:125 | fit progress: (8, 1.800580620765686, {'accuracy': 0.7916, 'data_size': 10000}, 80.93845603199952)
INFO flwr 2024-04-03 14:38:42,916 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-03 14:38:42,916 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:38:49,765 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-03 14:38:51,382 | server.py:125 | fit progress: (9, 1.7809770107269287, {'accuracy': 0.8213, 'data_size': 10000}, 89.40468929599956)
INFO flwr 2024-04-03 14:38:51,382 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-03 14:38:51,383 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:38:58,547 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-03 14:39:00,533 | server.py:125 | fit progress: (10, 1.7585777044296265, {'accuracy': 0.8304, 'data_size': 10000}, 98.55521252799917)
INFO flwr 2024-04-03 14:39:00,533 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-03 14:39:00,533 | server.py:153 | FL finished in 98.55568744099946
INFO flwr 2024-04-03 14:39:00,533 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-03 14:39:00,534 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-03 14:39:00,534 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-03 14:39:00,534 | app.py:229 | app_fit: losses_centralized [(0, 2.301785469055176), (1, 2.2341997623443604), (2, 2.1219866275787354), (3, 2.0182549953460693), (4, 1.948380708694458), (5, 1.9088722467422485), (6, 1.861946702003479), (7, 1.827425241470337), (8, 1.800580620765686), (9, 1.7809770107269287), (10, 1.7585777044296265)]
INFO flwr 2024-04-03 14:39:00,534 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.1134), (1, 0.3486), (2, 0.536), (3, 0.5125), (4, 0.6806), (5, 0.7173), (6, 0.752), (7, 0.7824), (8, 0.7916), (9, 0.8213), (10, 0.8304)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.8304
wandb:     loss 1.75858
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240403_143657-1j9q0s82
wandb: Find logs at: ./wandb/offline-run-20240403_143657-1j9q0s82/logs
Using the latest cached version of the dataset since mnist couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'mnist' at .cache/mnist/mnist/1.0.0/b06aab39e05f7bcd9635d18ed25d06eae523c574 (last modified on Tue Apr  2 18:09:57 2024).
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-03 14:46:12,001 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=80493)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=80493)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-03 14:46:16,602	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-03 14:46:17,010	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-03 14:46:17,367	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_4ea002ac6925799d.zip' (7.29MiB) to Ray cluster...
2024-04-03 14:46:17,383	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_4ea002ac6925799d.zip'.
INFO flwr 2024-04-03 14:46:28,553 | app.py:213 | Flower VCE: Ray initialized with resources: {'object_store_memory': 79757547110.0, 'GPU': 1.0, 'CPU': 64.0, 'accelerator_type:TITAN': 1.0, 'memory': 176100943258.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0}
INFO flwr 2024-04-03 14:46:28,553 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-03 14:46:28,553 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-03 14:46:28,573 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-03 14:46:28,574 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-03 14:46:28,575 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-03 14:46:28,575 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-03 14:46:31,562 | server.py:94 | initial parameters (loss, other metrics): 2.301466464996338, {'accuracy': 0.117, 'data_size': 10000}
INFO flwr 2024-04-03 14:46:31,563 | server.py:104 | FL starting
DEBUG flwr 2024-04-03 14:46:31,563 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=87912)[0m 2024-04-03 14:46:34.511887: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=87912)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=87912)[0m 2024-04-03 14:46:36.816123: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=87915)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=87915)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=87916)[0m 2024-04-03 14:46:34.754568: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=87916)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=87918)[0m 2024-04-03 14:46:37.130733: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-03 14:46:47,785 | server.py:236 | fit_round 1 received 10 results and 0 failures
WARNING flwr 2024-04-03 14:46:47,817 | fedavg.py:250 | No fit_metrics_aggregation_fn provided
INFO flwr 2024-04-03 14:46:48,990 | server.py:125 | fit progress: (1, 2.2982723712921143, {'accuracy': 0.1505, 'data_size': 10000}, 17.426825080998242)
INFO flwr 2024-04-03 14:46:48,990 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-03 14:46:48,990 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:46:56,601 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-03 14:46:57,797 | server.py:125 | fit progress: (2, 2.2950356006622314, {'accuracy': 0.1622, 'data_size': 10000}, 26.233657823999238)
INFO flwr 2024-04-03 14:46:57,797 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-03 14:46:57,797 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:47:04,583 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-03 14:47:06,010 | server.py:125 | fit progress: (3, 2.2902050018310547, {'accuracy': 0.1158, 'data_size': 10000}, 34.44720210399828)
INFO flwr 2024-04-03 14:47:06,010 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-03 14:47:06,011 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:47:12,748 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-03 14:47:14,202 | server.py:125 | fit progress: (4, 2.2866148948669434, {'accuracy': 0.1143, 'data_size': 10000}, 42.639427713998884)
INFO flwr 2024-04-03 14:47:14,203 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-03 14:47:14,203 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:47:21,298 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-03 14:47:22,835 | server.py:125 | fit progress: (5, 2.281604766845703, {'accuracy': 0.1434, 'data_size': 10000}, 51.27205373299876)
INFO flwr 2024-04-03 14:47:22,835 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-03 14:47:22,835 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:47:29,835 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-03 14:47:31,365 | server.py:125 | fit progress: (6, 2.276801109313965, {'accuracy': 0.1962, 'data_size': 10000}, 59.802615085998696)
INFO flwr 2024-04-03 14:47:31,366 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-03 14:47:31,366 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:47:38,268 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-03 14:47:39,677 | server.py:125 | fit progress: (7, 2.2718608379364014, {'accuracy': 0.2651, 'data_size': 10000}, 68.1141771779985)
INFO flwr 2024-04-03 14:47:39,677 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-03 14:47:39,678 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:47:46,865 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-03 14:47:48,245 | server.py:125 | fit progress: (8, 2.2661900520324707, {'accuracy': 0.303, 'data_size': 10000}, 76.68211167499976)
INFO flwr 2024-04-03 14:47:48,245 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-03 14:47:48,246 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:47:55,283 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-03 14:47:56,920 | server.py:125 | fit progress: (9, 2.259756326675415, {'accuracy': 0.3732, 'data_size': 10000}, 85.35672668799998)
INFO flwr 2024-04-03 14:47:56,920 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-03 14:47:56,920 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:48:03,891 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-03 14:48:05,523 | server.py:125 | fit progress: (10, 2.2524092197418213, {'accuracy': 0.4011, 'data_size': 10000}, 93.9601650279983)
INFO flwr 2024-04-03 14:48:05,523 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-03 14:48:05,524 | server.py:153 | FL finished in 93.96071291599947
INFO flwr 2024-04-03 14:48:05,524 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-03 14:48:05,524 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-03 14:48:05,524 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-03 14:48:05,524 | app.py:229 | app_fit: losses_centralized [(0, 2.301466464996338), (1, 2.2982723712921143), (2, 2.2950356006622314), (3, 2.2902050018310547), (4, 2.2866148948669434), (5, 2.281604766845703), (6, 2.276801109313965), (7, 2.2718608379364014), (8, 2.2661900520324707), (9, 2.259756326675415), (10, 2.2524092197418213)]
INFO flwr 2024-04-03 14:48:05,524 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.117), (1, 0.1505), (2, 0.1622), (3, 0.1158), (4, 0.1143), (5, 0.1434), (6, 0.1962), (7, 0.2651), (8, 0.303), (9, 0.3732), (10, 0.4011)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.4011
wandb:     loss 2.25241
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240403_144611-thwe2mr4
wandb: Find logs at: ./wandb/offline-run-20240403_144611-thwe2mr4/logs
Using the latest cached version of the dataset since mnist couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'mnist' at .cache/mnist/mnist/1.0.0/b06aab39e05f7bcd9635d18ed25d06eae523c574 (last modified on Tue Apr  2 18:09:57 2024).
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-03 14:55:18,138 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=87911)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=87911)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-03 14:55:41,803	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-03 14:55:45,919	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-03 14:55:46,861	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_c74db944925eaf78.zip' (7.30MiB) to Ray cluster...
2024-04-03 14:55:46,882	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_c74db944925eaf78.zip'.
INFO flwr 2024-04-03 14:55:59,829 | app.py:213 | Flower VCE: Ray initialized with resources: {'GPU': 1.0, 'CPU': 64.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0, 'object_store_memory': 80138138419.0, 'memory': 176988989645.0, 'accelerator_type:TITAN': 1.0}
INFO flwr 2024-04-03 14:55:59,829 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-03 14:55:59,829 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-03 14:55:59,848 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-03 14:55:59,849 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-03 14:55:59,849 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-03 14:55:59,849 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-03 14:56:04,227 | server.py:94 | initial parameters (loss, other metrics): 2.3058040142059326, {'accuracy': 0.0747, 'data_size': 10000}
INFO flwr 2024-04-03 14:56:04,228 | server.py:104 | FL starting
DEBUG flwr 2024-04-03 14:56:04,228 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=92915)[0m 2024-04-03 14:56:11.004467: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=92915)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=92915)[0m 2024-04-03 14:56:34.930607: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(pid=92917)[0m 2024-04-03 14:56:11.005977: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=92917)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=92915)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=92915)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=92917)[0m 2024-04-03 14:56:34.930607: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-03 14:57:23,841 | server.py:236 | fit_round 1 received 10 results and 0 failures
WARNING flwr 2024-04-03 14:57:23,876 | fedavg.py:250 | No fit_metrics_aggregation_fn provided
INFO flwr 2024-04-03 14:57:25,000 | server.py:125 | fit progress: (1, 2.2840750217437744, {'accuracy': 0.1982, 'data_size': 10000}, 80.77273323699956)
INFO flwr 2024-04-03 14:57:25,001 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-03 14:57:25,001 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:57:32,809 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-03 14:57:34,113 | server.py:125 | fit progress: (2, 2.2573764324188232, {'accuracy': 0.4191, 'data_size': 10000}, 89.88515033899967)
INFO flwr 2024-04-03 14:57:34,113 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-03 14:57:34,113 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:57:40,843 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-03 14:57:42,382 | server.py:125 | fit progress: (3, 2.2186012268066406, {'accuracy': 0.5025, 'data_size': 10000}, 98.15435749400058)
INFO flwr 2024-04-03 14:57:42,382 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-03 14:57:42,383 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:57:49,179 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-03 14:57:50,698 | server.py:125 | fit progress: (4, 2.1675455570220947, {'accuracy': 0.4608, 'data_size': 10000}, 106.47073770799943)
INFO flwr 2024-04-03 14:57:50,699 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-03 14:57:50,699 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:57:57,847 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-03 14:57:59,462 | server.py:125 | fit progress: (5, 2.132138252258301, {'accuracy': 0.5409, 'data_size': 10000}, 115.23383989899958)
INFO flwr 2024-04-03 14:57:59,462 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-03 14:57:59,462 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:58:06,290 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-03 14:58:07,835 | server.py:125 | fit progress: (6, 2.093271255493164, {'accuracy': 0.5875, 'data_size': 10000}, 123.6071264000002)
INFO flwr 2024-04-03 14:58:07,835 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-03 14:58:07,835 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:58:14,924 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-03 14:58:16,563 | server.py:125 | fit progress: (7, 2.045522451400757, {'accuracy': 0.6859, 'data_size': 10000}, 132.3352022580002)
INFO flwr 2024-04-03 14:58:16,563 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-03 14:58:16,563 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:58:23,591 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-03 14:58:25,223 | server.py:125 | fit progress: (8, 2.014662265777588, {'accuracy': 0.7025, 'data_size': 10000}, 140.99494718700043)
INFO flwr 2024-04-03 14:58:25,223 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-03 14:58:25,223 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:58:32,009 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-03 14:58:33,655 | server.py:125 | fit progress: (9, 1.9759494066238403, {'accuracy': 0.6996, 'data_size': 10000}, 149.4275575520005)
INFO flwr 2024-04-03 14:58:33,656 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-03 14:58:33,656 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 14:58:40,620 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-03 14:58:42,277 | server.py:125 | fit progress: (10, 1.9468106031417847, {'accuracy': 0.7341, 'data_size': 10000}, 158.0495244520007)
INFO flwr 2024-04-03 14:58:42,278 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-03 14:58:42,278 | server.py:153 | FL finished in 158.05003729999953
INFO flwr 2024-04-03 14:58:42,278 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-03 14:58:42,278 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-03 14:58:42,278 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-03 14:58:42,278 | app.py:229 | app_fit: losses_centralized [(0, 2.3058040142059326), (1, 2.2840750217437744), (2, 2.2573764324188232), (3, 2.2186012268066406), (4, 2.1675455570220947), (5, 2.132138252258301), (6, 2.093271255493164), (7, 2.045522451400757), (8, 2.014662265777588), (9, 1.9759494066238403), (10, 1.9468106031417847)]
INFO flwr 2024-04-03 14:58:42,279 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0747), (1, 0.1982), (2, 0.4191), (3, 0.5025), (4, 0.4608), (5, 0.5409), (6, 0.5875), (7, 0.6859), (8, 0.7025), (9, 0.6996), (10, 0.7341)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.7341
wandb:     loss 1.94681
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240403_145516-yso9264z
wandb: Find logs at: ./wandb/offline-run-20240403_145516-yso9264z/logs
Using the latest cached version of the dataset since mnist couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'mnist' at .cache/mnist/mnist/1.0.0/b06aab39e05f7bcd9635d18ed25d06eae523c574 (last modified on Tue Apr  2 18:09:57 2024).
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-03 15:06:07,030 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=92917)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=92917)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-03 15:06:16,316	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-03 15:06:16,858	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-03 15:06:17,179	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_5309f7990254e3cf.zip' (7.31MiB) to Ray cluster...
2024-04-03 15:06:17,202	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_5309f7990254e3cf.zip'.
INFO flwr 2024-04-03 15:06:28,427 | app.py:213 | Flower VCE: Ray initialized with resources: {'GPU': 1.0, 'object_store_memory': 80312006246.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0, 'accelerator_type:TITAN': 1.0, 'memory': 177394681242.0, 'CPU': 64.0}
INFO flwr 2024-04-03 15:06:28,428 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-03 15:06:28,428 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-03 15:06:28,449 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-03 15:06:28,450 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-03 15:06:28,450 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-03 15:06:28,451 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-03 15:06:31,459 | server.py:94 | initial parameters (loss, other metrics): 2.304913282394409, {'accuracy': 0.0592, 'data_size': 10000}
INFO flwr 2024-04-03 15:06:31,459 | server.py:104 | FL starting
DEBUG flwr 2024-04-03 15:06:31,459 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=97858)[0m 2024-04-03 15:06:35.283065: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=97858)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=97855)[0m 2024-04-03 15:06:38.488476: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=97855)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=97855)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=97848)[0m 2024-04-03 15:06:35.354293: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=97848)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=97848)[0m 2024-04-03 15:06:38.488475: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-03 15:06:52,938 | server.py:236 | fit_round 1 received 10 results and 0 failures
WARNING flwr 2024-04-03 15:06:52,976 | fedavg.py:250 | No fit_metrics_aggregation_fn provided
INFO flwr 2024-04-03 15:06:54,364 | server.py:125 | fit progress: (1, 2.238173484802246, {'accuracy': 0.3593, 'data_size': 10000}, 22.90437643400037)
INFO flwr 2024-04-03 15:06:54,364 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-03 15:06:54,364 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:07:02,466 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-03 15:07:03,937 | server.py:125 | fit progress: (2, 2.166766405105591, {'accuracy': 0.5499, 'data_size': 10000}, 32.47814785999981)
INFO flwr 2024-04-03 15:07:03,938 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-03 15:07:03,938 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:07:10,935 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-03 15:07:12,384 | server.py:125 | fit progress: (3, 2.0822746753692627, {'accuracy': 0.5663, 'data_size': 10000}, 40.92434180099917)
INFO flwr 2024-04-03 15:07:12,384 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-03 15:07:12,384 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:07:19,559 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-03 15:07:21,061 | server.py:125 | fit progress: (4, 2.016289710998535, {'accuracy': 0.6165, 'data_size': 10000}, 49.60163827799988)
INFO flwr 2024-04-03 15:07:21,061 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-03 15:07:21,061 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:07:28,259 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-03 15:07:29,551 | server.py:125 | fit progress: (5, 1.9656367301940918, {'accuracy': 0.6806, 'data_size': 10000}, 58.09206969799925)
INFO flwr 2024-04-03 15:07:29,552 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-03 15:07:29,552 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:07:36,982 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-03 15:07:38,346 | server.py:125 | fit progress: (6, 1.913364291191101, {'accuracy': 0.7644, 'data_size': 10000}, 66.88698073799969)
INFO flwr 2024-04-03 15:07:38,347 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-03 15:07:38,347 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:07:45,448 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-03 15:07:47,062 | server.py:125 | fit progress: (7, 1.8761035203933716, {'accuracy': 0.7984, 'data_size': 10000}, 75.60304789399925)
INFO flwr 2024-04-03 15:07:47,063 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-03 15:07:47,063 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:07:54,083 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-03 15:07:55,711 | server.py:125 | fit progress: (8, 1.8499963283538818, {'accuracy': 0.8164, 'data_size': 10000}, 84.25156862800031)
INFO flwr 2024-04-03 15:07:55,711 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-03 15:07:55,711 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:08:03,023 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-03 15:08:04,692 | server.py:125 | fit progress: (9, 1.8280972242355347, {'accuracy': 0.8028, 'data_size': 10000}, 93.23322480599927)
INFO flwr 2024-04-03 15:08:04,693 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-03 15:08:04,693 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:08:11,938 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-03 15:08:13,659 | server.py:125 | fit progress: (10, 1.8084454536437988, {'accuracy': 0.8301, 'data_size': 10000}, 102.20012590899933)
INFO flwr 2024-04-03 15:08:13,660 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-03 15:08:13,660 | server.py:153 | FL finished in 102.20057957099925
INFO flwr 2024-04-03 15:08:13,660 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-03 15:08:13,660 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-03 15:08:13,660 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-03 15:08:13,660 | app.py:229 | app_fit: losses_centralized [(0, 2.304913282394409), (1, 2.238173484802246), (2, 2.166766405105591), (3, 2.0822746753692627), (4, 2.016289710998535), (5, 1.9656367301940918), (6, 1.913364291191101), (7, 1.8761035203933716), (8, 1.8499963283538818), (9, 1.8280972242355347), (10, 1.8084454536437988)]
INFO flwr 2024-04-03 15:08:13,661 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0592), (1, 0.3593), (2, 0.5499), (3, 0.5663), (4, 0.6165), (5, 0.6806), (6, 0.7644), (7, 0.7984), (8, 0.8164), (9, 0.8028), (10, 0.8301)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.8301
wandb:     loss 1.80845
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240403_150606-shhclfs2
wandb: Find logs at: ./wandb/offline-run-20240403_150606-shhclfs2/logs
Using the latest cached version of the dataset since mnist couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'mnist' at .cache/mnist/mnist/1.0.0/b06aab39e05f7bcd9635d18ed25d06eae523c574 (last modified on Tue Apr  2 18:09:57 2024).
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-03 15:15:27,940 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=97848)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=97848)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-03 15:15:36,847	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-03 15:15:37,337	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-03 15:15:37,687	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_d57bb9b18825c785.zip' (7.32MiB) to Ray cluster...
2024-04-03 15:15:37,710	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_d57bb9b18825c785.zip'.
INFO flwr 2024-04-03 15:15:48,935 | app.py:213 | Flower VCE: Ray initialized with resources: {'CPU': 64.0, 'accelerator_type:TITAN': 1.0, 'memory': 176800778036.0, 'object_store_memory': 80057476300.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0, 'GPU': 1.0}
INFO flwr 2024-04-03 15:15:48,936 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-03 15:15:48,936 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-03 15:15:48,954 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-03 15:15:48,955 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-03 15:15:48,955 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-03 15:15:48,955 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-03 15:15:51,900 | server.py:94 | initial parameters (loss, other metrics): 2.3067049980163574, {'accuracy': 0.0589, 'data_size': 10000}
INFO flwr 2024-04-03 15:15:51,901 | server.py:104 | FL starting
DEBUG flwr 2024-04-03 15:15:51,902 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=102311)[0m 2024-04-03 15:16:03.834963: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=102311)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=102311)[0m 2024-04-03 15:16:08.375554: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=102311)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=102311)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=102304)[0m 2024-04-03 15:16:03.829135: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=102304)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=102304)[0m 2024-04-03 15:16:08.375558: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-03 15:16:26,488 | server.py:236 | fit_round 1 received 10 results and 0 failures
WARNING flwr 2024-04-03 15:16:26,519 | fedavg.py:250 | No fit_metrics_aggregation_fn provided
INFO flwr 2024-04-03 15:16:27,929 | server.py:125 | fit progress: (1, 2.2070629596710205, {'accuracy': 0.4395, 'data_size': 10000}, 36.02762605300086)
INFO flwr 2024-04-03 15:16:27,930 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-03 15:16:27,930 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:16:35,697 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-03 15:16:37,155 | server.py:125 | fit progress: (2, 2.064203977584839, {'accuracy': 0.5845, 'data_size': 10000}, 45.253551558000254)
INFO flwr 2024-04-03 15:16:37,156 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-03 15:16:37,156 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:16:44,279 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-03 15:16:45,825 | server.py:125 | fit progress: (3, 1.969566822052002, {'accuracy': 0.6321, 'data_size': 10000}, 53.92328568500125)
INFO flwr 2024-04-03 15:16:45,825 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-03 15:16:45,825 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:16:53,112 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-03 15:16:54,425 | server.py:125 | fit progress: (4, 1.9161471128463745, {'accuracy': 0.6601, 'data_size': 10000}, 62.52344537099998)
INFO flwr 2024-04-03 15:16:54,425 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-03 15:16:54,426 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:17:01,640 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-03 15:17:03,278 | server.py:125 | fit progress: (5, 1.861188530921936, {'accuracy': 0.7272, 'data_size': 10000}, 71.37651905300118)
INFO flwr 2024-04-03 15:17:03,278 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-03 15:17:03,279 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:17:10,495 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-03 15:17:12,121 | server.py:125 | fit progress: (6, 1.8328503370285034, {'accuracy': 0.7693, 'data_size': 10000}, 80.21969567500128)
INFO flwr 2024-04-03 15:17:12,122 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-03 15:17:12,122 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:17:19,344 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-03 15:17:23,890 | server.py:125 | fit progress: (7, 1.8182709217071533, {'accuracy': 0.767, 'data_size': 10000}, 91.98845462700046)
INFO flwr 2024-04-03 15:17:23,890 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-03 15:17:23,891 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:17:30,963 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-03 15:17:32,469 | server.py:125 | fit progress: (8, 1.7954550981521606, {'accuracy': 0.772, 'data_size': 10000}, 100.56767411100009)
INFO flwr 2024-04-03 15:17:32,470 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-03 15:17:32,470 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:17:39,911 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-03 15:17:41,467 | server.py:125 | fit progress: (9, 1.783579707145691, {'accuracy': 0.7765, 'data_size': 10000}, 109.56533249200038)
INFO flwr 2024-04-03 15:17:41,467 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-03 15:17:41,467 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:17:48,501 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-03 15:17:50,677 | server.py:125 | fit progress: (10, 1.7460044622421265, {'accuracy': 0.8408, 'data_size': 10000}, 118.77577517800091)
INFO flwr 2024-04-03 15:17:50,678 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-03 15:17:50,678 | server.py:153 | FL finished in 118.77626847400097
INFO flwr 2024-04-03 15:17:50,678 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-03 15:17:50,678 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-03 15:17:50,678 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-03 15:17:50,679 | app.py:229 | app_fit: losses_centralized [(0, 2.3067049980163574), (1, 2.2070629596710205), (2, 2.064203977584839), (3, 1.969566822052002), (4, 1.9161471128463745), (5, 1.861188530921936), (6, 1.8328503370285034), (7, 1.8182709217071533), (8, 1.7954550981521606), (9, 1.783579707145691), (10, 1.7460044622421265)]
INFO flwr 2024-04-03 15:17:50,679 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0589), (1, 0.4395), (2, 0.5845), (3, 0.6321), (4, 0.6601), (5, 0.7272), (6, 0.7693), (7, 0.767), (8, 0.772), (9, 0.7765), (10, 0.8408)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.8408
wandb:     loss 1.746
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240403_151527-l5yx94f1
wandb: Find logs at: ./wandb/offline-run-20240403_151527-l5yx94f1/logs
Using the latest cached version of the dataset since mnist couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'mnist' at .cache/mnist/mnist/1.0.0/b06aab39e05f7bcd9635d18ed25d06eae523c574 (last modified on Tue Apr  2 18:09:57 2024).
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-03 15:25:04,074 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=102304)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=102304)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-03 15:25:09,444	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-03 15:25:09,982	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-03 15:25:10,314	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_2a9019dd4cce2827.zip' (7.33MiB) to Ray cluster...
2024-04-03 15:25:10,336	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_2a9019dd4cce2827.zip'.
INFO flwr 2024-04-03 15:25:21,490 | app.py:213 | Flower VCE: Ray initialized with resources: {'GPU': 1.0, 'object_store_memory': 80023359897.0, 'node:__internal_head__': 1.0, 'node:10.20.240.12': 1.0, 'CPU': 64.0, 'accelerator_type:TITAN': 1.0, 'memory': 176721173095.0}
INFO flwr 2024-04-03 15:25:21,490 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-03 15:25:21,491 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-03 15:25:21,508 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-03 15:25:21,511 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-03 15:25:21,512 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-03 15:25:21,512 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-03 15:25:25,416 | server.py:94 | initial parameters (loss, other metrics): 2.3043336868286133, {'accuracy': 0.0808, 'data_size': 10000}
INFO flwr 2024-04-03 15:25:25,416 | server.py:104 | FL starting
DEBUG flwr 2024-04-03 15:25:25,417 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=108122)[0m 2024-04-03 15:25:27.747789: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=108122)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=108122)[0m 2024-04-03 15:25:30.423628: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=108122)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=108122)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=108118)[0m 2024-04-03 15:25:27.939996: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=108118)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=108118)[0m 2024-04-03 15:25:30.423628: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-03 15:25:44,311 | server.py:236 | fit_round 1 received 10 results and 0 failures
WARNING flwr 2024-04-03 15:25:44,342 | fedavg.py:250 | No fit_metrics_aggregation_fn provided
INFO flwr 2024-04-03 15:25:45,758 | server.py:125 | fit progress: (1, 2.300053358078003, {'accuracy': 0.1192, 'data_size': 10000}, 20.341463094000574)
INFO flwr 2024-04-03 15:25:45,758 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-03 15:25:45,759 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:25:53,494 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-03 15:25:54,937 | server.py:125 | fit progress: (2, 2.2953782081604004, {'accuracy': 0.167, 'data_size': 10000}, 29.519843447998937)
INFO flwr 2024-04-03 15:25:54,937 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-03 15:25:54,937 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:26:01,895 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-03 15:26:03,118 | server.py:125 | fit progress: (3, 2.290130138397217, {'accuracy': 0.2489, 'data_size': 10000}, 37.70123125200007)
INFO flwr 2024-04-03 15:26:03,118 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-03 15:26:03,118 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:26:10,406 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-03 15:26:11,733 | server.py:125 | fit progress: (4, 2.284050226211548, {'accuracy': 0.3127, 'data_size': 10000}, 46.31651217699982)
INFO flwr 2024-04-03 15:26:11,734 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-03 15:26:11,734 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:26:18,923 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-03 15:26:20,456 | server.py:125 | fit progress: (5, 2.2775330543518066, {'accuracy': 0.362, 'data_size': 10000}, 55.039462136999646)
INFO flwr 2024-04-03 15:26:20,456 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-03 15:26:20,457 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:26:27,514 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-03 15:26:29,087 | server.py:125 | fit progress: (6, 2.270075559616089, {'accuracy': 0.4045, 'data_size': 10000}, 63.66998663800041)
INFO flwr 2024-04-03 15:26:29,087 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-03 15:26:29,087 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:26:36,122 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-03 15:26:37,723 | server.py:125 | fit progress: (7, 2.2616541385650635, {'accuracy': 0.4155, 'data_size': 10000}, 72.3062496829989)
INFO flwr 2024-04-03 15:26:37,723 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-03 15:26:37,723 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:26:44,733 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-03 15:26:46,147 | server.py:125 | fit progress: (8, 2.252969741821289, {'accuracy': 0.4541, 'data_size': 10000}, 80.72981199499918)
INFO flwr 2024-04-03 15:26:46,147 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-03 15:26:46,147 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:26:53,531 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-03 15:26:54,981 | server.py:125 | fit progress: (9, 2.2390341758728027, {'accuracy': 0.4168, 'data_size': 10000}, 89.56423684000038)
INFO flwr 2024-04-03 15:26:54,981 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-03 15:26:54,981 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:27:01,853 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-03 15:27:03,570 | server.py:125 | fit progress: (10, 2.2255001068115234, {'accuracy': 0.4099, 'data_size': 10000}, 98.15299301099913)
INFO flwr 2024-04-03 15:27:03,570 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-03 15:27:03,570 | server.py:153 | FL finished in 98.15347414600001
INFO flwr 2024-04-03 15:27:03,570 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-03 15:27:03,570 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-03 15:27:03,571 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-03 15:27:03,571 | app.py:229 | app_fit: losses_centralized [(0, 2.3043336868286133), (1, 2.300053358078003), (2, 2.2953782081604004), (3, 2.290130138397217), (4, 2.284050226211548), (5, 2.2775330543518066), (6, 2.270075559616089), (7, 2.2616541385650635), (8, 2.252969741821289), (9, 2.2390341758728027), (10, 2.2255001068115234)]
INFO flwr 2024-04-03 15:27:03,571 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0808), (1, 0.1192), (2, 0.167), (3, 0.2489), (4, 0.3127), (5, 0.362), (6, 0.4045), (7, 0.4155), (8, 0.4541), (9, 0.4168), (10, 0.4099)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.4099
wandb:     loss 2.2255
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240403_152503-c3f0lv2c
wandb: Find logs at: ./wandb/offline-run-20240403_152503-c3f0lv2c/logs
Using the latest cached version of the dataset since mnist couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'mnist' at .cache/mnist/mnist/1.0.0/b06aab39e05f7bcd9635d18ed25d06eae523c574 (last modified on Tue Apr  2 18:09:57 2024).
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-03 15:34:16,365 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=108118)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=108118)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-03 15:34:21,435	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-03 15:34:21,941	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-03 15:34:22,285	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_071d5876938e8d4e.zip' (7.34MiB) to Ray cluster...
2024-04-03 15:34:22,306	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_071d5876938e8d4e.zip'.
INFO flwr 2024-04-03 15:34:33,556 | app.py:213 | Flower VCE: Ray initialized with resources: {'accelerator_type:TITAN': 1.0, 'memory': 176672098100.0, 'GPU': 1.0, 'object_store_memory': 80002327756.0, 'CPU': 64.0, 'node:10.20.240.12': 1.0, 'node:__internal_head__': 1.0}
INFO flwr 2024-04-03 15:34:33,556 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-03 15:34:33,556 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-03 15:34:33,575 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-03 15:34:33,576 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-03 15:34:33,577 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-03 15:34:33,577 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-03 15:34:37,549 | server.py:94 | initial parameters (loss, other metrics): 2.305086135864258, {'accuracy': 0.107, 'data_size': 10000}
INFO flwr 2024-04-03 15:34:37,552 | server.py:104 | FL starting
DEBUG flwr 2024-04-03 15:34:37,553 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=114208)[0m 2024-04-03 15:34:39.797449: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=114208)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=114208)[0m 2024-04-03 15:34:42.417744: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(DefaultActor pid=114208)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=114208)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=114210)[0m 2024-04-03 15:34:39.856152: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=114210)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(pid=114210)[0m 2024-04-03 15:34:42.417744: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-03 15:34:56,356 | server.py:236 | fit_round 1 received 10 results and 0 failures
WARNING flwr 2024-04-03 15:34:56,389 | fedavg.py:250 | No fit_metrics_aggregation_fn provided
INFO flwr 2024-04-03 15:34:57,543 | server.py:125 | fit progress: (1, 2.2827658653259277, {'accuracy': 0.1519, 'data_size': 10000}, 19.990789563000362)
INFO flwr 2024-04-03 15:34:57,544 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-03 15:34:57,544 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:35:05,658 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-03 15:35:06,907 | server.py:125 | fit progress: (2, 2.2424371242523193, {'accuracy': 0.3648, 'data_size': 10000}, 29.35488922299919)
INFO flwr 2024-04-03 15:35:06,908 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-03 15:35:06,908 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:35:14,113 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-03 15:35:15,620 | server.py:125 | fit progress: (3, 2.199552297592163, {'accuracy': 0.5696, 'data_size': 10000}, 38.067436466999425)
INFO flwr 2024-04-03 15:35:15,620 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-03 15:35:15,620 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:35:22,877 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-03 15:35:24,472 | server.py:125 | fit progress: (4, 2.1488685607910156, {'accuracy': 0.4955, 'data_size': 10000}, 46.91996541499975)
INFO flwr 2024-04-03 15:35:24,473 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-03 15:35:24,473 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:35:32,011 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-03 15:35:33,771 | server.py:125 | fit progress: (5, 2.1060245037078857, {'accuracy': 0.4865, 'data_size': 10000}, 56.21891868199964)
INFO flwr 2024-04-03 15:35:33,772 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-03 15:35:33,772 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:35:40,993 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-03 15:35:42,685 | server.py:125 | fit progress: (6, 2.0581440925598145, {'accuracy': 0.5264, 'data_size': 10000}, 65.13215438899897)
INFO flwr 2024-04-03 15:35:42,685 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-03 15:35:42,685 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:35:50,327 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-03 15:35:52,084 | server.py:125 | fit progress: (7, 2.02895188331604, {'accuracy': 0.5506, 'data_size': 10000}, 74.53156352899896)
INFO flwr 2024-04-03 15:35:52,084 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-03 15:35:52,085 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:35:59,623 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-03 15:36:01,377 | server.py:125 | fit progress: (8, 1.998887062072754, {'accuracy': 0.5928, 'data_size': 10000}, 83.82433757999934)
INFO flwr 2024-04-03 15:36:01,377 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-03 15:36:01,377 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:36:09,040 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-03 15:36:10,637 | server.py:125 | fit progress: (9, 1.958019733428955, {'accuracy': 0.6521, 'data_size': 10000}, 93.08495164399937)
INFO flwr 2024-04-03 15:36:10,638 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-03 15:36:10,638 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:36:18,380 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-03 15:36:20,241 | server.py:125 | fit progress: (10, 1.933623194694519, {'accuracy': 0.7142, 'data_size': 10000}, 102.68819636199987)
INFO flwr 2024-04-03 15:36:20,241 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-03 15:36:20,241 | server.py:153 | FL finished in 102.6886323259987
INFO flwr 2024-04-03 15:36:20,241 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-03 15:36:20,241 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-03 15:36:20,242 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-03 15:36:20,242 | app.py:229 | app_fit: losses_centralized [(0, 2.305086135864258), (1, 2.2827658653259277), (2, 2.2424371242523193), (3, 2.199552297592163), (4, 2.1488685607910156), (5, 2.1060245037078857), (6, 2.0581440925598145), (7, 2.02895188331604), (8, 1.998887062072754), (9, 1.958019733428955), (10, 1.933623194694519)]
INFO flwr 2024-04-03 15:36:20,242 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.107), (1, 0.1519), (2, 0.3648), (3, 0.5696), (4, 0.4955), (5, 0.4865), (6, 0.5264), (7, 0.5506), (8, 0.5928), (9, 0.6521), (10, 0.7142)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.7142
wandb:     loss 1.93362
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240403_153415-36mtqkjz
wandb: Find logs at: ./wandb/offline-run-20240403_153415-36mtqkjz/logs
Using the latest cached version of the dataset since mnist couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'mnist' at .cache/mnist/mnist/1.0.0/b06aab39e05f7bcd9635d18ed25d06eae523c574 (last modified on Tue Apr  2 18:09:57 2024).
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-03 15:43:46,274 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=114210)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=114210)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-03 15:44:11,080	ERROR services.py:1207 -- Failed to start the dashboard 
2024-04-03 15:44:11,082	ERROR services.py:1232 -- Error should be written to 'dashboard.log' or 'dashboard.err'. We are printing the last 20 lines for you. See 'https://docs.ray.io/en/master/ray-observability/ray-logging.html#logging-directory-structure' to find where the log file is.
2024-04-03 15:44:11,082	ERROR services.py:1242 -- Couldn't read dashboard.log file. Error: [Errno 2] No such file or directory: '/tmp/ray/session_2024-04-03_15-43-49_577198_2335/logs/dashboard.log'. It means the dashboard is broken even before it initializes the logger (mostly dependency issues). Reading the dashboard.err file which contains stdout/stderr.
2024-04-03 15:44:11,083	ERROR services.py:1276 -- Failed to read dashboard.err file: cannot mmap an empty file. It is unexpected. Please report an issue to Ray github. https://github.com/ray-project/ray/issues
2024-04-03 15:44:11,287	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-03 15:44:21,482	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-03 15:44:23,877	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_1afd8123bd54806c.zip' (7.35MiB) to Ray cluster...
2024-04-03 15:44:23,902	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_1afd8123bd54806c.zip'.
INFO flwr 2024-04-03 15:44:57,686 | app.py:213 | Flower VCE: Ray initialized with resources: {'CPU': 64.0, 'object_store_memory': 78155253350.0, 'accelerator_type:TITAN': 1.0, 'memory': 172362257818.0, 'node:__internal_head__': 1.0, 'node:10.20.240.12': 1.0, 'GPU': 1.0}
INFO flwr 2024-04-03 15:44:57,686 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-04-03 15:44:57,686 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 8, 'num_gpus': 0.125}
INFO flwr 2024-04-03 15:44:57,705 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 8 actors
INFO flwr 2024-04-03 15:44:57,707 | server.py:89 | Initializing global parameters
INFO flwr 2024-04-03 15:44:57,707 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-04-03 15:44:57,707 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-04-03 15:45:01,132 | server.py:94 | initial parameters (loss, other metrics): 2.3029520511627197, {'accuracy': 0.0906, 'data_size': 10000}
INFO flwr 2024-04-03 15:45:01,132 | server.py:104 | FL starting
DEBUG flwr 2024-04-03 15:45:01,133 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=119458)[0m 2024-04-03 15:45:19.399204: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=119458)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=119458)[0m 2024-04-03 15:45:31.359916: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(pid=119459)[0m 2024-04-03 15:45:19.399204: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.[32m [repeated 7x across cluster][0m
[2m[36m(pid=119459)[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=119458)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)
[2m[36m(DefaultActor pid=119458)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)
[2m[36m(pid=119459)[0m 2024-04-03 15:45:31.359919: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT[32m [repeated 7x across cluster][0m
DEBUG flwr 2024-04-03 15:46:24,556 | server.py:236 | fit_round 1 received 10 results and 0 failures
WARNING flwr 2024-04-03 15:46:26,053 | fedavg.py:250 | No fit_metrics_aggregation_fn provided
INFO flwr 2024-04-03 15:46:27,221 | server.py:125 | fit progress: (1, 2.2248759269714355, {'accuracy': 0.4604, 'data_size': 10000}, 86.08800965499904)
INFO flwr 2024-04-03 15:46:27,221 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-04-03 15:46:27,221 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:46:34,682 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-04-03 15:46:37,238 | server.py:125 | fit progress: (2, 2.130209445953369, {'accuracy': 0.5854, 'data_size': 10000}, 96.10555288099931)
INFO flwr 2024-04-03 15:46:37,239 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-04-03 15:46:37,239 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:46:44,369 | server.py:236 | fit_round 3 received 10 results and 0 failures
INFO flwr 2024-04-03 15:46:45,919 | server.py:125 | fit progress: (3, 2.034759759902954, {'accuracy': 0.5647, 'data_size': 10000}, 104.78672176699911)
INFO flwr 2024-04-03 15:46:45,920 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-04-03 15:46:45,920 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:46:52,823 | server.py:236 | fit_round 4 received 10 results and 0 failures
INFO flwr 2024-04-03 15:46:54,330 | server.py:125 | fit progress: (4, 1.9741543531417847, {'accuracy': 0.6787, 'data_size': 10000}, 113.19700869299959)
INFO flwr 2024-04-03 15:46:54,330 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-04-03 15:46:54,330 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:47:01,438 | server.py:236 | fit_round 5 received 10 results and 0 failures
INFO flwr 2024-04-03 15:47:03,021 | server.py:125 | fit progress: (5, 1.926297664642334, {'accuracy': 0.6807, 'data_size': 10000}, 121.8882752619993)
INFO flwr 2024-04-03 15:47:03,021 | server.py:171 | evaluate_round 5: no clients selected, cancel
DEBUG flwr 2024-04-03 15:47:03,021 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:47:10,085 | server.py:236 | fit_round 6 received 10 results and 0 failures
INFO flwr 2024-04-03 15:47:11,676 | server.py:125 | fit progress: (6, 1.9018195867538452, {'accuracy': 0.6664, 'data_size': 10000}, 130.5436151469985)
INFO flwr 2024-04-03 15:47:11,677 | server.py:171 | evaluate_round 6: no clients selected, cancel
DEBUG flwr 2024-04-03 15:47:11,677 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:47:18,724 | server.py:236 | fit_round 7 received 10 results and 0 failures
INFO flwr 2024-04-03 15:47:20,396 | server.py:125 | fit progress: (7, 1.8772984743118286, {'accuracy': 0.68, 'data_size': 10000}, 139.26342837599987)
INFO flwr 2024-04-03 15:47:20,396 | server.py:171 | evaluate_round 7: no clients selected, cancel
DEBUG flwr 2024-04-03 15:47:20,397 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:47:27,633 | server.py:236 | fit_round 8 received 10 results and 0 failures
INFO flwr 2024-04-03 15:47:29,389 | server.py:125 | fit progress: (8, 1.856916069984436, {'accuracy': 0.7069, 'data_size': 10000}, 148.25653137399968)
INFO flwr 2024-04-03 15:47:29,389 | server.py:171 | evaluate_round 8: no clients selected, cancel
DEBUG flwr 2024-04-03 15:47:29,390 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:47:36,317 | server.py:236 | fit_round 9 received 10 results and 0 failures
INFO flwr 2024-04-03 15:47:38,056 | server.py:125 | fit progress: (9, 1.8312575817108154, {'accuracy': 0.7438, 'data_size': 10000}, 156.9235721979985)
INFO flwr 2024-04-03 15:47:38,057 | server.py:171 | evaluate_round 9: no clients selected, cancel
DEBUG flwr 2024-04-03 15:47:38,057 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-04-03 15:47:44,960 | server.py:236 | fit_round 10 received 10 results and 0 failures
INFO flwr 2024-04-03 15:47:46,751 | server.py:125 | fit progress: (10, 1.8177682161331177, {'accuracy': 0.7584, 'data_size': 10000}, 165.61856346999957)
INFO flwr 2024-04-03 15:47:46,751 | server.py:171 | evaluate_round 10: no clients selected, cancel
INFO flwr 2024-04-03 15:47:46,752 | server.py:153 | FL finished in 165.61900106199937
INFO flwr 2024-04-03 15:47:46,752 | app.py:226 | app_fit: losses_distributed []
INFO flwr 2024-04-03 15:47:46,752 | app.py:227 | app_fit: metrics_distributed_fit {}
INFO flwr 2024-04-03 15:47:46,752 | app.py:228 | app_fit: metrics_distributed {}
INFO flwr 2024-04-03 15:47:46,752 | app.py:229 | app_fit: losses_centralized [(0, 2.3029520511627197), (1, 2.2248759269714355), (2, 2.130209445953369), (3, 2.034759759902954), (4, 1.9741543531417847), (5, 1.926297664642334), (6, 1.9018195867538452), (7, 1.8772984743118286), (8, 1.856916069984436), (9, 1.8312575817108154), (10, 1.8177682161331177)]
INFO flwr 2024-04-03 15:47:46,752 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0906), (1, 0.4604), (2, 0.5854), (3, 0.5647), (4, 0.6787), (5, 0.6807), (6, 0.6664), (7, 0.68), (8, 0.7069), (9, 0.7438), (10, 0.7584)], 'data_size': [(0, 10000), (1, 10000), (2, 10000), (3, 10000), (4, 10000), (5, 10000), (6, 10000), (7, 10000), (8, 10000), (9, 10000), (10, 10000)]}
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.7584
wandb:     loss 1.81777
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240403_154341-zfpi38au
wandb: Find logs at: ./wandb/offline-run-20240403_154341-zfpi38au/logs
Using the latest cached version of the dataset since mnist couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'mnist' at .cache/mnist/mnist/1.0.0/b06aab39e05f7bcd9635d18ed25d06eae523c574 (last modified on Tue Apr  2 18:09:57 2024).
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-04-03 15:55:22,229 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=10, round_timeout=None)
[2m[36m(DefaultActor pid=119459)[0m /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:183: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)[32m [repeated 7x across cluster][0m
[2m[36m(DefaultActor pid=119459)[0m   return collate([torch.as_tensor(b) for b in batch], collate_fn_map=collate_fn_map)[32m [repeated 7x across cluster][0m
2024-04-03 15:55:45,407	ERROR services.py:1207 -- Failed to start the dashboard 
2024-04-03 15:55:45,409	ERROR services.py:1232 -- Error should be written to 'dashboard.log' or 'dashboard.err'. We are printing the last 20 lines for you. See 'https://docs.ray.io/en/master/ray-observability/ray-logging.html#logging-directory-structure' to find where the log file is.
2024-04-03 15:55:45,409	ERROR services.py:1276 -- 
The last 20 lines of /tmp/ray/session_2024-04-03_15-55-24_077915_2335/logs/dashboard.log (it contains the error message from the dashboard): 
2024-04-03 15:55:45,723	INFO worker.py:1621 -- Started a local Ray instance.
2024-04-03 15:56:00,008	INFO packaging.py:518 -- Creating a file package for local directory '/home/s2240084/conFEDential'.
2024-04-03 15:56:08,772	INFO packaging.py:346 -- Pushing file package 'gcs://_ray_pkg_a2e4acd62702b34c.zip' (7.36MiB) to Ray cluster...
2024-04-03 15:56:08,791	INFO packaging.py:359 -- Successfully pushed file package 'gcs://_ray_pkg_a2e4acd62702b34c.zip'.
srun: error: Unable to create step for job 278696: Job/step already completing or completed
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd-ctit082: error: *** STEP 278696.0 ON ctit082 CANCELLED AT 2024-04-04T13:21:11 ***
*** SIGTERM received at time=1712229671 on cpu 62 ***
*** SIGTERM received at time=1712229671 on cpu 20 ***
slurmstepd-ctit082: error: *** JOB 278696 ON ctit082 CANCELLED AT 2024-04-04T13:21:11 ***
PC: @     0x7fe60d8e135c  (unknown)  recv
    @     0x7fe60d804090  (unknown)  (unknown)
[2024-04-04 13:21:11,839 E 37023 37023] logging.cc:361: *** SIGTERM received at time=1712229671 on cpu 62 ***
[2024-04-04 13:21:11,839 E 37023 37023] logging.cc:361: PC: @     0x7fe60d8e135c  (unknown)  recv
[2024-04-04 13:21:11,839 E 37023 37023] logging.cc:361:     @     0x7fe60d804090  (unknown)  (unknown)
PC: @     0x7f6bfd47b35c  (unknown)  recv
    @     0x7f6bfd39e090  (unknown)  (unknown)
[2024-04-04 13:21:11,842 E 2335 2335] logging.cc:361: *** SIGTERM received at time=1712229671 on cpu 20 ***
[2024-04-04 13:21:11,843 E 2335 2335] logging.cc:361: PC: @     0x7f6bfd47b35c  (unknown)  recv
[2024-04-04 13:21:11,843 E 2335 2335] logging.cc:361:     @     0x7f6bfd39e090  (unknown)  (unknown)
