ctit088
2024-05-22 08:50:49,826	INFO usage_lib.py:412 -- Usage stats collection is enabled. To disable this, add `--disable-usage-stats` to the command that starts the cluster, or run the following command: `ray disable-usage-stats` before starting the cluster. See https://docs.ray.io/en/master/cluster/usage-stats.html for more details.
2024-05-22 08:50:49,826	INFO scripts.py:722 -- Local node IP: 10.20.240.18
2024-05-22 08:51:06,723	SUCC scripts.py:759 -- --------------------
2024-05-22 08:51:06,723	SUCC scripts.py:760 -- Ray runtime started.
2024-05-22 08:51:06,724	SUCC scripts.py:761 -- --------------------
2024-05-22 08:51:06,724	INFO scripts.py:763 -- Next steps
2024-05-22 08:51:06,724	INFO scripts.py:766 -- To add another node to this Ray cluster, run
2024-05-22 08:51:06,724	INFO scripts.py:769 --   ray start --address='10.20.240.18:6379'
2024-05-22 08:51:06,724	INFO scripts.py:778 -- To connect to this Ray cluster:
2024-05-22 08:51:06,724	INFO scripts.py:780 -- import ray
2024-05-22 08:51:06,724	INFO scripts.py:781 -- ray.init()
2024-05-22 08:51:06,724	INFO scripts.py:812 -- To terminate the Ray runtime, run
2024-05-22 08:51:06,724	INFO scripts.py:813 --   ray stop
2024-05-22 08:51:06,725	INFO scripts.py:816 -- To view the status of the cluster, use
2024-05-22 08:51:06,726	INFO scripts.py:817 --   ray status
2024-05-22 08:52:15.347442: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-05-22 08:52:23.288509: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-22 08:52:56.853491: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
INFO flwr 2024-05-22 08:54:45,028 | Data.py:31 | Preprocessing the federated learning dataset
INFO flwr 2024-05-22 08:54:45,100 | Data.py:107 | Found preprocessed data for the given preprocess function, returning
INFO flwr 2024-05-22 08:54:54,373 | Simulation.py:37 | Preparing datasets for federated learning simulation
INFO flwr 2024-05-22 08:54:54,405 | Simulation.py:255 | Found previously split dataloaders, loading them
INFO flwr 2024-05-22 08:55:19,108 | main.py:103 | Loaded 1 configs with name PURCHASE-LOG_RES-FEDADAM, running...
INFO flwr 2024-05-22 08:55:19,109 | main.py:105 | Config:
	Simulation:
		Data:
			dataset_name: purchase
			batch_size: 1
			preprocess_fn:
				def preprocess_fn(element):
				  return {
				    "x": element["features"],
				    "y": element["label"]
				  }
		Federation:
			client_count: 100
			fraction_fit: 0.1
			global_rounds: 1
			local_rounds: 8
		Model:
			optimizer_name: FedAdam
			model_name: Logistic Regression
			criterion_name: CrossEntropyLoss
			optimizer_parameters: 
				local: {'lr': 0.1}
				global: {'lr': 0.1, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0.9999}
			model_architecture:
				type: Linear
					in_features: 600
					out_features: 100
				type: Softmax
					dim: -1
	Attack:
		data_access: all
		message_access: server
		repetitions: 10
		Attack Simulation:
			batch_size: 64
			optimizer_name: FedAvg
			optimizer_parameters:
				lr: 0.1
			ModelArchitecture:
				gradient_component:
					type: Dropout
						p: 0.2
					type: Conv3d
						out_channels: 1000
						kernel_size: [1, 1]
						stride: 1
					type: ReLU
				fcn_component:
					type: Dropout
						p: 0.2
					type: Linear
						out_features: 128
					type: ReLU
					type: Dropout
						p: 0.2
					type: Linear
						in_features: 128
						out_features: 64
					type: ReLU
				encoder_component:
					type: Dropout
						p: 0.2
					type: Linear
						out_features: 256
					type: ReLU
					type: Dropout
						p: 0.2
					type: Linear
						in_features: 256
						out_features: 128
					type: ReLU
					type: Dropout
						p: 0.2
					type: Linear
						in_features: 128
						out_features: 64
					type: ReLU
					type: Dropout
						p: 0.2
					type: Linear
						in_features: 64
						out_features: 1
					type: ReLU
					type: Sigmoid
INFO flwr 2024-05-22 08:55:19,123 | Config.py:68 | Starting conFEDential simulation
INFO flwr 2024-05-22 08:55:19,126 | Config.py:72 | No previous federated learning simulation found, starting training simulation...
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-05-22 08:55:30,736 | Simulation.py:395 | Created 1 clients with resources 16 CPUs, 1.0 GPUs, and 16.0GB for the total available 16 CPUs, 1 GPUs and 16.0GB.
INFO flwr 2024-05-22 08:55:30,736 | Simulation.py:160 | Starting federated learning simulation
2024-05-22 08:55:30,771	INFO worker.py:1431 -- Connecting to existing Ray cluster at address: 10.20.240.18:6379...
2024-05-22 08:55:30,792	INFO worker.py:1621 -- Connected to Ray cluster.
INFO flwr 2024-05-22 08:56:04,572 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=1, round_timeout=None)
2024-05-22 08:56:04,663	INFO worker.py:1453 -- Calling ray.init() again after it has already been called.
INFO flwr 2024-05-22 08:56:04,664 | app.py:213 | Flower VCE: Ray initialized with resources: {'CPU': 16.0, 'memory': 17179869184.0, 'accelerator_type:G': 1.0, 'GPU': 1.0, 'node:10.20.240.18': 1.0, 'object_store_memory': 60184261017.0, 'node:__internal_head__': 1.0}
INFO flwr 2024-05-22 08:56:04,664 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-05-22 08:56:04,665 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 16, 'num_gpus': 1.0, 'memory': 17179869184}
INFO flwr 2024-05-22 08:56:04,682 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 1 actors
INFO flwr 2024-05-22 08:56:04,683 | server.py:89 | Initializing global parameters
INFO flwr 2024-05-22 08:56:04,683 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-05-22 08:56:04,683 | server.py:91 | Evaluating initial parameters
[2m[36m(pid=521534)[0m 2024-05-22 08:56:09.187823: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
[2m[36m(pid=521534)[0m 2024-05-22 08:56:09.254550: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=521534)[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
INFO flwr 2024-05-22 08:56:09,323 | server.py:94 | initial parameters (loss, other metrics): 0.00015558291578652097, {'accuracy': 0.009155714720091895, 'data_size': 29599}
INFO flwr 2024-05-22 08:56:09,323 | server.py:104 | FL starting
DEBUG flwr 2024-05-22 08:56:09,323 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=521534)[0m 2024-05-22 08:56:10.888049: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
DEBUG flwr 2024-05-22 09:03:20,206 | server.py:236 | fit_round 1 received 10 results and 0 failures
ERROR flwr 2024-05-22 09:03:21,058 | app.py:313 | Unable to synchronously change a dataset's dimensions (dimension cannot exceed the existing maximal size (new: 2 max: 1))
ERROR flwr 2024-05-22 09:03:21,227 | app.py:314 | Traceback (most recent call last):
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/app.py", line 308, in start_simulation
    hist = run_fl(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/server/app.py", line 225, in run_fl
    hist = server.fit(num_rounds=config.num_rounds, timeout=config.round_timeout)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/server/server.py", line 109, in fit
    res_fit = self.fit_round(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/server/server.py", line 248, in fit_round
    ] = self.strategy.aggregate_fit(server_round, results, failures)
  File "/home/s2240084/conFEDential/src/training/Server.py", line 80, in aggregate_fit
    self._capture_results(server_round, results, aggregated_parameters, config)
  File "/home/s2240084/conFEDential/src/training/Server.py", line 101, in _capture_results
    self._capture_messages(server_round, results)
  File "/home/s2240084/conFEDential/src/training/Server.py", line 110, in _capture_messages
    self._capture_message_round(server_round, parameter_messages, f"{base_path}messages.hdf5")
  File "/home/s2240084/conFEDential/src/training/Server.py", line 176, in _capture_message_round
    client_layer_group["server_rounds"].resize((server_round + 1,))
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/h5py/_hl/dataset.py", line 679, in resize
    self.id.set_extent(size)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5d.pyx", line 335, in h5py.h5d.DatasetID.set_extent
RuntimeError: Unable to synchronously change a dataset's dimensions (dimension cannot exceed the existing maximal size (new: 2 max: 1))

ERROR flwr 2024-05-22 09:03:21,227 | app.py:315 | Your simulation crashed :(. This could be because of several reasons. The most common are: 
	 > Sometimes, issues in the simulation code itself can cause crashes. It's always a good idea to double-check your code for any potential bugs or inconsistencies that might be contributing to the problem. For example: 
		 - You might be using a class attribute in your clients that hasn't been defined.
		 - There could be an incorrect method call to a 3rd party library (e.g., PyTorch).
		 - The return types of methods in your clients/strategies might be incorrect.
	 > Your system couldn't fit a single VirtualClient: try lowering `client_resources`.
	 > All the actors in your pool crashed. This could be because: 
		 - You clients hit an out-of-memory (OOM) error and actors couldn't recover from it. Try launching your simulation with more generous `client_resources` setting (i.e. it seems {'num_cpus': 16, 'num_gpus': 1.0, 'memory': 17179869184} is not enough for your run). Use fewer concurrent actors. 
		 - You were running a multi-node simulation and all worker nodes disconnected. The head node might still be alive but cannot accommodate any actor with resources: {'num_cpus': 16, 'num_gpus': 1.0, 'memory': 17179869184}.
Take a look at the Flower simulation examples for guidance <https://flower.dev/docs/framework/how-to-run-simulations.html>.
ERROR flwr 2024-05-22 09:03:21,228 | Simulation.py:183 | Simulation crashed.
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.00916
wandb:     loss 0.00016
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240522_085525-n0oxsflp
wandb: Find logs at: ./wandb/offline-run-20240522_085525-n0oxsflp/logs
2024-05-22 09:04:32.031354: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-05-22 09:04:32.095493: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-22 09:04:33.473354: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
INFO flwr 2024-05-22 09:04:39,924 | Data.py:31 | Preprocessing the federated learning dataset
INFO flwr 2024-05-22 09:04:39,924 | Data.py:107 | Found preprocessed data for the given preprocess function, returning
INFO flwr 2024-05-22 09:04:39,955 | Simulation.py:37 | Preparing datasets for federated learning simulation
INFO flwr 2024-05-22 09:04:39,955 | Simulation.py:255 | Found previously split dataloaders, loading them
INFO flwr 2024-05-22 09:04:55,037 | main.py:103 | Loaded 1 configs with name PURCHASE-LOG_RES-FEDAVG, running...
INFO flwr 2024-05-22 09:04:55,039 | main.py:105 | Config:
	Simulation:
		Data:
			dataset_name: purchase
			batch_size: 1
			preprocess_fn:
				def preprocess_fn(element):
				  return {
				    "x": element["features"],
				    "y": element["label"]
				  }
		Federation:
			client_count: 100
			fraction_fit: 0.1
			global_rounds: 1
			local_rounds: 20
		Model:
			optimizer_name: FedAvg
			model_name: Logistic Regression
			criterion_name: CrossEntropyLoss
			optimizer_parameters: 
				lr: 0.1
			model_architecture:
				type: Linear
					in_features: 600
					out_features: 100
				type: Softmax
					dim: -1
	Attack:
		data_access: all
		message_access: server
		repetitions: 10
		Attack Simulation:
			batch_size: 64
			optimizer_name: FedAvg
			optimizer_parameters:
				lr: 0.1
			ModelArchitecture:
				gradient_component:
					type: Dropout
						p: 0.2
					type: Conv3d
						out_channels: 1000
						kernel_size: [1, 1]
						stride: 1
					type: ReLU
				fcn_component:
					type: Dropout
						p: 0.2
					type: Linear
						out_features: 128
					type: ReLU
					type: Dropout
						p: 0.2
					type: Linear
						in_features: 128
						out_features: 64
					type: ReLU
				encoder_component:
					type: Dropout
						p: 0.2
					type: Linear
						out_features: 256
					type: ReLU
					type: Dropout
						p: 0.2
					type: Linear
						in_features: 256
						out_features: 128
					type: ReLU
					type: Dropout
						p: 0.2
					type: Linear
						in_features: 128
						out_features: 64
					type: ReLU
					type: Dropout
						p: 0.2
					type: Linear
						in_features: 64
						out_features: 1
					type: ReLU
					type: Sigmoid
INFO flwr 2024-05-22 09:04:55,106 | Config.py:68 | Starting conFEDential simulation
INFO flwr 2024-05-22 09:04:55,111 | Config.py:72 | No previous federated learning simulation found, starting training simulation...
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-05-22 09:04:58,762 | Simulation.py:395 | Created 1 clients with resources 16 CPUs, 1.0 GPUs, and 16.0GB for the total available 16 CPUs, 1 GPUs and 16.0GB.
INFO flwr 2024-05-22 09:04:58,762 | Simulation.py:160 | Starting federated learning simulation
2024-05-22 09:04:58,792	INFO worker.py:1431 -- Connecting to existing Ray cluster at address: 10.20.240.18:6379...
2024-05-22 09:04:58,804	INFO worker.py:1621 -- Connected to Ray cluster.
INFO flwr 2024-05-22 09:04:58,819 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=1, round_timeout=None)
2024-05-22 09:04:58,866	INFO worker.py:1453 -- Calling ray.init() again after it has already been called.
INFO flwr 2024-05-22 09:04:58,867 | app.py:213 | Flower VCE: Ray initialized with resources: {'memory': 17179869184.0, 'CPU': 16.0, 'GPU': 1.0, 'accelerator_type:G': 1.0, 'object_store_memory': 60184261017.0, 'node:10.20.240.18': 1.0, 'node:__internal_head__': 1.0}
INFO flwr 2024-05-22 09:04:58,867 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-05-22 09:04:58,867 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 16, 'num_gpus': 1.0, 'memory': 17179869184}
INFO flwr 2024-05-22 09:04:58,876 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 1 actors
INFO flwr 2024-05-22 09:04:58,878 | server.py:89 | Initializing global parameters
INFO flwr 2024-05-22 09:04:58,878 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-05-22 09:04:58,879 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-05-22 09:04:59,413 | server.py:94 | initial parameters (loss, other metrics): 0.00015558291578652097, {'accuracy': 0.009155714720091895, 'data_size': 29599}
INFO flwr 2024-05-22 09:04:59,414 | server.py:104 | FL starting
DEBUG flwr 2024-05-22 09:04:59,414 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=522724)[0m 2024-05-22 09:05:03.734275: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
[2m[36m(pid=522724)[0m 2024-05-22 09:05:03.854397: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=522724)[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=522724)[0m 2024-05-22 09:05:05.934691: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
DEBUG flwr 2024-05-22 09:14:50,890 | server.py:236 | fit_round 1 received 10 results and 0 failures
ERROR flwr 2024-05-22 09:14:52,338 | app.py:313 | Unable to synchronously change a dataset's dimensions (dimension cannot exceed the existing maximal size (new: 2 max: 1))
ERROR flwr 2024-05-22 09:14:52,341 | app.py:314 | Traceback (most recent call last):
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/app.py", line 308, in start_simulation
    hist = run_fl(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/server/app.py", line 225, in run_fl
    hist = server.fit(num_rounds=config.num_rounds, timeout=config.round_timeout)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/server/server.py", line 109, in fit
    res_fit = self.fit_round(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/server/server.py", line 248, in fit_round
    ] = self.strategy.aggregate_fit(server_round, results, failures)
  File "/home/s2240084/conFEDential/src/training/Server.py", line 80, in aggregate_fit
    self._capture_results(server_round, results, aggregated_parameters, config)
  File "/home/s2240084/conFEDential/src/training/Server.py", line 101, in _capture_results
    self._capture_messages(server_round, results)
  File "/home/s2240084/conFEDential/src/training/Server.py", line 110, in _capture_messages
    self._capture_message_round(server_round, parameter_messages, f"{base_path}messages.hdf5")
  File "/home/s2240084/conFEDential/src/training/Server.py", line 176, in _capture_message_round
    client_layer_group["server_rounds"].resize((server_round + 1,))
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/h5py/_hl/dataset.py", line 679, in resize
    self.id.set_extent(size)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5d.pyx", line 335, in h5py.h5d.DatasetID.set_extent
RuntimeError: Unable to synchronously change a dataset's dimensions (dimension cannot exceed the existing maximal size (new: 2 max: 1))

ERROR flwr 2024-05-22 09:14:52,341 | app.py:315 | Your simulation crashed :(. This could be because of several reasons. The most common are: 
	 > Sometimes, issues in the simulation code itself can cause crashes. It's always a good idea to double-check your code for any potential bugs or inconsistencies that might be contributing to the problem. For example: 
		 - You might be using a class attribute in your clients that hasn't been defined.
		 - There could be an incorrect method call to a 3rd party library (e.g., PyTorch).
		 - The return types of methods in your clients/strategies might be incorrect.
	 > Your system couldn't fit a single VirtualClient: try lowering `client_resources`.
	 > All the actors in your pool crashed. This could be because: 
		 - You clients hit an out-of-memory (OOM) error and actors couldn't recover from it. Try launching your simulation with more generous `client_resources` setting (i.e. it seems {'num_cpus': 16, 'num_gpus': 1.0, 'memory': 17179869184} is not enough for your run). Use fewer concurrent actors. 
		 - You were running a multi-node simulation and all worker nodes disconnected. The head node might still be alive but cannot accommodate any actor with resources: {'num_cpus': 16, 'num_gpus': 1.0, 'memory': 17179869184}.
Take a look at the Flower simulation examples for guidance <https://flower.dev/docs/framework/how-to-run-simulations.html>.
ERROR flwr 2024-05-22 09:14:52,342 | Simulation.py:183 | Simulation crashed.
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.00916
wandb:     loss 0.00016
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240522_090458-8uf5t24g
wandb: Find logs at: ./wandb/offline-run-20240522_090458-8uf5t24g/logs
2024-05-22 09:16:01.008965: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-05-22 09:16:01.074754: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-22 09:16:02.401758: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
INFO flwr 2024-05-22 09:16:08,921 | Data.py:31 | Preprocessing the federated learning dataset
INFO flwr 2024-05-22 09:16:08,921 | Data.py:107 | Found preprocessed data for the given preprocess function, returning
INFO flwr 2024-05-22 09:16:08,950 | Simulation.py:37 | Preparing datasets for federated learning simulation
INFO flwr 2024-05-22 09:16:08,951 | Simulation.py:255 | Found previously split dataloaders, loading them
INFO flwr 2024-05-22 09:16:29,604 | main.py:103 | Loaded 1 configs with name PURCHASE-LOG_RES-FEDNAG, running...
INFO flwr 2024-05-22 09:16:29,605 | main.py:105 | Config:
	Simulation:
		Data:
			dataset_name: purchase
			batch_size: 2
			preprocess_fn:
				def preprocess_fn(element):
				  return {
				    "x": element["features"],
				    "y": element["label"]
				  }
		Federation:
			client_count: 100
			fraction_fit: 0.1
			global_rounds: 1
			local_rounds: 20
		Model:
			optimizer_name: FedNAG
			model_name: Logistic Regression
			criterion_name: CrossEntropyLoss
			optimizer_parameters: 
				lr: 0.1
				momentum: 0.85
			model_architecture:
				type: Linear
					in_features: 600
					out_features: 100
				type: Softmax
					dim: -1
	Attack:
		data_access: all
		message_access: server
		repetitions: 10
		Attack Simulation:
			batch_size: 64
			optimizer_name: FedAvg
			optimizer_parameters:
				lr: 0.1
			ModelArchitecture:
				gradient_component:
					type: Dropout
						p: 0.2
					type: Conv3d
						out_channels: 1000
						kernel_size: [1, 1]
						stride: 1
					type: ReLU
				fcn_component:
					type: Dropout
						p: 0.2
					type: Linear
						out_features: 128
					type: ReLU
					type: Dropout
						p: 0.2
					type: Linear
						in_features: 128
						out_features: 64
					type: ReLU
				encoder_component:
					type: Dropout
						p: 0.2
					type: Linear
						out_features: 256
					type: ReLU
					type: Dropout
						p: 0.2
					type: Linear
						in_features: 256
						out_features: 128
					type: ReLU
					type: Dropout
						p: 0.2
					type: Linear
						in_features: 128
						out_features: 64
					type: ReLU
					type: Dropout
						p: 0.2
					type: Linear
						in_features: 64
						out_features: 1
					type: ReLU
					type: Sigmoid
INFO flwr 2024-05-22 09:16:29,619 | Config.py:68 | Starting conFEDential simulation
INFO flwr 2024-05-22 09:16:29,622 | Config.py:72 | No previous federated learning simulation found, starting training simulation...
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-05-22 09:16:33,256 | Simulation.py:395 | Created 1 clients with resources 16 CPUs, 1.0 GPUs, and 16.0GB for the total available 16 CPUs, 1 GPUs and 16.0GB.
INFO flwr 2024-05-22 09:16:33,256 | Simulation.py:160 | Starting federated learning simulation
2024-05-22 09:16:33,287	INFO worker.py:1431 -- Connecting to existing Ray cluster at address: 10.20.240.18:6379...
2024-05-22 09:16:33,299	INFO worker.py:1621 -- Connected to Ray cluster.
INFO flwr 2024-05-22 09:16:33,321 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=1, round_timeout=None)
2024-05-22 09:16:33,360	INFO worker.py:1453 -- Calling ray.init() again after it has already been called.
INFO flwr 2024-05-22 09:16:33,361 | app.py:213 | Flower VCE: Ray initialized with resources: {'object_store_memory': 60184261017.0, 'node:10.20.240.18': 1.0, 'accelerator_type:G': 1.0, 'GPU': 1.0, 'CPU': 16.0, 'memory': 17179869184.0, 'node:__internal_head__': 1.0}
INFO flwr 2024-05-22 09:16:33,361 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-05-22 09:16:33,361 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 16, 'num_gpus': 1.0, 'memory': 17179869184}
INFO flwr 2024-05-22 09:16:33,370 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 1 actors
INFO flwr 2024-05-22 09:16:33,370 | server.py:89 | Initializing global parameters
INFO flwr 2024-05-22 09:16:33,371 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-05-22 09:16:33,371 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-05-22 09:16:33,916 | server.py:94 | initial parameters (loss, other metrics): 0.00015558291578652097, {'accuracy': 0.009155714720091895, 'data_size': 29599}
INFO flwr 2024-05-22 09:16:33,916 | server.py:104 | FL starting
DEBUG flwr 2024-05-22 09:16:33,916 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=525080)[0m 2024-05-22 09:16:38.174362: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
[2m[36m(pid=525080)[0m 2024-05-22 09:16:38.296670: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=525080)[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=525080)[0m 2024-05-22 09:16:39.646455: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
DEBUG flwr 2024-05-22 09:24:25,253 | server.py:236 | fit_round 1 received 10 results and 0 failures
ERROR flwr 2024-05-22 09:24:27,452 | app.py:313 | Unable to synchronously change a dataset's dimensions (dimension cannot exceed the existing maximal size (new: 2 max: 1))
ERROR flwr 2024-05-22 09:24:27,455 | app.py:314 | Traceback (most recent call last):
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/app.py", line 308, in start_simulation
    hist = run_fl(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/server/app.py", line 225, in run_fl
    hist = server.fit(num_rounds=config.num_rounds, timeout=config.round_timeout)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/server/server.py", line 109, in fit
    res_fit = self.fit_round(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/server/server.py", line 248, in fit_round
    ] = self.strategy.aggregate_fit(server_round, results, failures)
  File "/home/s2240084/conFEDential/src/training/Server.py", line 80, in aggregate_fit
    self._capture_results(server_round, results, aggregated_parameters, config)
  File "/home/s2240084/conFEDential/src/training/Server.py", line 101, in _capture_results
    self._capture_messages(server_round, results)
  File "/home/s2240084/conFEDential/src/training/Server.py", line 110, in _capture_messages
    self._capture_message_round(server_round, parameter_messages, f"{base_path}messages.hdf5")
  File "/home/s2240084/conFEDential/src/training/Server.py", line 176, in _capture_message_round
    client_layer_group["server_rounds"].resize((server_round + 1,))
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/h5py/_hl/dataset.py", line 679, in resize
    self.id.set_extent(size)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5d.pyx", line 335, in h5py.h5d.DatasetID.set_extent
RuntimeError: Unable to synchronously change a dataset's dimensions (dimension cannot exceed the existing maximal size (new: 2 max: 1))

ERROR flwr 2024-05-22 09:24:27,455 | app.py:315 | Your simulation crashed :(. This could be because of several reasons. The most common are: 
	 > Sometimes, issues in the simulation code itself can cause crashes. It's always a good idea to double-check your code for any potential bugs or inconsistencies that might be contributing to the problem. For example: 
		 - You might be using a class attribute in your clients that hasn't been defined.
		 - There could be an incorrect method call to a 3rd party library (e.g., PyTorch).
		 - The return types of methods in your clients/strategies might be incorrect.
	 > Your system couldn't fit a single VirtualClient: try lowering `client_resources`.
	 > All the actors in your pool crashed. This could be because: 
		 - You clients hit an out-of-memory (OOM) error and actors couldn't recover from it. Try launching your simulation with more generous `client_resources` setting (i.e. it seems {'num_cpus': 16, 'num_gpus': 1.0, 'memory': 17179869184} is not enough for your run). Use fewer concurrent actors. 
		 - You were running a multi-node simulation and all worker nodes disconnected. The head node might still be alive but cannot accommodate any actor with resources: {'num_cpus': 16, 'num_gpus': 1.0, 'memory': 17179869184}.
Take a look at the Flower simulation examples for guidance <https://flower.dev/docs/framework/how-to-run-simulations.html>.
ERROR flwr 2024-05-22 09:24:27,455 | Simulation.py:183 | Simulation crashed.
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.00916
wandb:     loss 0.00016
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240522_091632-rxg9szkn
wandb: Find logs at: ./wandb/offline-run-20240522_091632-rxg9szkn/logs
2024-05-22 09:25:37,238	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --raylet_socket_name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/raylet --store_socket_name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/plasma_store --object_manager_port=0 --min_worker_port=10002 --max_worker_port=19999 --node_manager_port=0 --node_ip_address=10.20.240.18 --maximum_startup_concurrency=16 --static_resource_list=node:10.20.240.18,1.0,node:__internal_head__,1.0,accelerator_type:G,1,CPU,16,GPU,1,memory,17179869184,object_store_memory,60184261017 "--python_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/default_worker.py --node-ip-address=10.20.240.18 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/plasma_store --raylet-name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/raylet --redis-address=None --temp-dir=/local/ray --metrics-agent-port=61802 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=10.20.240.18:6379 --session-name=session_2024-05-22_08-50-49_908020_519686 --temp-dir=/local/ray --webui= RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER" "--java_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py -Dray.address=10.20.240.18:6379 -Dray.raylet.node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER -Dray.object-store.socket-name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/plasma_store -Dray.raylet.socket-name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/raylet -Dray.redis.password= -Dray.node-ip=10.20.240.18 -Dray.home=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/../.. -Dray.logging.dir=/local/ray/session_2024-05-22_08-50-49_908020_519686/logs -Dray.session-dir=/local/ray/session_2024-05-22_08-50-49_908020_519686 RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER io.ray.runtime.runner.worker.DefaultWorker" --cpp_worker_command= --native_library_path=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/cpp/lib --temp_dir=/local/ray --session_dir=/local/ray/session_2024-05-22_08-50-49_908020_519686 --log_dir=/local/ray/session_2024-05-22_08-50-49_908020_519686/logs --resource_dir=/local/ray/session_2024-05-22_08-50-49_908020_519686/runtime_resources --metrics-agent-port=61802 --metrics_export_port=56347 --object_store_memory=60184261017 --plasma_directory=/dev/shm --ray-debugger-external=0 --gcs-address=10.20.240.18:6379 --session-name=session_2024-05-22_08-50-49_908020_519686 --labels= --head --num_prestart_python_workers=16 "--agent_command=/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/dashboard/agent.py --node-ip-address=10.20.240.18 --metrics-export-port=56347 --dashboard-agent-port=61802 --listen-port=52365 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/plasma_store --raylet-name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/raylet --temp-dir=/local/ray --session-dir=/local/ray/session_2024-05-22_08-50-49_908020_519686 --runtime-env-dir=/local/ray/session_2024-05-22_08-50-49_908020_519686/runtime_resources --log-dir=/local/ray/session_2024-05-22_08-50-49_908020_519686/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --session-name=session_2024-05-22_08-50-49_908020_519686 --gcs-address=10.20.240.18:6379 --minimal"` (via SIGTERM)
2024-05-22 09:25:37,240	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/autoscaler/_private/monitor.py --logs-dir=/local/ray/session_2024-05-22_08-50-49_908020_519686/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=10.20.240.18:6379 --monitor-ip=10.20.240.18` (via SIGTERM)
2024-05-22 09:25:37,240	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/log_monitor.py --logs-dir=/local/ray/session_2024-05-22_08-50-49_908020_519686/logs --gcs-address=10.20.240.18:6379 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5` (via SIGTERM)
2024-05-22 09:25:37,242	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/bin/python -m ray.util.client.server --address=10.20.240.18:6379 --host=0.0.0.0 --port=10001 --mode=proxy --metrics-agent-port=61802` (via SIGTERM)
2024-05-22 09:25:37,244	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --raylet_socket_name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/raylet --store_socket_name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/plasma_store --object_manager_port=0 --min_worker_port=10002 --max_worker_port=19999 --node_manager_port=0 --node_ip_address=10.20.240.18 --maximum_startup_concurrency=16 --static_resource_list=node:10.20.240.18,1.0,node:__internal_head__,1.0,accelerator_type:G,1,CPU,16,GPU,1,memory,17179869184,object_store_memory,60184261017 "--python_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/default_worker.py --node-ip-address=10.20.240.18 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/plasma_store --raylet-name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/raylet --redis-address=None --temp-dir=/local/ray --metrics-agent-port=61802 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=10.20.240.18:6379 --session-name=session_2024-05-22_08-50-49_908020_519686 --temp-dir=/local/ray --webui= RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER" "--java_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py -Dray.address=10.20.240.18:6379 -Dray.raylet.node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER -Dray.object-store.socket-name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/plasma_store -Dray.raylet.socket-name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/raylet -Dray.redis.password= -Dray.node-ip=10.20.240.18 -Dray.home=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/../.. -Dray.logging.dir=/local/ray/session_2024-05-22_08-50-49_908020_519686/logs -Dray.session-dir=/local/ray/session_2024-05-22_08-50-49_908020_519686 RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER io.ray.runtime.runner.worker.DefaultWorker" --cpp_worker_command= --native_library_path=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/cpp/lib --temp_dir=/local/ray --session_dir=/local/ray/session_2024-05-22_08-50-49_908020_519686 --log_dir=/local/ray/session_2024-05-22_08-50-49_908020_519686/logs --resource_dir=/local/ray/session_2024-05-22_08-50-49_908020_519686/runtime_resources --metrics-agent-port=61802 --metrics_export_port=56347 --object_store_memory=60184261017 --plasma_directory=/dev/shm --ray-debugger-external=0 --gcs-address=10.20.240.18:6379 --session-name=session_2024-05-22_08-50-49_908020_519686 --labels= --head --num_prestart_python_workers=16 "--agent_command=/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/dashboard/agent.py --node-ip-address=10.20.240.18 --metrics-export-port=56347 --dashboard-agent-port=61802 --listen-port=52365 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/plasma_store --raylet-name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/raylet --temp-dir=/local/ray --session-dir=/local/ray/session_2024-05-22_08-50-49_908020_519686 --runtime-env-dir=/local/ray/session_2024-05-22_08-50-49_908020_519686/runtime_resources --log-dir=/local/ray/session_2024-05-22_08-50-49_908020_519686/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --session-name=session_2024-05-22_08-50-49_908020_519686 --gcs-address=10.20.240.18:6379 --minimal"` (via SIGTERM)
2024-05-22 09:25:37,246	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --raylet_socket_name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/raylet --store_socket_name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/plasma_store --object_manager_port=0 --min_worker_port=10002 --max_worker_port=19999 --node_manager_port=0 --node_ip_address=10.20.240.18 --maximum_startup_concurrency=16 --static_resource_list=node:10.20.240.18,1.0,node:__internal_head__,1.0,accelerator_type:G,1,CPU,16,GPU,1,memory,17179869184,object_store_memory,60184261017 "--python_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/default_worker.py --node-ip-address=10.20.240.18 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/plasma_store --raylet-name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/raylet --redis-address=None --temp-dir=/local/ray --metrics-agent-port=61802 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=10.20.240.18:6379 --session-name=session_2024-05-22_08-50-49_908020_519686 --temp-dir=/local/ray --webui= RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER" "--java_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py -Dray.address=10.20.240.18:6379 -Dray.raylet.node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER -Dray.object-store.socket-name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/plasma_store -Dray.raylet.socket-name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/raylet -Dray.redis.password= -Dray.node-ip=10.20.240.18 -Dray.home=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/../.. -Dray.logging.dir=/local/ray/session_2024-05-22_08-50-49_908020_519686/logs -Dray.session-dir=/local/ray/session_2024-05-22_08-50-49_908020_519686 RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER io.ray.runtime.runner.worker.DefaultWorker" --cpp_worker_command= --native_library_path=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/cpp/lib --temp_dir=/local/ray --session_dir=/local/ray/session_2024-05-22_08-50-49_908020_519686 --log_dir=/local/ray/session_2024-05-22_08-50-49_908020_519686/logs --resource_dir=/local/ray/session_2024-05-22_08-50-49_908020_519686/runtime_resources --metrics-agent-port=61802 --metrics_export_port=56347 --object_store_memory=60184261017 --plasma_directory=/dev/shm --ray-debugger-external=0 --gcs-address=10.20.240.18:6379 --session-name=session_2024-05-22_08-50-49_908020_519686 --labels= --head --num_prestart_python_workers=16 "--agent_command=/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/dashboard/agent.py --node-ip-address=10.20.240.18 --metrics-export-port=56347 --dashboard-agent-port=61802 --listen-port=52365 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/plasma_store --raylet-name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/raylet --temp-dir=/local/ray --session-dir=/local/ray/session_2024-05-22_08-50-49_908020_519686 --runtime-env-dir=/local/ray/session_2024-05-22_08-50-49_908020_519686/runtime_resources --log-dir=/local/ray/session_2024-05-22_08-50-49_908020_519686/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --session-name=session_2024-05-22_08-50-49_908020_519686 --gcs-address=10.20.240.18:6379 --minimal"` (via SIGTERM)
2024-05-22 09:25:37,249	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --raylet_socket_name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/raylet --store_socket_name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/plasma_store --object_manager_port=0 --min_worker_port=10002 --max_worker_port=19999 --node_manager_port=0 --node_ip_address=10.20.240.18 --maximum_startup_concurrency=16 --static_resource_list=node:10.20.240.18,1.0,node:__internal_head__,1.0,accelerator_type:G,1,CPU,16,GPU,1,memory,17179869184,object_store_memory,60184261017 "--python_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/default_worker.py --node-ip-address=10.20.240.18 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/plasma_store --raylet-name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/raylet --redis-address=None --temp-dir=/local/ray --metrics-agent-port=61802 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=10.20.240.18:6379 --session-name=session_2024-05-22_08-50-49_908020_519686 --temp-dir=/local/ray --webui= RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER" "--java_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py -Dray.address=10.20.240.18:6379 -Dray.raylet.node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER -Dray.object-store.socket-name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/plasma_store -Dray.raylet.socket-name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/raylet -Dray.redis.password= -Dray.node-ip=10.20.240.18 -Dray.home=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/../.. -Dray.logging.dir=/local/ray/session_2024-05-22_08-50-49_908020_519686/logs -Dray.session-dir=/local/ray/session_2024-05-22_08-50-49_908020_519686 RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER io.ray.runtime.runner.worker.DefaultWorker" --cpp_worker_command= --native_library_path=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/cpp/lib --temp_dir=/local/ray --session_dir=/local/ray/session_2024-05-22_08-50-49_908020_519686 --log_dir=/local/ray/session_2024-05-22_08-50-49_908020_519686/logs --resource_dir=/local/ray/session_2024-05-22_08-50-49_908020_519686/runtime_resources --metrics-agent-port=61802 --metrics_export_port=56347 --object_store_memory=60184261017 --plasma_directory=/dev/shm --ray-debugger-external=0 --gcs-address=10.20.240.18:6379 --session-name=session_2024-05-22_08-50-49_908020_519686 --labels= --head --num_prestart_python_workers=16 "--agent_command=/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/dashboard/agent.py --node-ip-address=10.20.240.18 --metrics-export-port=56347 --dashboard-agent-port=61802 --listen-port=52365 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/plasma_store --raylet-name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/raylet --temp-dir=/local/ray --session-dir=/local/ray/session_2024-05-22_08-50-49_908020_519686 --runtime-env-dir=/local/ray/session_2024-05-22_08-50-49_908020_519686/runtime_resources --log-dir=/local/ray/session_2024-05-22_08-50-49_908020_519686/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --session-name=session_2024-05-22_08-50-49_908020_519686 --gcs-address=10.20.240.18:6379 --minimal"` (via SIGTERM)
2024-05-22 09:25:37,250	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/log_monitor.py --logs-dir=/local/ray/session_2024-05-22_08-50-49_908020_519686/logs --gcs-address=10.20.240.18:6379 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5` (via SIGTERM)
2024-05-22 09:25:37,254	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --raylet_socket_name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/raylet --store_socket_name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/plasma_store --object_manager_port=0 --min_worker_port=10002 --max_worker_port=19999 --node_manager_port=0 --node_ip_address=10.20.240.18 --maximum_startup_concurrency=16 --static_resource_list=node:10.20.240.18,1.0,node:__internal_head__,1.0,accelerator_type:G,1,CPU,16,GPU,1,memory,17179869184,object_store_memory,60184261017 "--python_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/default_worker.py --node-ip-address=10.20.240.18 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/plasma_store --raylet-name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/raylet --redis-address=None --temp-dir=/local/ray --metrics-agent-port=61802 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=10.20.240.18:6379 --session-name=session_2024-05-22_08-50-49_908020_519686 --temp-dir=/local/ray --webui= RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER" "--java_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py -Dray.address=10.20.240.18:6379 -Dray.raylet.node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER -Dray.object-store.socket-name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/plasma_store -Dray.raylet.socket-name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/raylet -Dray.redis.password= -Dray.node-ip=10.20.240.18 -Dray.home=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/../.. -Dray.logging.dir=/local/ray/session_2024-05-22_08-50-49_908020_519686/logs -Dray.session-dir=/local/ray/session_2024-05-22_08-50-49_908020_519686 RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER io.ray.runtime.runner.worker.DefaultWorker" --cpp_worker_command= --native_library_path=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/cpp/lib --temp_dir=/local/ray --session_dir=/local/ray/session_2024-05-22_08-50-49_908020_519686 --log_dir=/local/ray/session_2024-05-22_08-50-49_908020_519686/logs --resource_dir=/local/ray/session_2024-05-22_08-50-49_908020_519686/runtime_resources --metrics-agent-port=61802 --metrics_export_port=56347 --object_store_memory=60184261017 --plasma_directory=/dev/shm --ray-debugger-external=0 --gcs-address=10.20.240.18:6379 --session-name=session_2024-05-22_08-50-49_908020_519686 --labels= --head --num_prestart_python_workers=16 "--agent_command=/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/dashboard/agent.py --node-ip-address=10.20.240.18 --metrics-export-port=56347 --dashboard-agent-port=61802 --listen-port=52365 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/plasma_store --raylet-name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/raylet --temp-dir=/local/ray --session-dir=/local/ray/session_2024-05-22_08-50-49_908020_519686 --runtime-env-dir=/local/ray/session_2024-05-22_08-50-49_908020_519686/runtime_resources --log-dir=/local/ray/session_2024-05-22_08-50-49_908020_519686/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --session-name=session_2024-05-22_08-50-49_908020_519686 --gcs-address=10.20.240.18:6379 --minimal"` (via SIGTERM)
2024-05-22 09:25:37,255	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/dashboard/agent.py --node-ip-address=10.20.240.18 --metrics-export-port=56347 --dashboard-agent-port=61802 --listen-port=52365 --node-manager-port=43271 --object-store-name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/plasma_store --raylet-name=/local/ray/session_2024-05-22_08-50-49_908020_519686/sockets/raylet --temp-dir=/local/ray --session-dir=/local/ray/session_2024-05-22_08-50-49_908020_519686 --runtime-env-dir=/local/ray/session_2024-05-22_08-50-49_908020_519686/runtime_resources --log-dir=/local/ray/session_2024-05-22_08-50-49_908020_519686/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --session-name=session_2024-05-22_08-50-49_908020_519686 --gcs-address=10.20.240.18:6379 --minimal --agent-id 424238335` (via SIGTERM)
2024-05-22 09:25:37,257	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/dashboard/dashboard.py --host=127.0.0.1 --port=8265 --port-retries=0 --temp-dir=/local/ray --log-dir=/local/ray/session_2024-05-22_08-50-49_908020_519686/logs --session-dir=/local/ray/session_2024-05-22_08-50-49_908020_519686 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=10.20.240.18:6379 --node-ip-address=10.20.240.18 --minimal` (via SIGTERM)
2024-05-22 09:25:37,272	INFO scripts.py:1098 -- 1/6 stopped.2024-05-22 09:25:37,445	INFO scripts.py:1098 -- 2/6 stopped.2024-05-22 09:25:37,459	INFO scripts.py:1098 -- 3/6 stopped.2024-05-22 09:25:37,459	INFO scripts.py:1098 -- 4/6 stopped.2024-05-22 09:25:37,459	INFO scripts.py:1098 -- 5/6 stopped.2024-05-22 09:25:37,913	INFO scripts.py:1098 -- 6/6 stopped.2024-05-22 09:25:38,008	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_dir=/local/ray/session_2024-05-22_08-50-49_908020_519686/logs --config_list=eyJvYmplY3Rfc3BpbGxpbmdfY29uZmlnIjogIntcInR5cGVcIjogXCJmaWxlc3lzdGVtXCIsIFwicGFyYW1zXCI6IHtcImRpcmVjdG9yeV9wYXRoXCI6IFwiL2xvY2FsL3JheS9zZXNzaW9uXzIwMjQtMDUtMjJfMDgtNTAtNDlfOTA4MDIwXzUxOTY4NlwifX0iLCAiaXNfZXh0ZXJuYWxfc3RvcmFnZV90eXBlX2ZzIjogdHJ1ZX0= --gcs_server_port=6379 --metrics-agent-port=61802 --node-ip-address=10.20.240.18 --session-name=session_2024-05-22_08-50-49_908020_519686` (via SIGTERM)
2024-05-22 09:25:38,381	INFO scripts.py:1098 -- 1/1 stopped.2024-05-22 09:25:38,381	SUCC scripts.py:1142 -- Stopped all 7 Ray processes.
