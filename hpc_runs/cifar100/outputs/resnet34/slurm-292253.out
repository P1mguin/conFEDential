ctit088
2024-06-10 16:23:33,559	INFO usage_lib.py:412 -- Usage stats collection is enabled. To disable this, add `--disable-usage-stats` to the command that starts the cluster, or run the following command: `ray disable-usage-stats` before starting the cluster. See https://docs.ray.io/en/master/cluster/usage-stats.html for more details.
2024-06-10 16:23:33,560	INFO scripts.py:722 -- Local node IP: 10.20.240.18
2024-06-10 16:23:56,540	SUCC scripts.py:759 -- --------------------
2024-06-10 16:23:56,541	SUCC scripts.py:760 -- Ray runtime started.
2024-06-10 16:23:56,541	SUCC scripts.py:761 -- --------------------
2024-06-10 16:23:56,541	INFO scripts.py:763 -- Next steps
2024-06-10 16:23:56,541	INFO scripts.py:766 -- To add another node to this Ray cluster, run
2024-06-10 16:23:56,541	INFO scripts.py:769 --   ray start --address='10.20.240.18:6379'
2024-06-10 16:23:56,541	INFO scripts.py:778 -- To connect to this Ray cluster:
2024-06-10 16:23:56,541	INFO scripts.py:780 -- import ray
2024-06-10 16:23:56,541	INFO scripts.py:781 -- ray.init()
2024-06-10 16:23:56,541	INFO scripts.py:812 -- To terminate the Ray runtime, run
2024-06-10 16:23:56,541	INFO scripts.py:813 --   ray stop
2024-06-10 16:23:56,542	INFO scripts.py:816 -- To view the status of the cluster, use
2024-06-10 16:23:56,542	INFO scripts.py:817 --   ray status
2024-06-10 16:25:19.131950: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-06-10 16:25:36.418594: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-10 16:25:57.753866: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
INFO flwr 2024-06-10 16:26:15,834 | Data.py:36 | Preprocessing the federated learning dataset
INFO flwr 2024-06-10 16:26:15,835 | Data.py:111 | Found preprocessed data for the given preprocess function with hash efddb1ca4fe67eba076ca51cfd1766212af1fce46847913eececd421a82a7a21, returning
INFO flwr 2024-06-10 16:26:18,835 | Simulation.py:37 | Preparing datasets for federated learning simulation
INFO flwr 2024-06-10 16:26:18,836 | Simulation.py:266 | Found previously split dataloaders with hash bd65c6a03831e38c587d483e1fe6a818e6bdcb912c586e58c4dda52c558b4a79, loading them
INFO flwr 2024-06-10 16:26:30,159 | main.py:110 | Loaded 1 configs with name CIFAR100-RESNET34-FEDADAM, running...
INFO flwr 2024-06-10 16:26:30,164 | main.py:112 | Config:
	Simulation:
		Data:
			dataset_name: cifar100
			batch_size: 64
			preprocess_fn:
				def preprocess_fn(element):
				  return {
				    "x": element["img"],
				    "y": element["fine_label"]
				  }
		Federation:
			client_count: 100
			fraction_fit: 0.1
			global_rounds: 300
			local_rounds: 4
		Model:
			optimizer_name: FedAdam
			model_name: ResNet34
			criterion_name: CrossEntropyLoss
			optimizer_parameters: 
				local: {'lr': 0.01}
				global: {'lr': 0.01, 'betas': [0.9, 0.99], 'eps': 0.0001}
			model_architecture:
				repo_or_dir: pytorch/vision:v0.10.0
					model: resnet34
					pretrained: False
					out_features: 100
	Attack:
		data_access: 1.0
		message_access: server
		repetitions: 0
		Attack Simulation:
			batch_size: 64
			optimizer_name: Adam
			optimizer_parameters:
				eps: 0.0001
			ModelArchitecture:
				gradient_component:
					type: Dropout
						p: 0.2
					type: Conv2d
						out_channels: 1000
						kernel_size: None
						stride: 1
					type: ReLU
				fcn_component:
					type: Dropout
						p: 0.2
					type: Linear
						out_features: 128
					type: ReLU
					type: Dropout
						p: 0.2
					type: Linear
						in_features: 128
						out_features: 64
					type: ReLU
				encoder_component:
					type: Dropout
						p: 0.2
					type: Linear
						out_features: 256
					type: ReLU
					type: Dropout
						p: 0.2
					type: Linear
						in_features: 256
						out_features: 128
					type: ReLU
					type: Dropout
						p: 0.2
					type: Linear
						in_features: 128
						out_features: 64
					type: ReLU
					type: Dropout
						p: 0.2
					type: Linear
						in_features: 64
						out_features: 1
					type: ReLU
					type: Sigmoid
INFO flwr 2024-06-10 16:26:30,174 | Config.py:67 | Starting conFEDential simulation
INFO flwr 2024-06-10 16:26:30,176 | Config.py:72 | No previous federated learning simulation found with hash caa47aafb7ac0f49d834ae52c066512e979437b77978603c35f56eaf479e01b8, starting training simulation...
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-06-10 16:26:33,788 | Simulation.py:406 | Created 1 clients with resources 2 CPUs, 1.0 GPUs, and 16.0GB for the total available 2 CPUs, 1 GPUs and 16.0GB.
INFO flwr 2024-06-10 16:26:33,788 | Simulation.py:161 | Starting federated learning simulation
2024-06-10 16:26:33,846	INFO worker.py:1431 -- Connecting to existing Ray cluster at address: 10.20.240.18:6379...
2024-06-10 16:26:33,859	INFO worker.py:1621 -- Connected to Ray cluster.
E0610 16:26:35.363250704 2906681 chttp2_server.cc:1051]      {"created":"@1718029595.363200566","description":"No address added out of total 1 resolved for '0.0.0.0:10002'","file":"external/com_github_grpc_grpc/src/core/ext/transport/chttp2/server/chttp2_server.cc","file_line":947,"referenced_errors":[{"created":"@1718029595.363195700","description":"Failed to add any wildcard listeners","file":"external/com_github_grpc_grpc/src/core/lib/iomgr/tcp_server_posix.cc","file_line":357,"referenced_errors":[{"created":"@1718029595.363167504","description":"Address family not supported by protocol","errno":97,"file":"external/com_github_grpc_grpc/src/core/lib/iomgr/socket_utils_common_posix.cc","file_line":446,"os_error":"Address family not supported by protocol","syscall":"socket","target_address":"[::]:10002"},{"created":"@1718029595.363195213","description":"Unable to configure socket","fd":28,"file":"external/com_github_grpc_grpc/src/core/lib/iomgr/tcp_server_utils_posix_common.cc","file_line":217,"referenced_errors":[{"created":"@1718029595.363191097","description":"Address already in use","errno":98,"file":"external/com_github_grpc_grpc/src/core/lib/iomgr/tcp_server_utils_posix_common.cc","file_line":191,"os_error":"Address already in use","syscall":"bind"}]}]}]}
[2024-06-10 16:26:35,769 C 2906681 2906681] grpc_server.cc:119:  Check failed: server_ Failed to start the grpc server. The specified port is 10002. This means that Ray's core components will not be able to function correctly. If the server startup error message is `Address already in use`, it indicates the server fails to start because the port is already used by other processes (such as --node-manager-port, --object-manager-port, --gcs-server-port, and ports between --min-worker-port, --max-worker-port). Try running sudo lsof -i :10002 to check if there are other processes listening to the port.
*** StackTrace Information ***
/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_raylet.so(+0xe4bc3a) [0x7efce9d99c3a] ray::operator<<()
/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_raylet.so(+0xe4d722) [0x7efce9d9b722] ray::SpdLogMessage::Flush()
/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_raylet.so(_ZN3ray6RayLogD1Ev+0x37) [0x7efce9d9ba37] ray::RayLog::~RayLog()
/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_raylet.so(_ZN3ray3rpc10GrpcServer3RunEv+0x1530) [0x7efce98973f0] ray::rpc::GrpcServer::Run()
/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_raylet.so(_ZN3ray4core10CoreWorkerC1ERKNS0_17CoreWorkerOptionsERKNS_8WorkerIDE+0x1033) [0x7efce9644293] ray::core::CoreWorker::CoreWorker()
/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_raylet.so(_ZN3ray4core21CoreWorkerProcessImplC2ERKNS0_17CoreWorkerOptionsE+0x587) [0x7efce9650af7] ray::core::CoreWorkerProcessImpl::CoreWorkerProcessImpl()
/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_raylet.so(_ZN3ray4core17CoreWorkerProcess10InitializeERKNS0_17CoreWorkerOptionsE+0xcf) [0x7efce9651bdf] ray::core::CoreWorkerProcess::Initialize()
/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_raylet.so(+0x598914) [0x7efce94e6914] __pyx_pw_3ray_7_raylet_10CoreWorker_1__cinit__()
/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_raylet.so(+0x599993) [0x7efce94e7993] __pyx_tp_new_3ray_7_raylet_CoreWorker()
/deepstore/software/python/3.10.7/lib/libpython3.10.so.1.0(+0x18dbf0) [0x7efdf9fe6bf0] type_call
/deepstore/software/python/3.10.7/lib/libpython3.10.so.1.0(_PyObject_MakeTpCall+0x173) [0x7efdf9fbf333] _PyObject_MakeTpCall
/deepstore/software/python/3.10.7/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x618f) [0x7efdfa06e3af] _PyEval_EvalFrameDefault
/deepstore/software/python/3.10.7/lib/libpython3.10.so.1.0(_PyFunction_Vectorcall+0x26d) [0x7efdfa01c45d] _PyFunction_Vectorcall
/deepstore/software/python/3.10.7/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x14a5) [0x7efdfa0696c5] _PyEval_EvalFrameDefault
/deepstore/software/python/3.10.7/lib/libpython3.10.so.1.0(_PyFunction_Vectorcall+0x26d) [0x7efdfa01c45d] _PyFunction_Vectorcall
/deepstore/software/python/3.10.7/lib/libpython3.10.so.1.0(PyObject_Call+0xc5) [0x7efdf9fe6905] PyObject_Call
/deepstore/software/python/3.10.7/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x31b0) [0x7efdfa06b3d0] _PyEval_EvalFrameDefault
/deepstore/software/python/3.10.7/lib/libpython3.10.so.1.0(_PyFunction_Vectorcall+0x26d) [0x7efdfa01c45d] _PyFunction_Vectorcall
/deepstore/software/python/3.10.7/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x14a5) [0x7efdfa0696c5] _PyEval_EvalFrameDefault
/deepstore/software/python/3.10.7/lib/libpython3.10.so.1.0(_PyFunction_Vectorcall+0x26d) [0x7efdfa01c45d] _PyFunction_Vectorcall
/deepstore/software/python/3.10.7/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x767) [0x7efdfa068987] _PyEval_EvalFrameDefault
/deepstore/software/python/3.10.7/lib/libpython3.10.so.1.0(_PyFunction_Vectorcall+0x26d) [0x7efdfa01c45d] _PyFunction_Vectorcall
/deepstore/software/python/3.10.7/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x767) [0x7efdfa068987] _PyEval_EvalFrameDefault
/deepstore/software/python/3.10.7/lib/libpython3.10.so.1.0(_PyFunction_Vectorcall+0x26d) [0x7efdfa01c45d] _PyFunction_Vectorcall
/deepstore/software/python/3.10.7/lib/libpython3.10.so.1.0(_PyEval_EvalFrameDefault+0x330) [0x7efdfa068550] _PyEval_EvalFrameDefault
/deepstore/software/python/3.10.7/lib/libpython3.10.so.1.0(+0x1bf021) [0x7efdfa018021] _PyEval_Vector
/deepstore/software/python/3.10.7/lib/libpython3.10.so.1.0(PyEval_EvalCode+0x96) [0x7efdfa0eeaf6] PyEval_EvalCode
/deepstore/software/python/3.10.7/lib/libpython3.10.so.1.0(+0x2a7a9d) [0x7efdfa100a9d] run_eval_code_obj
/deepstore/software/python/3.10.7/lib/libpython3.10.so.1.0(+0x2c5d0b) [0x7efdfa11ed0b] run_mod
/deepstore/software/python/3.10.7/lib/libpython3.10.so.1.0(+0x12206b) [0x7efdf9f7b06b] pyrun_file
/deepstore/software/python/3.10.7/lib/libpython3.10.so.1.0(_PyRun_SimpleFileObject+0x373) [0x7efdf9f7b409] _PyRun_SimpleFileObject
/deepstore/software/python/3.10.7/lib/libpython3.10.so.1.0(_PyRun_AnyFileObject+0x88) [0x7efdf9f7b5c2] _PyRun_AnyFileObject
/deepstore/software/python/3.10.7/lib/libpython3.10.so.1.0(Py_RunMain+0x3d6) [0x7efdfa124366] Py_RunMain
/deepstore/software/python/3.10.7/lib/libpython3.10.so.1.0(Py_BytesMain+0x3d) [0x7efdfa12459d] Py_BytesMain
/lib/x86_64-linux-gnu/libc.so.6(+0x29d90) [0x7efdfa291d90]
/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0x80) [0x7efdfa291e40] __libc_start_main
/home/s2240084/conFEDential/venv/bin/python(_start+0x2e) [0x5555d4b5909e] _start

srun: error: ctit088: task 0: Exited with exit code 1
2024-06-10 16:26:40.404548: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-06-10 16:26:40.474503: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-10 16:26:41.789241: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
INFO flwr 2024-06-10 16:26:48,073 | Data.py:36 | Preprocessing the federated learning dataset
INFO flwr 2024-06-10 16:26:48,074 | Data.py:111 | Found preprocessed data for the given preprocess function with hash efddb1ca4fe67eba076ca51cfd1766212af1fce46847913eececd421a82a7a21, returning
INFO flwr 2024-06-10 16:26:48,425 | Simulation.py:37 | Preparing datasets for federated learning simulation
INFO flwr 2024-06-10 16:26:48,426 | Simulation.py:266 | Found previously split dataloaders with hash bd65c6a03831e38c587d483e1fe6a818e6bdcb912c586e58c4dda52c558b4a79, loading them
INFO flwr 2024-06-10 16:26:58,462 | main.py:110 | Loaded 1 configs with name CIFAR100-RESNET34-FEDAVG, running...
INFO flwr 2024-06-10 16:26:58,468 | main.py:112 | Config:
	Simulation:
		Data:
			dataset_name: cifar100
			batch_size: 64
			preprocess_fn:
				def preprocess_fn(element):
				  return {
				    "x": element["img"],
				    "y": element["fine_label"]
				  }
		Federation:
			client_count: 100
			fraction_fit: 0.1
			global_rounds: 300
			local_rounds: 4
		Model:
			optimizer_name: FedAvg
			model_name: ResNet34
			criterion_name: CrossEntropyLoss
			optimizer_parameters: 
				lr: 0.01
			model_architecture:
				repo_or_dir: pytorch/vision:v0.10.0
					model: resnet34
					pretrained: False
					out_features: 100
	Attack:
		data_access: 1.0
		message_access: server
		repetitions: 0
		Attack Simulation:
			batch_size: 64
			optimizer_name: Adam
			optimizer_parameters:
				lr: 0.0001
			ModelArchitecture:
				gradient_component:
					type: Dropout
						p: 0.2
					type: Conv2d
						out_channels: 1000
						kernel_size: None
						stride: 1
					type: ReLU
				fcn_component:
					type: Dropout
						p: 0.2
					type: Linear
						out_features: 128
					type: ReLU
					type: Dropout
						p: 0.2
					type: Linear
						in_features: 128
						out_features: 64
					type: ReLU
				encoder_component:
					type: Dropout
						p: 0.2
					type: Linear
						out_features: 256
					type: ReLU
					type: Dropout
						p: 0.2
					type: Linear
						in_features: 256
						out_features: 128
					type: ReLU
					type: Dropout
						p: 0.2
					type: Linear
						in_features: 128
						out_features: 64
					type: ReLU
					type: Dropout
						p: 0.2
					type: Linear
						in_features: 64
						out_features: 1
					type: ReLU
					type: Sigmoid
INFO flwr 2024-06-10 16:26:58,480 | Config.py:67 | Starting conFEDential simulation
INFO flwr 2024-06-10 16:26:58,482 | Config.py:72 | No previous federated learning simulation found with hash b3b9198efd6ce563a44ef7ab149d79fbaa826077dedf48204d6e81f2596f72b8, starting training simulation...
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-06-10 16:27:00,582 | Simulation.py:406 | Created 1 clients with resources 2 CPUs, 1.0 GPUs, and 16.0GB for the total available 2 CPUs, 1 GPUs and 16.0GB.
INFO flwr 2024-06-10 16:27:00,583 | Simulation.py:161 | Starting federated learning simulation
2024-06-10 16:27:00,660	INFO worker.py:1431 -- Connecting to existing Ray cluster at address: 10.20.240.18:6379...
2024-06-10 16:27:00,677	INFO worker.py:1621 -- Connected to Ray cluster.
INFO flwr 2024-06-10 16:27:00,703 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=300, round_timeout=None)
2024-06-10 16:27:00,849	INFO worker.py:1453 -- Calling ray.init() again after it has already been called.
INFO flwr 2024-06-10 16:27:00,850 | app.py:213 | Flower VCE: Ray initialized with resources: {'node:__internal_head__': 2.0, 'GPU': 2.0, 'accelerator_type:G': 2.0, 'object_store_memory': 36316086681.0, 'node:10.20.240.18': 2.0, 'CPU': 4.0, 'memory': 34359738368.0}
INFO flwr 2024-06-10 16:27:00,851 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-06-10 16:27:00,851 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 2, 'num_gpus': 1.0, 'memory': 17179869184}
INFO flwr 2024-06-10 16:27:00,871 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 2 actors
INFO flwr 2024-06-10 16:27:00,872 | server.py:89 | Initializing global parameters
INFO flwr 2024-06-10 16:27:00,873 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-06-10 16:27:00,873 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-06-10 16:27:04,426 | server.py:94 | initial parameters (loss, other metrics): 5.040051953125, {'accuracy': 0.0116, 'data_size': 10000}
INFO flwr 2024-06-10 16:27:04,427 | server.py:104 | FL starting
DEBUG flwr 2024-06-10 16:27:04,427 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[1m[36m(autoscaler +56s)[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.
[2m[1m[33m(autoscaler +56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2m11s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2m11s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3m21s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3m21s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7m32s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8m12s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8m52s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9m2s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9m32s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10m12s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10m12s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10m52s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10m52s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11m32s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11m33s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +12m12s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +12m23s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +12m52s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +12m58s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +13m32s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +13m33s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +14m13s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +14m14s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +14m53s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +14m53s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +15m33s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +15m33s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +16m8s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +16m8s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +16m43s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +16m43s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +17m24s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +17m24s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +17m58s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +17m58s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +18m34s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +18m34s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +19m24s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +19m24s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +20m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +20m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +20m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +20m39s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +21m14s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +21m14s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +21m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +21m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +22m34s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +22m34s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +23m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +23m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +24m19s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +24m19s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +24m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +24m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +25m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +25m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +26m19s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +26m19s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +26m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +26m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +27m34s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +27m34s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +28m14s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +28m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +29m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +29m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +30m19s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +30m20s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +32m34s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +32m35s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +33m14s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +33m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +34m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +34m35s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +34m50s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +35m10s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +35m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +35m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +36m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +36m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +36m40s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +37m1s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +37m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +37m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +38m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +38m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +39m35s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +39m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +40m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +40m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +40m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +41m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +41m30s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +42m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +43m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +43m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +43m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +43m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +44m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +44m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +45m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +45m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +47m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +47m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +47m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +48m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +48m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +48m42s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +49m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +49m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +49m51s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +49m52s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +50m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +50m32s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +51m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +51m8s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +51m53s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +51m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +52m33s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +53m13s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +54m3s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +54m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +54m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +54m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +55m13s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +55m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +55m53s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +56m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +56m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +56m52s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +57m13s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +57m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +58m14s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +58m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +58m49s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +58m52s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +59m24s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h32s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h1m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h1m19s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h1m42s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h1m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h2m22s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h2m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h3m2s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h3m29s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h3m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h4m13s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h5m3s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h5m14s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h5m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h5m49s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h6m13s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h6m35s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h6m53s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h7m10s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h7m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h7m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h8m3s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h8m35s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h8m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h9m13s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h9m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h9m48s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h9m50s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h10m23s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h10m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h11m3s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h11m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h11m43s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h11m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h12m23s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h13m23s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h13m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h13m59s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h14m1s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h15m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h15m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h15m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h15m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h16m19s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h16m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h16m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h17m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h17m34s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h18m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h18m9s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h18m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h18m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h19m34s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h19m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h20m14s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h20m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h20m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h22m14s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h22m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h22m49s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h22m52s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h23m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h23m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h24m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h24m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h24m40s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h24m42s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h25m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h25m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h25m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h26m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h26m30s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h27m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h28m12s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h28m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h28m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h29m0s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h29m22s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h29m35s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h29m58s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h30m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h30m33s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h30m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h31m8s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h31m30s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h31m43s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h32m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h32m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h32m53s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h32m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h33m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h33m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h34m3s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h34m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h34m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h34m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h35m13s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h35m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h35m48s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h36m23s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h36m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h37m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h37m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h37m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h38m19s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h38m31s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h38m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h40m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h40m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h40m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h40m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h41m24s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h41m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h42m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h42m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h42m39s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h42m42s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h44m34s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h44m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h45m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h45m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h45m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h46m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h46m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h47m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h47m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h48m20s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h48m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h48m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h49m2s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h49m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h50m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h51m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h51m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h51m42s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h52m23s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h53m3s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h53m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h53m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h53m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h54m13s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h54m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h54m53s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h55m21s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h55m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h55m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h56m3s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h56m43s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h56m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h57m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h57m31s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h57m53s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h58m33s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h59m13s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h59m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1h59m48s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h23s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h1m23s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h1m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h1m59s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h2m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h2m34s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h3m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h3m14s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h3m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h3m49s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h4m24s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h5m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h5m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h5m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h6m19s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h6m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h6m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h7m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h7m34s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h7m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h8m9s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h8m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h8m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h9m13s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h9m24s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h9m53s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h10m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h10m33s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h11m13s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h11m53s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h12m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h12m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h12m50s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h13m3s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h13m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h13m43s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h14m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h14m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h14m50s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h15m3s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h15m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h15m43s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h16m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h16m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h16m40s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h16m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h17m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h17m29s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h17m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h18m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h18m35s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h18m39s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h19m14s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h20m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h20m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h20m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h21m19s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h21m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h21m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h22m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h22m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h22m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h24m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h24m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h25m30s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h25m31s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h26m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h26m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h26m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h26m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h27m20s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h27m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h28m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h28m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h28m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h28m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h29m20s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h29m21s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h31m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h31m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h31m50s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h31m52s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h32m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h32m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h33m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h33m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h33m41s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h33m42s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h34m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h34m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h34m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h34m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h35m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h35m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h36m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h37m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h37m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h38m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h38m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h39m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h39m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h40m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h40m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h41m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h41m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h41m58s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h42m33s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h43m13s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h43m53s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h43m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h44m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h44m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h45m3s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h45m43s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h46m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h46m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h46m53s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h46m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h47m43s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h48m8s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h48m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h48m53s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h49m33s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h49m43s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h50m13s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h50m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h50m53s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h50m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h51m33s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h51m34s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h52m13s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h52m14s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h52m48s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h52m49s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h53m23s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h53m24s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h54m3s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h54m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h54m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h54m39s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h55m13s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h55m24s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h56m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h56m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h56m39s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h56m39s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h57m24s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h57m34s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h58m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h58m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h58m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h59m19s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h59m19s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h59m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2h59m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h1m34s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h2m14s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h2m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h2m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h3m30s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h3m30s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h4m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h4m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h4m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h4m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h5m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h5m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h6m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h6m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h6m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h6m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h7m20s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h7m20s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h8m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h8m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h9m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h9m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h9m40s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h9m40s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h11m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h11m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h13m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h13m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h14m1s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h14m1s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h14m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h14m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h15m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h15m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h15m51s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h15m51s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h16m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h16m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h17m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h17m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h17m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h17m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h19m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h19m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h21m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h21m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h22m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h22m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h24m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h24m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h25m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h26m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h26m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h27m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h28m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h28m33s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h30m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h30m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h31m3s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h31m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h31m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h31m58s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h32m13s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h32m48s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h32m48s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h33m23s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h33m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h33m58s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h34m13s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h34m33s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h34m48s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h35m8s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h35m23s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h35m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h36m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h36m24s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h36m43s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h36m59s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h37m23s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h37m34s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h38m3s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h38m14s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h38m43s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h38m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h39m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h39m29s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h39m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h40m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h40m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h40m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h41m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h41m19s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h41m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h41m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h42m24s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h42m34s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h43m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h43m10s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h43m39s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h43m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h44m24s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h45m14s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h45m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h45m49s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h45m50s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h46m34s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h46m35s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h47m24s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h47m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h48m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h48m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h48m39s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h48m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h49m14s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h49m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h49m49s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h50m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h50m24s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h50m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h51m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h51m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h51m40s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h52m11s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h52m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h52m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h52m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h53m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h53m35s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h54m1s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h54m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h54m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h54m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h55m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h55m35s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h55m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h56m10s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h58m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3h58m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h41s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h1m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h1m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h1m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h2m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h2m31s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h2m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h3m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h4m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h4m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h4m51s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h4m52s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h6m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h6m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h8m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h8m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h9m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h9m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h9m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h9m58s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h10m33s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h10m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h11m8s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h11m12s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h11m43s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h11m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h12m23s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h12m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h12m58s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h13m2s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h13m33s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h14m13s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h15m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h15m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h15m39s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h15m52s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h16m14s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h16m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h16m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h17m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h17m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h17m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h18m34s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h19m14s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h19m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h19m58s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h20m29s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h20m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h21m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h21m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h21m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h21m58s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h22m20s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h22m33s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h23m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h23m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h24m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h24m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h25m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h25m23s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h25m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h26m3s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h26m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h26m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h27m0s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h27m13s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h27m53s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h28m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h28m33s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h28m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h29m14s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h29m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h30m34s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h30m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h31m9s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h31m21s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h31m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h31m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h32m34s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h32m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h33m9s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h33m11s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h33m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h33m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h34m34s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h34m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h35m9s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h35m11s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h35m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h35m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h36m24s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h36m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h37m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h37m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h37m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h39m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h39m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h39m50s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h39m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h40m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h40m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h41m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h41m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h41m40s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h42m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h42m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h42m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h43m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h43m30s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h43m42s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h44m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h44m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h44m50s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h44m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h45m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h45m32s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h46m0s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h46m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h46m35s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h46m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h47m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h47m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h47m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h48m3s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h48m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h48m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h49m11s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h49m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h49m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h49m58s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h50m21s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h50m33s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h52m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h52m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h52m51s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h53m8s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h53m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h53m43s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h54m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h54m23s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h54m41s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h55m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h55m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h55m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h56m24s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h56m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h56m59s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h57m11s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h57m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h58m24s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h58m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h58m59s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h59m32s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4h59m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h24s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h59s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h1m2s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h1m34s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h1m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h2m10s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h2m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h2m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h2m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h3m20s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h3m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h3m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h4m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h4m30s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h4m58s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h5m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h5m32s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h5m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h6m8s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h6m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h7m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h7m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h7m40s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h9m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h9m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h10m1s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h10m3s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h10m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h10m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h11m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h11m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h11m51s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h11m53s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h12m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h12m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h13m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h13m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h13m48s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h14m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h14m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h15m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h15m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h15m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h15m58s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h16m53s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h17m33s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h17m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h18m9s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h18m12s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h18m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h18m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h19m24s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h19m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h20m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h20m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h20m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h20m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h21m24s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h21m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h22m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h22m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h22m39s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h23m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h23m14s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h24m34s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h24m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h25m9s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h25m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h25m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h25m58s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h26m24s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h26m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h27m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h27m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h27m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h27m58s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h28m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h28m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h29m0s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h29m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h30m35s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h30m48s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h31m10s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h31m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h31m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h32m13s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h32m20s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h32m53s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h33m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h33m29s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h33m40s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h34m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h34m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h34m39s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h34m50s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h35m14s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h35m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h35m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h36m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h36m34s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h36m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h37m10s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h37m20s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h37m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h37m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h38m24s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h38m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h39m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h39m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h39m39s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h40m14s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h41m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h41m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h41m50s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h42m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h42m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h43m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h43m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h43m40s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h44m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h44m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h44m50s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h44m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h45m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h45m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h46m0s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h46m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h46m35s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h47m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h47m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h47m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h47m50s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h48m22s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h48m35s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h48m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h49m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h49m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h50m11s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h50m12s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h50m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h50m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h51m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h51m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h52m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h52m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h52m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h53m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h53m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h54m31s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h54m32s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h55m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h55m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h56m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h56m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h56m52s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h57m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h57m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h57m48s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h58m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h58m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h58m42s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h59m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h59m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h59m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5h59m58s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h2m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h2m48s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h3m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h4m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h4m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h4m48s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h5m23s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h5m23s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h5m58s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h5m58s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h6m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h6m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h7m13s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h7m13s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h7m48s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h7m49s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h8m24s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h8m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h9m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h9m8s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h9m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h10m24s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h11m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h11m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h11m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h11m53s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h12m24s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h13m14s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h13m19s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h13m49s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h13m59s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h14m24s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h14m39s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h15m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h15m14s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h15m39s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h15m49s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h16m14s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h16m24s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h16m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h17m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h17m35s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h17m39s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h18m14s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h18m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h18m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h18m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h19m34s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h19m35s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h20m9s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h20m10s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h20m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h20m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h21m20s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h21m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h21m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h22m0s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h22m35s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h22m35s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h23m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h23m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h23m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h23m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h24m35s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h24m35s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h25m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h25m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h25m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h25m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h26m30s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h26m30s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h27m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h27m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h27m40s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h27m41s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h28m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h28m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h28m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h28m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h29m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h29m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h30m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h30m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h31m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h31m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h32m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h32m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h32m41s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h32m41s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h33m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h33m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h34m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h34m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h34m41s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h34m41s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h36m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h36m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h37m22s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h37m22s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h38m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h38m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h39m22s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h39m22s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h39m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h39m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h40m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h40m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h41m13s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h41m13s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h41m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h41m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h42m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h42m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h43m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h43m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h43m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h43m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h44m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h44m58s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h45m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h45m33s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h47m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h47m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h47m53s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h47m53s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h49m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h49m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h50m8s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h50m8s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h51m8s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h51m8s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h51m43s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h51m43s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h53m58s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h53m59s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h54m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h54m39s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h55m14s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h55m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h55m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h56m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h56m34s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h56m49s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h57m9s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h57m29s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h57m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h58m19s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h58m19s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h58m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h58m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h59m34s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6h59m34s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h9s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h1m19s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h1m30s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h1m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h2m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h2m29s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h2m40s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h3m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h3m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h3m40s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h3m50s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h4m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h4m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h4m50s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h5m0s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h5m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h5m35s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h6m0s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h6m10s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h6m35s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h6m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h7m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h7m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h7m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h8m35s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h8m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h9m10s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h9m11s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h9m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h9m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h10m20s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h10m21s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h10m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h10m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h11m31s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h11m31s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h12m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h12m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h12m41s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h12m41s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h13m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h13m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h13m51s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h13m51s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h14m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h14m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h15m1s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h15m2s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h15m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h15m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h16m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h16m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h16m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h16m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h17m31s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h17m32s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h18m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h18m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h18m42s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h18m42s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h19m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h19m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h19m52s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h19m52s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h20m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h20m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h21m2s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h21m3s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h21m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h21m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h22m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h22m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h23m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h23m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h23m52s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h23m53s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h24m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h24m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h25m2s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h25m3s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h25m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h25m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h26m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h26m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h26m53s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h26m53s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h27m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h27m48s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h28m8s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h28m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h28m48s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h29m9s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h29m23s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h29m49s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h29m58s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h30m29s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h30m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h31m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h31m19s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h31m58s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h31m59s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h32m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h32m39s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h33m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h33m19s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h33m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h33m58s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h34m29s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h34m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h35m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h35m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h35m39s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h35m53s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h36m14s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h36m29s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h36m49s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h37m9s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h37m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h37m49s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h38m0s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h38m29s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h38m35s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h39m9s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h39m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h39m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h39m59s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h40m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h40m39s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h41m24s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h41m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h42m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h42m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h42m39s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h42m40s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h43m14s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h43m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h44m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h44m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h44m39s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h44m41s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h45m14s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h45m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h45m50s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h45m51s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h46m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h46m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h47m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h47m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h47m40s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h47m41s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h48m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h48m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h48m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h48m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h49m35s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h49m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h50m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h50m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h50m50s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h50m51s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h51m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h51m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h52m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h52m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h52m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h52m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h53m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h53m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h54m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h54m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h54m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h54m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h55m30s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h55m32s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h56m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h56m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h56m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h56m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h57m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h57m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h58m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h58m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h58m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h58m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h59m21s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7h59m22s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h1m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h1m8s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h1m41s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h1m43s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h2m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h2m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h2m51s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h2m58s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h3m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h3m33s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h4m1s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h4m8s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h4m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h4m48s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h5m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h5m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h5m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h6m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h6m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h6m58s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h7m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h7m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h7m52s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h8m13s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h8m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h9m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h9m9s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h9m42s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h9m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h10m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h10m19s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h10m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h10m59s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h11m32s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h11m39s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h12m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h12m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h12m49s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h13m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h13m29s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h14m2s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h14m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h14m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h15m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h15m24s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h15m48s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h16m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h16m23s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h16m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h17m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h17m48s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h18m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h18m23s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h18m40s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h18m58s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h19m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h19m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h19m50s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h20m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h20m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h20m58s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h21m0s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h21m35s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h21m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h22m10s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h22m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h22m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h23m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h23m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h24m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h24m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h24m41s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h25m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h25m19s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h25m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h25m59s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h26m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h26m49s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h27m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h27m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h28m19s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h28m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h28m59s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h29m11s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h30m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h30m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h30m59s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h31m32s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h31m34s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h32m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h33m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h33m29s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h33m52s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h34m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h34m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h34m39s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h35m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h35m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h35m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h35m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h36m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h36m30s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h37m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h37m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h37m40s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h37m42s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h38m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h38m48s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h38m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h39m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h39m30s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h40m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h40m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h40m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h41m8s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h41m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h41m48s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h42m0s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h42m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h42m35s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h43m8s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h43m10s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h43m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h43m59s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h44m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h44m39s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h45m1s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h45m19s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h45m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h45m53s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h46m11s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h46m29s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h46m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h47m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h48m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h48m19s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h48m51s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h48m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h49m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h50m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h50m39s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h51m11s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h51m19s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h51m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h52m9s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h52m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h52m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h53m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h53m29s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h53m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h54m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h54m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h54m44s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h55m2s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h55m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h56m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h56m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h56m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h57m20s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h57m22s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h57m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h57m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h58m30s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h58m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h59m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h59m12s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h59m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8h59m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h1m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h1m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h1m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h1m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h2m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h3m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h3m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h3m41s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h3m52s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h4m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h4m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h4m51s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h5m8s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h5m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h5m48s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h6m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h6m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h6m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h7m8s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h7m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h7m43s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h8m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h8m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h9m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h9m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h10m1s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h10m3s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h10m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h10m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h11m12s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h11m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h11m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h11m53s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h12m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h12m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h13m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h13m8s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h13m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h13m48s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h15m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h15m59s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h16m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h16m39s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h17m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h17m29s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h17m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h18m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h20m8s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h20m9s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h20m48s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h20m49s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h21m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h21m39s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h22m8s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h22m14s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h24m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h24m20s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h24m53s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h24m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h25m35s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h26m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h26m19s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h26m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h26m59s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h27m30s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h27m39s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h28m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h28m19s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h28m40s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h29m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h29m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h30m29s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h30m30s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h31m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h31m19s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h31m40s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h32m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h32m49s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h33m20s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h33m29s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h33m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h34m10s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h34m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h34m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h35m11s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h35m35s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h35m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h36m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h36m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h36m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h37m11s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h37m30s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h37m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h38m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h38m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h38m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h39m2s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h39m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h39m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h40m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h40m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h41m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h41m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h41m41s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h41m42s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h42m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h43m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h43m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h43m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h44m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h44m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h44m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h45m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h45m31s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h45m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h46m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h47m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h47m31s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h47m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h48m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h48m32s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h48m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h49m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h49m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h49m42s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h50m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h50m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h50m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h51m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h51m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h52m2s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h52m2s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h52m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h52m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h53m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h53m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h53m52s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h53m52s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h54m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h54m58s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h55m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h55m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h56m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h56m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h56m52s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h56m53s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h57m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h57m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h58m3s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h58m3s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h58m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h58m48s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h59m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h59m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9h59m58s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h3s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h1m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h1m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h2m8s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h2m8s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h2m43s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h2m43s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h3m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h3m19s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h3m58s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h3m59s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h4m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h4m39s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h5m19s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h5m19s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h5m59s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h5m59s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h6m34s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h6m34s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h8m29s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h8m29s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h9m9s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h9m9s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h9m49s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h9m49s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h10m29s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h10m29s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h11m49s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h11m49s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h12m39s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h12m39s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h14m50s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h14m50s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h15m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h15m40s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h16m0s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h16m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h16m35s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h16m50s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h17m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h17m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h17m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h18m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h18m35s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h18m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h19m10s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h19m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h19m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h20m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h20m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h20m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h21m1s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h21m20s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h21m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h21m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h22m11s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h22m30s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h22m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h23m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h23m21s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h23m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h23m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h24m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h24m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h25m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h25m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h25m41s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h25m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h26m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h26m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h26m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h27m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h27m31s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h27m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h28m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h28m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h28m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h29m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h29m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h30m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h30m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h31m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h31m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h31m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h32m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h32m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h32m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h33m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h33m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h33m52s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h34m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h34m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h35m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h35m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h36m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h36m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h36m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h36m58s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h37m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h37m48s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h38m37s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h38m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h39m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h39m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h39m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h39m58s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h40m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h40m48s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h41m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h41m48s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h42m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h42m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h43m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h43m8s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h43m48s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h43m48s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h44m23s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h44m23s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h45m8s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h45m9s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h45m48s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h45m49s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h46m23s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h46m24s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h46m58s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h46m59s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h48m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h48m29s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h49m8s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h49m9s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h49m48s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h49m49s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h50m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h50m29s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h52m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h52m40s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h53m49s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h53m50s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h54m39s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[36m(pid=3822180)[0m 2024-06-11 03:26:22.316358: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
[2m[36m(pid=3822181)[0m 2024-06-11 03:26:24.991280: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=3822181)[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=3822181)[0m 2024-06-11 03:26:46.751695: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[36m(pid=3822181)[0m 2024-06-11 03:26:22.316348: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
[2m[36m(pid=3822180)[0m 2024-06-11 03:26:24.991222: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=3822180)[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
DEBUG flwr 2024-06-11 03:31:38,676 | server.py:236 | fit_round 1 received 10 results and 0 failures
[2m[1m[33m(autoscaler +10h54m40s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h55m29s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h55m30s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h56m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h56m9s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h56m40s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h56m49s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h57m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h57m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h58m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10h58m49s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h2m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h2m30s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h2m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h3m20s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h3m31s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h3m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h4m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h4m40s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h4m41s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h5m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h5m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h5m50s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h6m25s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h6m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h7m0s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
INFO flwr 2024-06-11 03:36:35,514 | server.py:125 | fit progress: (1, 4.758622265625, {'accuracy': 0.0134, 'data_size': 10000}, 40171.08711425029)
INFO flwr 2024-06-11 03:36:35,515 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-06-11 03:36:35,516 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
DEBUG flwr 2024-06-11 03:39:49,694 | server.py:236 | fit_round 2 received 10 results and 0 failures
INFO flwr 2024-06-11 03:41:08,016 | server.py:125 | fit progress: (2, 4.69891875, {'accuracy': 0.017, 'data_size': 10000}, 40443.5893953871)
INFO flwr 2024-06-11 03:41:08,017 | server.py:171 | evaluate_round 2: no clients selected, cancel
DEBUG flwr 2024-06-11 03:41:08,018 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 100)
ERROR flwr 2024-06-11 03:44:05,523 | ray_client_proxy.py:161 | Traceback (most recent call last):
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 151, in _submit_job
    res, updated_context = self.actor_pool.get_client_result(self.cid, timeout)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 425, in get_client_result
    return self._fetch_future_result(cid)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 306, in _fetch_future_result
    res_cid, res, updated_context = ray.get(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2526, in get
    raise value
ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13) where the task (actor ID: 86b0d854d81e2e02d453023703000000, name=DefaultActor.__init__, pid=3822180, memory used=3.37GB) was running was 238.96GB / 251.51GB (0.950083), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
2909640	8.45	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_a...
3822259	3.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3822181	3.43	ray::DefaultActor
3822180	3.37	ray::DefaultActor.run
2906522	1.00	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.

ERROR flwr 2024-06-11 03:44:05,523 | ray_client_proxy.py:162 | Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13) where the task (actor ID: 86b0d854d81e2e02d453023703000000, name=DefaultActor.__init__, pid=3822180, memory used=3.37GB) was running was 238.96GB / 251.51GB (0.950083), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
2909640	8.45	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_a...
3822259	3.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3822181	3.43	ray::DefaultActor
3822180	3.37	ray::DefaultActor.run
2906522	1.00	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
DEBUG flwr 2024-06-11 03:44:18,715 | server.py:236 | fit_round 3 received 9 results and 1 failures
[2m[1m[33m(autoscaler +11h7m35s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h7m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h8m10s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h8m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h8m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h9m20s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h9m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h10m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h11m10s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h11m12s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h11m46s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h12m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h12m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h13m1s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h13m36s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h14m11s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h14m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h14m52s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h15m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h15m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h16m6s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h16m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h16m41s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h16m42s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h17m16s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h17m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[33m(raylet)[0m [2024-06-11 03:44:57,527 E 2906522 2906522] (raylet) node_manager.cc:3084: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13, IP: 10.20.240.18) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.20.240.18`
[2m[33m(raylet)[0m 
[2m[33m(raylet)[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
INFO flwr 2024-06-11 03:45:27,203 | server.py:125 | fit progress: (3, 4.647551953125, {'accuracy': 0.0205, 'data_size': 10000}, 40702.77597283991)
INFO flwr 2024-06-11 03:45:27,204 | server.py:171 | evaluate_round 3: no clients selected, cancel
DEBUG flwr 2024-06-11 03:45:27,204 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 100)
ERROR flwr 2024-06-11 03:46:33,219 | ray_client_proxy.py:161 | Traceback (most recent call last):
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 151, in _submit_job
    res, updated_context = self.actor_pool.get_client_result(self.cid, timeout)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 425, in get_client_result
    return self._fetch_future_result(cid)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 306, in _fetch_future_result
    res_cid, res, updated_context = ray.get(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2526, in get
    raise value
ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13) where the task (actor ID: 86b0d854d81e2e02d453023703000000, name=DefaultActor.__init__, pid=3822180, memory used=3.37GB) was running was 238.96GB / 251.51GB (0.950083), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
2909640	8.45	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_a...
3822259	3.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3822181	3.43	ray::DefaultActor
3822180	3.37	ray::DefaultActor.run
2906522	1.00	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.

ERROR flwr 2024-06-11 03:46:33,224 | ray_client_proxy.py:161 | Traceback (most recent call last):
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 151, in _submit_job
    res, updated_context = self.actor_pool.get_client_result(self.cid, timeout)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 425, in get_client_result
    return self._fetch_future_result(cid)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 306, in _fetch_future_result
    res_cid, res, updated_context = ray.get(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2526, in get
    raise value
ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13) where the task (actor ID: 86b0d854d81e2e02d453023703000000, name=DefaultActor.__init__, pid=3822180, memory used=3.37GB) was running was 238.96GB / 251.51GB (0.950083), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
2909640	8.45	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_a...
3822259	3.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3822181	3.43	ray::DefaultActor
3822180	3.37	ray::DefaultActor.run
2906522	1.00	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.

ERROR flwr 2024-06-11 03:46:33,225 | ray_client_proxy.py:162 | Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13) where the task (actor ID: 86b0d854d81e2e02d453023703000000, name=DefaultActor.__init__, pid=3822180, memory used=3.37GB) was running was 238.96GB / 251.51GB (0.950083), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
2909640	8.45	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_a...
3822259	3.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3822181	3.43	ray::DefaultActor
3822180	3.37	ray::DefaultActor.run
2906522	1.00	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
ERROR flwr 2024-06-11 03:46:33,250 | ray_client_proxy.py:162 | Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13) where the task (actor ID: 86b0d854d81e2e02d453023703000000, name=DefaultActor.__init__, pid=3822180, memory used=3.37GB) was running was 238.96GB / 251.51GB (0.950083), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
2909640	8.45	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_a...
3822259	3.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3822181	3.43	ray::DefaultActor
3822180	3.37	ray::DefaultActor.run
2906522	1.00	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
ERROR flwr 2024-06-11 03:46:43,704 | ray_client_proxy.py:161 | Traceback (most recent call last):
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 151, in _submit_job
    res, updated_context = self.actor_pool.get_client_result(self.cid, timeout)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 425, in get_client_result
    return self._fetch_future_result(cid)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 306, in _fetch_future_result
    res_cid, res, updated_context = ray.get(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2526, in get
    raise value
ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13) where the task (actor ID: 86b0d854d81e2e02d453023703000000, name=DefaultActor.__init__, pid=3822180, memory used=3.37GB) was running was 238.96GB / 251.51GB (0.950083), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
2909640	8.45	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_a...
3822259	3.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3822181	3.43	ray::DefaultActor
3822180	3.37	ray::DefaultActor.run
2906522	1.00	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.

ERROR flwr 2024-06-11 03:46:43,705 | ray_client_proxy.py:162 | Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13) where the task (actor ID: 86b0d854d81e2e02d453023703000000, name=DefaultActor.__init__, pid=3822180, memory used=3.37GB) was running was 238.96GB / 251.51GB (0.950083), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
2909640	8.45	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_a...
3822259	3.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3822181	3.43	ray::DefaultActor
3822180	3.37	ray::DefaultActor.run
2906522	1.00	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
ERROR flwr 2024-06-11 03:47:14,942 | ray_client_proxy.py:161 | Traceback (most recent call last):
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 151, in _submit_job
    res, updated_context = self.actor_pool.get_client_result(self.cid, timeout)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 425, in get_client_result
    return self._fetch_future_result(cid)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 306, in _fetch_future_result
    res_cid, res, updated_context = ray.get(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2526, in get
    raise value
ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13) where the task (actor ID: 86b0d854d81e2e02d453023703000000, name=DefaultActor.__init__, pid=3822180, memory used=3.37GB) was running was 238.96GB / 251.51GB (0.950083), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
2909640	8.45	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_a...
3822259	3.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3822181	3.43	ray::DefaultActor
3822180	3.37	ray::DefaultActor.run
2906522	1.00	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.

ERROR flwr 2024-06-11 03:47:14,943 | ray_client_proxy.py:162 | Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13) where the task (actor ID: 86b0d854d81e2e02d453023703000000, name=DefaultActor.__init__, pid=3822180, memory used=3.37GB) was running was 238.96GB / 251.51GB (0.950083), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
2909640	8.45	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_a...
3822259	3.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3822181	3.43	ray::DefaultActor
3822180	3.37	ray::DefaultActor.run
2906522	1.00	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
ERROR flwr 2024-06-11 03:47:14,944 | ray_client_proxy.py:161 | Traceback (most recent call last):
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 151, in _submit_job
    res, updated_context = self.actor_pool.get_client_result(self.cid, timeout)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 425, in get_client_result
    return self._fetch_future_result(cid)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 306, in _fetch_future_result
    res_cid, res, updated_context = ray.get(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2526, in get
    raise value
ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13) where the task (actor ID: 86b0d854d81e2e02d453023703000000, name=DefaultActor.__init__, pid=3822180, memory used=3.37GB) was running was 238.96GB / 251.51GB (0.950083), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
2909640	8.45	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_a...
3822259	3.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3822181	3.43	ray::DefaultActor
3822180	3.37	ray::DefaultActor.run
2906522	1.00	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.

ERROR flwr 2024-06-11 03:47:14,945 | ray_client_proxy.py:162 | Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13) where the task (actor ID: 86b0d854d81e2e02d453023703000000, name=DefaultActor.__init__, pid=3822180, memory used=3.37GB) was running was 238.96GB / 251.51GB (0.950083), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
2909640	8.45	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_a...
3822259	3.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3822181	3.43	ray::DefaultActor
3822180	3.37	ray::DefaultActor.run
2906522	1.00	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
ERROR flwr 2024-06-11 03:47:48,735 | ray_client_proxy.py:161 | Traceback (most recent call last):
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 151, in _submit_job
    res, updated_context = self.actor_pool.get_client_result(self.cid, timeout)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 425, in get_client_result
    return self._fetch_future_result(cid)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 306, in _fetch_future_result
    res_cid, res, updated_context = ray.get(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2526, in get
    raise value
ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13) where the task (actor ID: 86b0d854d81e2e02d453023703000000, name=DefaultActor.__init__, pid=3822180, memory used=3.37GB) was running was 238.96GB / 251.51GB (0.950083), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
2909640	8.45	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_a...
3822259	3.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3822181	3.43	ray::DefaultActor
3822180	3.37	ray::DefaultActor.run
2906522	1.00	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.

ERROR flwr 2024-06-11 03:47:48,735 | ray_client_proxy.py:162 | Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13) where the task (actor ID: 86b0d854d81e2e02d453023703000000, name=DefaultActor.__init__, pid=3822180, memory used=3.37GB) was running was 238.96GB / 251.51GB (0.950083), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
2909640	8.45	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_a...
3822259	3.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3822181	3.43	ray::DefaultActor
3822180	3.37	ray::DefaultActor.run
2906522	1.00	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
ERROR flwr 2024-06-11 03:47:49,203 | ray_client_proxy.py:161 | Traceback (most recent call last):
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 151, in _submit_job
    res, updated_context = self.actor_pool.get_client_result(self.cid, timeout)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 425, in get_client_result
    return self._fetch_future_result(cid)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 306, in _fetch_future_result
    res_cid, res, updated_context = ray.get(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2526, in get
    raise value
ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13) where the task (actor ID: 86b0d854d81e2e02d453023703000000, name=DefaultActor.__init__, pid=3822180, memory used=3.37GB) was running was 238.96GB / 251.51GB (0.950083), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
2909640	8.45	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_a...
3822259	3.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3822181	3.43	ray::DefaultActor
3822180	3.37	ray::DefaultActor.run
2906522	1.00	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.

ERROR flwr 2024-06-11 03:47:49,204 | ray_client_proxy.py:162 | Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13) where the task (actor ID: 86b0d854d81e2e02d453023703000000, name=DefaultActor.__init__, pid=3822180, memory used=3.37GB) was running was 238.96GB / 251.51GB (0.950083), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
2909640	8.45	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_a...
3822259	3.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3822181	3.43	ray::DefaultActor
3822180	3.37	ray::DefaultActor.run
2906522	1.00	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
DEBUG flwr 2024-06-11 03:47:49,295 | server.py:236 | fit_round 4 received 3 results and 7 failures
[2m[33m(raylet)[0m [2024-06-11 03:47:57,530 E 2906522 2906522] (raylet) node_manager.cc:3084: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13, IP: 10.20.240.18) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.20.240.18`
[2m[33m(raylet)[0m 
[2m[33m(raylet)[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
[2m[33m(raylet)[0m [2024-06-11 03:47:57,944 E 2906523 2906523] (raylet) node_manager.cc:3084: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: baccd8655287851f0509ddef8187bf7d920d56b081f1f711a92be0a1, IP: 10.20.240.18) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.20.240.18`
[2m[33m(raylet)[0m 
[2m[33m(raylet)[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
INFO flwr 2024-06-11 03:48:13,805 | server.py:125 | fit progress: (4, 4.60558359375, {'accuracy': 0.0269, 'data_size': 10000}, 40869.37829907611)
INFO flwr 2024-06-11 03:48:13,806 | server.py:171 | evaluate_round 4: no clients selected, cancel
DEBUG flwr 2024-06-11 03:48:13,806 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 100)
ERROR flwr 2024-06-11 03:48:53,080 | ray_client_proxy.py:161 | Traceback (most recent call last):
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 151, in _submit_job
    res, updated_context = self.actor_pool.get_client_result(self.cid, timeout)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 425, in get_client_result
    return self._fetch_future_result(cid)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 306, in _fetch_future_result
    res_cid, res, updated_context = ray.get(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2526, in get
    raise value
ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: baccd8655287851f0509ddef8187bf7d920d56b081f1f711a92be0a1) where the task (actor ID: e30aa655e903fec27a1e5adf03000000, name=DefaultActor.__init__, pid=3822181, memory used=3.46GB) was running was 238.97GB / 251.51GB (0.950139), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 402cb6a22662ca4470a46261055d8e53040d7fd99d074477c9a980df) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-402cb6a22662ca4470a46261055d8e53040d7fd99d074477c9a980df*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
2909640	8.06	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_a...
3822259	5.19	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3822181	3.46	ray::DefaultActor
3839164	3.42	ray::DefaultActor
2906523	0.54	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906522	0.48	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.

ERROR flwr 2024-06-11 03:48:53,086 | ray_client_proxy.py:162 | Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: baccd8655287851f0509ddef8187bf7d920d56b081f1f711a92be0a1) where the task (actor ID: e30aa655e903fec27a1e5adf03000000, name=DefaultActor.__init__, pid=3822181, memory used=3.46GB) was running was 238.97GB / 251.51GB (0.950139), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 402cb6a22662ca4470a46261055d8e53040d7fd99d074477c9a980df) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-402cb6a22662ca4470a46261055d8e53040d7fd99d074477c9a980df*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
2909640	8.06	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_a...
3822259	5.19	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3822181	3.46	ray::DefaultActor
3839164	3.42	ray::DefaultActor
2906523	0.54	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906522	0.48	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
ERROR flwr 2024-06-11 03:48:53,086 | ray_client_proxy.py:161 | Traceback (most recent call last):
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 151, in _submit_job
    res, updated_context = self.actor_pool.get_client_result(self.cid, timeout)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 425, in get_client_result
    return self._fetch_future_result(cid)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 306, in _fetch_future_result
    res_cid, res, updated_context = ray.get(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2526, in get
    raise value
ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13) where the task (actor ID: 86b0d854d81e2e02d453023703000000, name=DefaultActor.__init__, pid=3822180, memory used=3.37GB) was running was 238.96GB / 251.51GB (0.950083), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
2909640	8.45	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_a...
3822259	3.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3822181	3.43	ray::DefaultActor
3822180	3.37	ray::DefaultActor.run
2906522	1.00	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.

ERROR flwr 2024-06-11 03:48:53,113 | ray_client_proxy.py:162 | Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13) where the task (actor ID: 86b0d854d81e2e02d453023703000000, name=DefaultActor.__init__, pid=3822180, memory used=3.37GB) was running was 238.96GB / 251.51GB (0.950083), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
2909640	8.45	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_a...
3822259	3.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3822181	3.43	ray::DefaultActor
3822180	3.37	ray::DefaultActor.run
2906522	1.00	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
ERROR flwr 2024-06-11 03:49:23,982 | ray_client_proxy.py:161 | Traceback (most recent call last):
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 151, in _submit_job
    res, updated_context = self.actor_pool.get_client_result(self.cid, timeout)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 425, in get_client_result
    return self._fetch_future_result(cid)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 306, in _fetch_future_result
    res_cid, res, updated_context = ray.get(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2526, in get
    raise value
ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13) where the task (actor ID: 86b0d854d81e2e02d453023703000000, name=DefaultActor.__init__, pid=3822180, memory used=3.37GB) was running was 238.96GB / 251.51GB (0.950083), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
2909640	8.45	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_a...
3822259	3.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3822181	3.43	ray::DefaultActor
3822180	3.37	ray::DefaultActor.run
2906522	1.00	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.

ERROR flwr 2024-06-11 03:49:23,983 | ray_client_proxy.py:162 | Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13) where the task (actor ID: 86b0d854d81e2e02d453023703000000, name=DefaultActor.__init__, pid=3822180, memory used=3.37GB) was running was 238.96GB / 251.51GB (0.950083), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
2909640	8.45	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_a...
3822259	3.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3822181	3.43	ray::DefaultActor
3822180	3.37	ray::DefaultActor.run
2906522	1.00	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
ERROR flwr 2024-06-11 03:49:23,984 | ray_client_proxy.py:161 | Traceback (most recent call last):
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 151, in _submit_job
    res, updated_context = self.actor_pool.get_client_result(self.cid, timeout)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 425, in get_client_result
    return self._fetch_future_result(cid)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 306, in _fetch_future_result
    res_cid, res, updated_context = ray.get(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2526, in get
    raise value
ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: baccd8655287851f0509ddef8187bf7d920d56b081f1f711a92be0a1) where the task (actor ID: e30aa655e903fec27a1e5adf03000000, name=DefaultActor.__init__, pid=3822181, memory used=3.46GB) was running was 238.97GB / 251.51GB (0.950139), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 402cb6a22662ca4470a46261055d8e53040d7fd99d074477c9a980df) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-402cb6a22662ca4470a46261055d8e53040d7fd99d074477c9a980df*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
2909640	8.06	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_a...
3822259	5.19	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3822181	3.46	ray::DefaultActor
3839164	3.42	ray::DefaultActor
2906523	0.54	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906522	0.48	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.

ERROR flwr 2024-06-11 03:49:24,006 | ray_client_proxy.py:162 | Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: baccd8655287851f0509ddef8187bf7d920d56b081f1f711a92be0a1) where the task (actor ID: e30aa655e903fec27a1e5adf03000000, name=DefaultActor.__init__, pid=3822181, memory used=3.46GB) was running was 238.97GB / 251.51GB (0.950139), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 402cb6a22662ca4470a46261055d8e53040d7fd99d074477c9a980df) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-402cb6a22662ca4470a46261055d8e53040d7fd99d074477c9a980df*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
2909640	8.06	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_a...
3822259	5.19	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3822181	3.46	ray::DefaultActor
3839164	3.42	ray::DefaultActor
2906523	0.54	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906522	0.48	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
ERROR flwr 2024-06-11 03:49:45,923 | ray_client_proxy.py:161 | Traceback (most recent call last):
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 151, in _submit_job
    res, updated_context = self.actor_pool.get_client_result(self.cid, timeout)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 425, in get_client_result
    return self._fetch_future_result(cid)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 306, in _fetch_future_result
    res_cid, res, updated_context = ray.get(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2526, in get
    raise value
ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: baccd8655287851f0509ddef8187bf7d920d56b081f1f711a92be0a1) where the task (actor ID: e30aa655e903fec27a1e5adf03000000, name=DefaultActor.__init__, pid=3822181, memory used=3.46GB) was running was 238.97GB / 251.51GB (0.950139), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 402cb6a22662ca4470a46261055d8e53040d7fd99d074477c9a980df) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-402cb6a22662ca4470a46261055d8e53040d7fd99d074477c9a980df*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
2909640	8.06	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_a...
3822259	5.19	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3822181	3.46	ray::DefaultActor
3839164	3.42	ray::DefaultActor
2906523	0.54	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906522	0.48	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.

ERROR flwr 2024-06-11 03:49:45,933 | ray_client_proxy.py:162 | Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: baccd8655287851f0509ddef8187bf7d920d56b081f1f711a92be0a1) where the task (actor ID: e30aa655e903fec27a1e5adf03000000, name=DefaultActor.__init__, pid=3822181, memory used=3.46GB) was running was 238.97GB / 251.51GB (0.950139), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 402cb6a22662ca4470a46261055d8e53040d7fd99d074477c9a980df) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-402cb6a22662ca4470a46261055d8e53040d7fd99d074477c9a980df*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
2909640	8.06	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_a...
3822259	5.19	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3822181	3.46	ray::DefaultActor
3839164	3.42	ray::DefaultActor
2906523	0.54	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906522	0.48	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
ERROR flwr 2024-06-11 03:49:54,975 | ray_client_proxy.py:161 | Traceback (most recent call last):
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 151, in _submit_job
    res, updated_context = self.actor_pool.get_client_result(self.cid, timeout)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 425, in get_client_result
    return self._fetch_future_result(cid)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 306, in _fetch_future_result
    res_cid, res, updated_context = ray.get(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2526, in get
    raise value
ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: baccd8655287851f0509ddef8187bf7d920d56b081f1f711a92be0a1) where the task (actor ID: e30aa655e903fec27a1e5adf03000000, name=DefaultActor.__init__, pid=3822181, memory used=3.46GB) was running was 238.97GB / 251.51GB (0.950139), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 402cb6a22662ca4470a46261055d8e53040d7fd99d074477c9a980df) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-402cb6a22662ca4470a46261055d8e53040d7fd99d074477c9a980df*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
2909640	8.06	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_a...
3822259	5.19	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3822181	3.46	ray::DefaultActor
3839164	3.42	ray::DefaultActor
2906523	0.54	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906522	0.48	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.

ERROR flwr 2024-06-11 03:49:54,976 | ray_client_proxy.py:162 | Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: baccd8655287851f0509ddef8187bf7d920d56b081f1f711a92be0a1) where the task (actor ID: e30aa655e903fec27a1e5adf03000000, name=DefaultActor.__init__, pid=3822181, memory used=3.46GB) was running was 238.97GB / 251.51GB (0.950139), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 402cb6a22662ca4470a46261055d8e53040d7fd99d074477c9a980df) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-402cb6a22662ca4470a46261055d8e53040d7fd99d074477c9a980df*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
2909640	8.06	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_a...
3822259	5.19	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3822181	3.46	ray::DefaultActor
3839164	3.42	ray::DefaultActor
2906523	0.54	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906522	0.48	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
ERROR flwr 2024-06-11 03:49:54,976 | ray_client_proxy.py:161 | Traceback (most recent call last):
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 151, in _submit_job
    res, updated_context = self.actor_pool.get_client_result(self.cid, timeout)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 425, in get_client_result
    return self._fetch_future_result(cid)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 306, in _fetch_future_result
    res_cid, res, updated_context = ray.get(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2526, in get
    raise value
ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13) where the task (actor ID: 86b0d854d81e2e02d453023703000000, name=DefaultActor.__init__, pid=3822180, memory used=3.37GB) was running was 238.96GB / 251.51GB (0.950083), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
2909640	8.45	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_a...
3822259	3.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3822181	3.43	ray::DefaultActor
3822180	3.37	ray::DefaultActor.run
2906522	1.00	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.

ERROR flwr 2024-06-11 03:49:54,977 | ray_client_proxy.py:162 | Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13) where the task (actor ID: 86b0d854d81e2e02d453023703000000, name=DefaultActor.__init__, pid=3822180, memory used=3.37GB) was running was 238.96GB / 251.51GB (0.950083), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
2909640	8.45	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_a...
3822259	3.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3822181	3.43	ray::DefaultActor
3822180	3.37	ray::DefaultActor.run
2906522	1.00	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
ERROR flwr 2024-06-11 03:49:54,978 | ray_client_proxy.py:161 | Traceback (most recent call last):
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 151, in _submit_job
    res, updated_context = self.actor_pool.get_client_result(self.cid, timeout)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 425, in get_client_result
    return self._fetch_future_result(cid)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 306, in _fetch_future_result
    res_cid, res, updated_context = ray.get(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2526, in get
    raise value
ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13) where the task (actor ID: 86b0d854d81e2e02d453023703000000, name=DefaultActor.__init__, pid=3822180, memory used=3.37GB) was running was 238.96GB / 251.51GB (0.950083), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
2909640	8.45	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_a...
3822259	3.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3822181	3.43	ray::DefaultActor
3822180	3.37	ray::DefaultActor.run
2906522	1.00	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.

ERROR flwr 2024-06-11 03:49:54,979 | ray_client_proxy.py:161 | Traceback (most recent call last):
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 151, in _submit_job
    res, updated_context = self.actor_pool.get_client_result(self.cid, timeout)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 425, in get_client_result
    return self._fetch_future_result(cid)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 306, in _fetch_future_result
    res_cid, res, updated_context = ray.get(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2526, in get
    raise value
ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13) where the task (actor ID: 86b0d854d81e2e02d453023703000000, name=DefaultActor.__init__, pid=3822180, memory used=3.37GB) was running was 238.96GB / 251.51GB (0.950083), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
2909640	8.45	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_a...
3822259	3.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3822181	3.43	ray::DefaultActor
3822180	3.37	ray::DefaultActor.run
2906522	1.00	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.

ERROR flwr 2024-06-11 03:49:54,980 | ray_client_proxy.py:162 | Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13) where the task (actor ID: 86b0d854d81e2e02d453023703000000, name=DefaultActor.__init__, pid=3822180, memory used=3.37GB) was running was 238.96GB / 251.51GB (0.950083), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
2909640	8.45	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_a...
3822259	3.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3822181	3.43	ray::DefaultActor
3822180	3.37	ray::DefaultActor.run
2906522	1.00	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
ERROR flwr 2024-06-11 03:49:54,979 | ray_client_proxy.py:162 | Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13) where the task (actor ID: 86b0d854d81e2e02d453023703000000, name=DefaultActor.__init__, pid=3822180, memory used=3.37GB) was running was 238.96GB / 251.51GB (0.950083), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-de1addd228db016a16ea0aa1ea019a03dbd38652337723201a816351*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
2909640	8.45	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_a...
3822259	3.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3822181	3.43	ray::DefaultActor
3822180	3.37	ray::DefaultActor.run
2906522	1.00	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
ERROR flwr 2024-06-11 03:49:54,979 | ray_client_proxy.py:161 | Traceback (most recent call last):
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 151, in _submit_job
    res, updated_context = self.actor_pool.get_client_result(self.cid, timeout)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 425, in get_client_result
    return self._fetch_future_result(cid)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 306, in _fetch_future_result
    res_cid, res, updated_context = ray.get(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2526, in get
    raise value
ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: baccd8655287851f0509ddef8187bf7d920d56b081f1f711a92be0a1) where the task (actor ID: e30aa655e903fec27a1e5adf03000000, name=DefaultActor.__init__, pid=3822181, memory used=3.46GB) was running was 238.97GB / 251.51GB (0.950139), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 402cb6a22662ca4470a46261055d8e53040d7fd99d074477c9a980df) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-402cb6a22662ca4470a46261055d8e53040d7fd99d074477c9a980df*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
2909640	8.06	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_a...
3822259	5.19	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3822181	3.46	ray::DefaultActor
3839164	3.42	ray::DefaultActor
2906523	0.54	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906522	0.48	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.

ERROR flwr 2024-06-11 03:49:54,980 | ray_client_proxy.py:162 | Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: baccd8655287851f0509ddef8187bf7d920d56b081f1f711a92be0a1) where the task (actor ID: e30aa655e903fec27a1e5adf03000000, name=DefaultActor.__init__, pid=3822181, memory used=3.46GB) was running was 238.97GB / 251.51GB (0.950139), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 402cb6a22662ca4470a46261055d8e53040d7fd99d074477c9a980df) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-402cb6a22662ca4470a46261055d8e53040d7fd99d074477c9a980df*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
2909640	8.06	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_a...
3822259	5.19	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3822181	3.46	ray::DefaultActor
3839164	3.42	ray::DefaultActor
2906523	0.54	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906522	0.48	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
DEBUG flwr 2024-06-11 03:49:55,024 | server.py:236 | fit_round 5 received 0 results and 10 failures
ERROR flwr 2024-06-11 03:49:55,048 | app.py:313 | 'NoneType' object has no attribute 'tensors'
ERROR flwr 2024-06-11 03:49:55,104 | app.py:314 | Traceback (most recent call last):
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/app.py", line 308, in start_simulation
    hist = run_fl(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/server/app.py", line 225, in run_fl
    hist = server.fit(num_rounds=config.num_rounds, timeout=config.round_timeout)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/server/server.py", line 109, in fit
    res_fit = self.fit_round(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/server/server.py", line 248, in fit_round
    ] = self.strategy.aggregate_fit(server_round, results, failures)
  File "/home/s2240084/conFEDential/src/training/Server.py", line 78, in aggregate_fit
    self._capture_results(server_round, results, aggregated_parameters, config)
  File "/home/s2240084/conFEDential/src/training/Server.py", line 98, in _capture_results
    self._capture_aggregates(server_round, aggregated_parameters, metrics)
  File "/home/s2240084/conFEDential/src/training/Server.py", line 124, in _capture_aggregates
    aggregated_parameters = parameters_to_ndarrays(aggregated_parameters)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/common/parameter.py", line 34, in parameters_to_ndarrays
    return [bytes_to_ndarray(tensor) for tensor in parameters.tensors]
AttributeError: 'NoneType' object has no attribute 'tensors'

ERROR flwr 2024-06-11 03:49:55,105 | app.py:315 | Your simulation crashed :(. This could be because of several reasons. The most common are: 
	 > Sometimes, issues in the simulation code itself can cause crashes. It's always a good idea to double-check your code for any potential bugs or inconsistencies that might be contributing to the problem. For example: 
		 - You might be using a class attribute in your clients that hasn't been defined.
		 - There could be an incorrect method call to a 3rd party library (e.g., PyTorch).
		 - The return types of methods in your clients/strategies might be incorrect.
	 > Your system couldn't fit a single VirtualClient: try lowering `client_resources`.
	 > All the actors in your pool crashed. This could be because: 
		 - You clients hit an out-of-memory (OOM) error and actors couldn't recover from it. Try launching your simulation with more generous `client_resources` setting (i.e. it seems {'num_cpus': 2, 'num_gpus': 1.0, 'memory': 17179869184} is not enough for your run). Use fewer concurrent actors. 
		 - You were running a multi-node simulation and all worker nodes disconnected. The head node might still be alive but cannot accommodate any actor with resources: {'num_cpus': 2, 'num_gpus': 1.0, 'memory': 17179869184}.
Take a look at the Flower simulation examples for guidance <https://flower.dev/docs/framework/how-to-run-simulations.html>.
ERROR flwr 2024-06-11 03:49:55,107 | Simulation.py:185 | Simulation crashed.
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.0269
wandb:     loss 4.60558
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240610_162700-9c3e4ukb
wandb: Find logs at: ./wandb/offline-run-20240610_162700-9c3e4ukb/logs
[2m[36m(pid=3822180)[0m 2024-06-11 03:26:46.750311: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[1m[33m(autoscaler +11h17m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h17m57s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h18m31s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h19m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h19m8s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h19m47s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h19m48s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h20m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h20m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11h21m1s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
2024-06-11 03:51:03.863435: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-06-11 03:51:04.048657: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-06-11 03:51:06.113808: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
INFO flwr 2024-06-11 03:51:14,363 | Data.py:36 | Preprocessing the federated learning dataset
INFO flwr 2024-06-11 03:51:14,446 | Data.py:111 | Found preprocessed data for the given preprocess function with hash efddb1ca4fe67eba076ca51cfd1766212af1fce46847913eececd421a82a7a21, returning
INFO flwr 2024-06-11 03:51:15,751 | Simulation.py:37 | Preparing datasets for federated learning simulation
INFO flwr 2024-06-11 03:51:15,771 | Simulation.py:266 | Found previously split dataloaders with hash bd65c6a03831e38c587d483e1fe6a818e6bdcb912c586e58c4dda52c558b4a79, loading them
INFO flwr 2024-06-11 03:51:25,492 | main.py:110 | Loaded 1 configs with name CIFAR100-RESNET34-FEDNAG, running...
INFO flwr 2024-06-11 03:51:25,496 | main.py:112 | Config:
	Simulation:
		Data:
			dataset_name: cifar100
			batch_size: 64
			preprocess_fn:
				def preprocess_fn(element):
				  return {
				    "x": element["img"],
				    "y": element["fine_label"]
				  }
		Federation:
			client_count: 100
			fraction_fit: 0.1
			global_rounds: 300
			local_rounds: 4
		Model:
			optimizer_name: FedNag
			model_name: ResNet34
			criterion_name: CrossEntropyLoss
			optimizer_parameters: 
				lr: 0.01
				momentum: 0.9
			model_architecture:
				repo_or_dir: pytorch/vision:v0.10.0
					model: resnet34
					pretrained: False
					out_features: 100
	Attack:
		data_access: 1.0
		message_access: server
		repetitions: 0
		Attack Simulation:
			batch_size: 64
			optimizer_name: Adam
			optimizer_parameters:
				lr: 0.0001
			ModelArchitecture:
				gradient_component:
					type: Dropout
						p: 0.2
					type: Conv2d
						out_channels: 1000
						kernel_size: None
						stride: 1
					type: ReLU
				fcn_component:
					type: Dropout
						p: 0.2
					type: Linear
						out_features: 128
					type: ReLU
					type: Dropout
						p: 0.2
					type: Linear
						in_features: 128
						out_features: 64
					type: ReLU
				encoder_component:
					type: Dropout
						p: 0.2
					type: Linear
						out_features: 256
					type: ReLU
					type: Dropout
						p: 0.2
					type: Linear
						in_features: 256
						out_features: 128
					type: ReLU
					type: Dropout
						p: 0.2
					type: Linear
						in_features: 128
						out_features: 64
					type: ReLU
					type: Dropout
						p: 0.2
					type: Linear
						in_features: 64
						out_features: 1
					type: ReLU
					type: Sigmoid
INFO flwr 2024-06-11 03:51:25,508 | Config.py:67 | Starting conFEDential simulation
INFO flwr 2024-06-11 03:51:25,558 | Config.py:72 | No previous federated learning simulation found with hash d3453dc869cf16ea7829424fbda52f8fff1d34cb0ed8efbc8926106d89775e3f, starting training simulation...
wandb: Tracking run with wandb version 0.16.5
wandb: W&B syncing is set to `offline` in this directory.  
wandb: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
INFO flwr 2024-06-11 03:51:27,393 | Simulation.py:406 | Created 1 clients with resources 2 CPUs, 1.0 GPUs, and 16.0GB for the total available 2 CPUs, 1 GPUs and 16.0GB.
INFO flwr 2024-06-11 03:51:27,393 | Simulation.py:161 | Starting federated learning simulation
2024-06-11 03:51:27,449	INFO worker.py:1431 -- Connecting to existing Ray cluster at address: 10.20.240.18:6379...
2024-06-11 03:51:27,472	INFO worker.py:1621 -- Connected to Ray cluster.
INFO flwr 2024-06-11 03:51:27,490 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=300, round_timeout=None)
2024-06-11 03:51:27,569	INFO worker.py:1453 -- Calling ray.init() again after it has already been called.
INFO flwr 2024-06-11 03:51:27,570 | app.py:213 | Flower VCE: Ray initialized with resources: {'GPU': 2.0, 'accelerator_type:G': 2.0, 'object_store_memory': 36316086681.0, 'node:10.20.240.18': 2.0, 'CPU': 4.0, 'node:__internal_head__': 2.0, 'memory': 34359738368.0}
INFO flwr 2024-06-11 03:51:27,570 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html
INFO flwr 2024-06-11 03:51:27,571 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 2, 'num_gpus': 1.0, 'memory': 17179869184}
INFO flwr 2024-06-11 03:51:27,586 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 2 actors
INFO flwr 2024-06-11 03:51:27,587 | server.py:89 | Initializing global parameters
INFO flwr 2024-06-11 03:51:27,588 | server.py:272 | Using initial parameters provided by strategy
INFO flwr 2024-06-11 03:51:27,588 | server.py:91 | Evaluating initial parameters
INFO flwr 2024-06-11 03:51:29,870 | server.py:94 | initial parameters (loss, other metrics): 5.040051953125, {'accuracy': 0.0116, 'data_size': 10000}
INFO flwr 2024-06-11 03:51:29,871 | server.py:104 | FL starting
DEBUG flwr 2024-06-11 03:51:29,872 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 100)
[2m[36m(pid=3846027)[0m 2024-06-11 03:51:31.157061: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
[2m[36m(pid=3846027)[0m 2024-06-11 03:51:34.955107: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[2m[1m[36m(autoscaler +31s)[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.
[2m[1m[33m(autoscaler +31s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +32s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1m11s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1m13s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1m51s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +1m53s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2m26s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +2m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3m1s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3m3s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3m41s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +3m43s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4m22s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +4m56s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5m13s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5m32s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +5m48s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6m23s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6m42s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +6m58s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7m33s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +7m52s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8m13s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +8m32s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[33m(raylet)[0m [2024-06-11 04:02:57,549 E 2906522 2906522] (raylet) node_manager.cc:3084: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13, IP: 10.20.240.18) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.20.240.18`
[2m[33m(raylet)[0m 
[2m[33m(raylet)[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
[2m[33m(raylet)[0m [2024-06-11 04:02:57,973 E 2906523 2906523] (raylet) node_manager.cc:3084: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: baccd8655287851f0509ddef8187bf7d920d56b081f1f711a92be0a1, IP: 10.20.240.18) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.20.240.18`
[2m[33m(raylet)[0m 
[2m[33m(raylet)[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
[2m[36m(pid=3858367)[0m 2024-06-11 04:03:08.595992: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
[2m[36m(pid=3858367)[0m 2024-06-11 04:03:16.443806: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
[2m[36m(pid=3858367)[0m To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
[2m[36m(pid=3858367)[0m 2024-06-11 04:04:01.352635: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
DEBUG flwr 2024-06-11 04:06:47,913 | server.py:236 | fit_round 1 received 10 results and 0 failures
[2m[1m[33m(autoscaler +8m48s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9m7s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9m23s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9m42s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +9m59s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10m17s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10m34s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +10m52s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11m9s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +11m27s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +17m3s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +17m4s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +17m38s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +17m39s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +18m13s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +18m14s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +18m53s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +18m55s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +19m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +19m30s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +20m3s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +20m5s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +20m43s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +20m45s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +21m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +21m21s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +21m53s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
INFO flwr 2024-06-11 04:16:37,110 | server.py:125 | fit progress: (1, 4.748258984375, {'accuracy': 0.0132, 'data_size': 10000}, 1507.2388901975937)
INFO flwr 2024-06-11 04:16:37,111 | server.py:171 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2024-06-11 04:16:37,112 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 100)
ERROR flwr 2024-06-11 04:17:33,182 | ray_client_proxy.py:161 | Traceback (most recent call last):
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 151, in _submit_job
    res, updated_context = self.actor_pool.get_client_result(self.cid, timeout)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 425, in get_client_result
    return self._fetch_future_result(cid)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 306, in _fetch_future_result
    res_cid, res, updated_context = ray.get(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2526, in get
    raise value
ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13) where the task (actor ID: 651bbd98d559a3ada79c486c05000000, name=DefaultActor.__init__, pid=3858367, memory used=3.28GB) was running was 238.97GB / 251.51GB (0.950124), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: e686884549f13b359f600f64a94f9ce6ce8fc9754ed3943ce33469f3) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-e686884549f13b359f600f64a94f9ce6ce8fc9754ed3943ce33469f3*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
3845950	8.27	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_n...
3863186	3.63	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_na...
3858367	3.28	ray::DefaultActor.run
3864250	3.22	
2906523	0.86	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906522	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.39	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.

ERROR flwr 2024-06-11 04:17:33,182 | ray_client_proxy.py:162 | Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13) where the task (actor ID: 651bbd98d559a3ada79c486c05000000, name=DefaultActor.__init__, pid=3858367, memory used=3.28GB) was running was 238.97GB / 251.51GB (0.950124), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: e686884549f13b359f600f64a94f9ce6ce8fc9754ed3943ce33469f3) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-e686884549f13b359f600f64a94f9ce6ce8fc9754ed3943ce33469f3*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
3845950	8.27	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_n...
3863186	3.63	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_na...
3858367	3.28	ray::DefaultActor.run
3864250	3.22	
2906523	0.86	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906522	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.39	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
ERROR flwr 2024-06-11 04:17:33,184 | ray_client_proxy.py:161 | Traceback (most recent call last):
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 151, in _submit_job
    res, updated_context = self.actor_pool.get_client_result(self.cid, timeout)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 425, in get_client_result
    return self._fetch_future_result(cid)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 306, in _fetch_future_result
    res_cid, res, updated_context = ray.get(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2526, in get
    raise value
ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: baccd8655287851f0509ddef8187bf7d920d56b081f1f711a92be0a1) where the task (actor ID: 2c4dead682da3514ae9fb09105000000, name=DefaultActor.__init__, pid=3846027, memory used=3.34GB) was running was 238.95GB / 251.51GB (0.950057), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 1596c551f53876d974ac82926abe611519a2c3bb9d62821d4cf06630) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-1596c551f53876d974ac82926abe611519a2c3bb9d62821d4cf06630*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
3822259	7.05	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3845950	4.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_n...
3846027	3.34	ray::DefaultActor
3843263	3.21	ray::DefaultActor
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906522	0.36	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.

ERROR flwr 2024-06-11 04:17:33,205 | ray_client_proxy.py:162 | Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: baccd8655287851f0509ddef8187bf7d920d56b081f1f711a92be0a1) where the task (actor ID: 2c4dead682da3514ae9fb09105000000, name=DefaultActor.__init__, pid=3846027, memory used=3.34GB) was running was 238.95GB / 251.51GB (0.950057), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 1596c551f53876d974ac82926abe611519a2c3bb9d62821d4cf06630) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-1596c551f53876d974ac82926abe611519a2c3bb9d62821d4cf06630*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
3822259	7.05	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3845950	4.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_n...
3846027	3.34	ray::DefaultActor
3843263	3.21	ray::DefaultActor
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906522	0.36	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
ERROR flwr 2024-06-11 04:17:33,195 | ray_client_proxy.py:161 | Traceback (most recent call last):
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 151, in _submit_job
    res, updated_context = self.actor_pool.get_client_result(self.cid, timeout)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 425, in get_client_result
    return self._fetch_future_result(cid)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 306, in _fetch_future_result
    res_cid, res, updated_context = ray.get(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2526, in get
    raise value
ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: baccd8655287851f0509ddef8187bf7d920d56b081f1f711a92be0a1) where the task (actor ID: 2c4dead682da3514ae9fb09105000000, name=DefaultActor.__init__, pid=3846027, memory used=3.34GB) was running was 238.95GB / 251.51GB (0.950057), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 1596c551f53876d974ac82926abe611519a2c3bb9d62821d4cf06630) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-1596c551f53876d974ac82926abe611519a2c3bb9d62821d4cf06630*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
3822259	7.05	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3845950	4.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_n...
3846027	3.34	ray::DefaultActor
3843263	3.21	ray::DefaultActor
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906522	0.36	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.

ERROR flwr 2024-06-11 04:17:33,206 | ray_client_proxy.py:162 | Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: baccd8655287851f0509ddef8187bf7d920d56b081f1f711a92be0a1) where the task (actor ID: 2c4dead682da3514ae9fb09105000000, name=DefaultActor.__init__, pid=3846027, memory used=3.34GB) was running was 238.95GB / 251.51GB (0.950057), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 1596c551f53876d974ac82926abe611519a2c3bb9d62821d4cf06630) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-1596c551f53876d974ac82926abe611519a2c3bb9d62821d4cf06630*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
3822259	7.05	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3845950	4.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_n...
3846027	3.34	ray::DefaultActor
3843263	3.21	ray::DefaultActor
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906522	0.36	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
ERROR flwr 2024-06-11 04:17:43,438 | ray_client_proxy.py:161 | Traceback (most recent call last):
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 151, in _submit_job
    res, updated_context = self.actor_pool.get_client_result(self.cid, timeout)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 425, in get_client_result
    return self._fetch_future_result(cid)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 306, in _fetch_future_result
    res_cid, res, updated_context = ray.get(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2526, in get
    raise value
ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: baccd8655287851f0509ddef8187bf7d920d56b081f1f711a92be0a1) where the task (actor ID: 2c4dead682da3514ae9fb09105000000, name=DefaultActor.__init__, pid=3846027, memory used=3.34GB) was running was 238.95GB / 251.51GB (0.950057), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 1596c551f53876d974ac82926abe611519a2c3bb9d62821d4cf06630) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-1596c551f53876d974ac82926abe611519a2c3bb9d62821d4cf06630*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
3822259	7.05	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3845950	4.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_n...
3846027	3.34	ray::DefaultActor
3843263	3.21	ray::DefaultActor
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906522	0.36	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.

ERROR flwr 2024-06-11 04:17:43,455 | ray_client_proxy.py:162 | Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: baccd8655287851f0509ddef8187bf7d920d56b081f1f711a92be0a1) where the task (actor ID: 2c4dead682da3514ae9fb09105000000, name=DefaultActor.__init__, pid=3846027, memory used=3.34GB) was running was 238.95GB / 251.51GB (0.950057), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 1596c551f53876d974ac82926abe611519a2c3bb9d62821d4cf06630) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-1596c551f53876d974ac82926abe611519a2c3bb9d62821d4cf06630*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
3822259	7.05	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3845950	4.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_n...
3846027	3.34	ray::DefaultActor
3843263	3.21	ray::DefaultActor
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906522	0.36	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
[2m[33m(raylet)[0m [2024-06-11 04:17:57,567 E 2906522 2906522] (raylet) node_manager.cc:3084: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13, IP: 10.20.240.18) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.20.240.18`
[2m[33m(raylet)[0m 
[2m[33m(raylet)[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
[2m[33m(raylet)[0m [2024-06-11 04:17:57,995 E 2906523 2906523] (raylet) node_manager.cc:3084: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: baccd8655287851f0509ddef8187bf7d920d56b081f1f711a92be0a1, IP: 10.20.240.18) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.20.240.18`
[2m[33m(raylet)[0m 
[2m[33m(raylet)[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
ERROR flwr 2024-06-11 04:18:03,851 | ray_client_proxy.py:161 | Traceback (most recent call last):
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 151, in _submit_job
    res, updated_context = self.actor_pool.get_client_result(self.cid, timeout)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 425, in get_client_result
    return self._fetch_future_result(cid)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 306, in _fetch_future_result
    res_cid, res, updated_context = ray.get(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2526, in get
    raise value
ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13) where the task (actor ID: 651bbd98d559a3ada79c486c05000000, name=DefaultActor.__init__, pid=3858367, memory used=3.28GB) was running was 238.97GB / 251.51GB (0.950124), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: e686884549f13b359f600f64a94f9ce6ce8fc9754ed3943ce33469f3) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-e686884549f13b359f600f64a94f9ce6ce8fc9754ed3943ce33469f3*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
3845950	8.27	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_n...
3863186	3.63	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_na...
3858367	3.28	ray::DefaultActor.run
3864250	3.22	
2906523	0.86	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906522	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.39	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.

ERROR flwr 2024-06-11 04:18:03,852 | ray_client_proxy.py:162 | Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13) where the task (actor ID: 651bbd98d559a3ada79c486c05000000, name=DefaultActor.__init__, pid=3858367, memory used=3.28GB) was running was 238.97GB / 251.51GB (0.950124), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: e686884549f13b359f600f64a94f9ce6ce8fc9754ed3943ce33469f3) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-e686884549f13b359f600f64a94f9ce6ce8fc9754ed3943ce33469f3*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
3845950	8.27	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_n...
3863186	3.63	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_na...
3858367	3.28	ray::DefaultActor.run
3864250	3.22	
2906523	0.86	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906522	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.39	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
ERROR flwr 2024-06-11 04:18:14,519 | ray_client_proxy.py:161 | Traceback (most recent call last):
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 151, in _submit_job
    res, updated_context = self.actor_pool.get_client_result(self.cid, timeout)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 425, in get_client_result
    return self._fetch_future_result(cid)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 306, in _fetch_future_result
    res_cid, res, updated_context = ray.get(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2526, in get
    raise value
ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: baccd8655287851f0509ddef8187bf7d920d56b081f1f711a92be0a1) where the task (actor ID: 2c4dead682da3514ae9fb09105000000, name=DefaultActor.__init__, pid=3846027, memory used=3.34GB) was running was 238.95GB / 251.51GB (0.950057), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 1596c551f53876d974ac82926abe611519a2c3bb9d62821d4cf06630) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-1596c551f53876d974ac82926abe611519a2c3bb9d62821d4cf06630*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
3822259	7.05	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3845950	4.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_n...
3846027	3.34	ray::DefaultActor
3843263	3.21	ray::DefaultActor
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906522	0.36	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.

ERROR flwr 2024-06-11 04:18:14,525 | ray_client_proxy.py:161 | Traceback (most recent call last):
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 151, in _submit_job
    res, updated_context = self.actor_pool.get_client_result(self.cid, timeout)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 425, in get_client_result
    return self._fetch_future_result(cid)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 306, in _fetch_future_result
    res_cid, res, updated_context = ray.get(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2526, in get
    raise value
ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: baccd8655287851f0509ddef8187bf7d920d56b081f1f711a92be0a1) where the task (actor ID: 2c4dead682da3514ae9fb09105000000, name=DefaultActor.__init__, pid=3846027, memory used=3.34GB) was running was 238.95GB / 251.51GB (0.950057), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 1596c551f53876d974ac82926abe611519a2c3bb9d62821d4cf06630) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-1596c551f53876d974ac82926abe611519a2c3bb9d62821d4cf06630*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
3822259	7.05	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3845950	4.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_n...
3846027	3.34	ray::DefaultActor
3843263	3.21	ray::DefaultActor
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906522	0.36	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.

ERROR flwr 2024-06-11 04:18:14,540 | ray_client_proxy.py:162 | Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: baccd8655287851f0509ddef8187bf7d920d56b081f1f711a92be0a1) where the task (actor ID: 2c4dead682da3514ae9fb09105000000, name=DefaultActor.__init__, pid=3846027, memory used=3.34GB) was running was 238.95GB / 251.51GB (0.950057), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 1596c551f53876d974ac82926abe611519a2c3bb9d62821d4cf06630) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-1596c551f53876d974ac82926abe611519a2c3bb9d62821d4cf06630*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
3822259	7.05	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3845950	4.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_n...
3846027	3.34	ray::DefaultActor
3843263	3.21	ray::DefaultActor
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906522	0.36	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
ERROR flwr 2024-06-11 04:18:14,561 | ray_client_proxy.py:162 | Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: baccd8655287851f0509ddef8187bf7d920d56b081f1f711a92be0a1) where the task (actor ID: 2c4dead682da3514ae9fb09105000000, name=DefaultActor.__init__, pid=3846027, memory used=3.34GB) was running was 238.95GB / 251.51GB (0.950057), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 1596c551f53876d974ac82926abe611519a2c3bb9d62821d4cf06630) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-1596c551f53876d974ac82926abe611519a2c3bb9d62821d4cf06630*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
3822259	7.05	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3845950	4.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_n...
3846027	3.34	ray::DefaultActor
3843263	3.21	ray::DefaultActor
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906522	0.36	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
ERROR flwr 2024-06-11 04:18:24,202 | ray_client_proxy.py:161 | Traceback (most recent call last):
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 151, in _submit_job
    res, updated_context = self.actor_pool.get_client_result(self.cid, timeout)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 425, in get_client_result
    return self._fetch_future_result(cid)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 306, in _fetch_future_result
    res_cid, res, updated_context = ray.get(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2526, in get
    raise value
ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13) where the task (actor ID: 651bbd98d559a3ada79c486c05000000, name=DefaultActor.__init__, pid=3858367, memory used=3.28GB) was running was 238.97GB / 251.51GB (0.950124), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: e686884549f13b359f600f64a94f9ce6ce8fc9754ed3943ce33469f3) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-e686884549f13b359f600f64a94f9ce6ce8fc9754ed3943ce33469f3*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
3845950	8.27	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_n...
3863186	3.63	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_na...
3858367	3.28	ray::DefaultActor.run
3864250	3.22	
2906523	0.86	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906522	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.39	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.

ERROR flwr 2024-06-11 04:18:24,202 | ray_client_proxy.py:162 | Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13) where the task (actor ID: 651bbd98d559a3ada79c486c05000000, name=DefaultActor.__init__, pid=3858367, memory used=3.28GB) was running was 238.97GB / 251.51GB (0.950124), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: e686884549f13b359f600f64a94f9ce6ce8fc9754ed3943ce33469f3) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-e686884549f13b359f600f64a94f9ce6ce8fc9754ed3943ce33469f3*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
3845950	8.27	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_n...
3863186	3.63	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_na...
3858367	3.28	ray::DefaultActor.run
3864250	3.22	
2906523	0.86	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906522	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.39	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
ERROR flwr 2024-06-11 04:18:24,203 | ray_client_proxy.py:161 | Traceback (most recent call last):
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 151, in _submit_job
    res, updated_context = self.actor_pool.get_client_result(self.cid, timeout)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 425, in get_client_result
    return self._fetch_future_result(cid)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 306, in _fetch_future_result
    res_cid, res, updated_context = ray.get(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2526, in get
    raise value
ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: baccd8655287851f0509ddef8187bf7d920d56b081f1f711a92be0a1) where the task (actor ID: 2c4dead682da3514ae9fb09105000000, name=DefaultActor.__init__, pid=3846027, memory used=3.34GB) was running was 238.95GB / 251.51GB (0.950057), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 1596c551f53876d974ac82926abe611519a2c3bb9d62821d4cf06630) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-1596c551f53876d974ac82926abe611519a2c3bb9d62821d4cf06630*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
3822259	7.05	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3845950	4.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_n...
3846027	3.34	ray::DefaultActor
3843263	3.21	ray::DefaultActor
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906522	0.36	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.

ERROR flwr 2024-06-11 04:18:24,204 | ray_client_proxy.py:162 | Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: baccd8655287851f0509ddef8187bf7d920d56b081f1f711a92be0a1) where the task (actor ID: 2c4dead682da3514ae9fb09105000000, name=DefaultActor.__init__, pid=3846027, memory used=3.34GB) was running was 238.95GB / 251.51GB (0.950057), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 1596c551f53876d974ac82926abe611519a2c3bb9d62821d4cf06630) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-1596c551f53876d974ac82926abe611519a2c3bb9d62821d4cf06630*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
3822259	7.05	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_av...
3845950	4.70	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_n...
3846027	3.34	ray::DefaultActor
3843263	3.21	ray::DefaultActor
2906523	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.38	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906522	0.36	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
ERROR flwr 2024-06-11 04:18:24,205 | ray_client_proxy.py:161 | Traceback (most recent call last):
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py", line 151, in _submit_job
    res, updated_context = self.actor_pool.get_client_result(self.cid, timeout)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 425, in get_client_result
    return self._fetch_future_result(cid)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/ray_transport/ray_actor.py", line 306, in _fetch_future_result
    res_cid, res, updated_context = ray.get(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/worker.py", line 2526, in get
    raise value
ray.exceptions.OutOfMemoryError: Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13) where the task (actor ID: 651bbd98d559a3ada79c486c05000000, name=DefaultActor.__init__, pid=3858367, memory used=3.28GB) was running was 238.97GB / 251.51GB (0.950124), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: e686884549f13b359f600f64a94f9ce6ce8fc9754ed3943ce33469f3) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-e686884549f13b359f600f64a94f9ce6ce8fc9754ed3943ce33469f3*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
3845950	8.27	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_n...
3863186	3.63	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_na...
3858367	3.28	ray::DefaultActor.run
3864250	3.22	
2906523	0.86	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906522	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.39	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.

ERROR flwr 2024-06-11 04:18:24,205 | ray_client_proxy.py:162 | Task was killed due to the node running low on memory.
Memory on the node (IP: 10.20.240.18, ID: 8040f2f6f337106e2bafe961461b06a0a32795d404c6a86ba721fb13) where the task (actor ID: 651bbd98d559a3ada79c486c05000000, name=DefaultActor.__init__, pid=3858367, memory used=3.28GB) was running was 238.97GB / 251.51GB (0.950124), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: e686884549f13b359f600f64a94f9ce6ce8fc9754ed3943ce33469f3) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.20.240.18`. To see the logs of the worker, use `ray logs worker-e686884549f13b359f600f64a94f9ce6ce8fc9754ed3943ce33469f3*out -ip 10.20.240.18. Top 10 memory users:
PID	MEM(GB)	COMMAND
3845950	8.27	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar100/resnet34/fed_n...
3863186	3.63	/home/s2240084/conFEDential/venv/bin/python src/main.py --yaml-file examples/cifar10/resnet18/fed_na...
3858367	3.28	ray::DefaultActor.run
3864250	3.22	
2906523	0.86	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2906522	0.53	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --rayle...
2905333	0.39	/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_...
2906612	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2906615	0.06	/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-...
2905909	0.06	/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-pac...
Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
DEBUG flwr 2024-06-11 04:18:24,259 | server.py:236 | fit_round 2 received 0 results and 10 failures
ERROR flwr 2024-06-11 04:18:24,279 | app.py:313 | 'NoneType' object has no attribute 'tensors'
ERROR flwr 2024-06-11 04:18:24,286 | app.py:314 | Traceback (most recent call last):
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/simulation/app.py", line 308, in start_simulation
    hist = run_fl(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/server/app.py", line 225, in run_fl
    hist = server.fit(num_rounds=config.num_rounds, timeout=config.round_timeout)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/server/server.py", line 109, in fit
    res_fit = self.fit_round(
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/server/server.py", line 248, in fit_round
    ] = self.strategy.aggregate_fit(server_round, results, failures)
  File "/home/s2240084/conFEDential/src/training/Server.py", line 78, in aggregate_fit
    self._capture_results(server_round, results, aggregated_parameters, config)
  File "/home/s2240084/conFEDential/src/training/Server.py", line 98, in _capture_results
    self._capture_aggregates(server_round, aggregated_parameters, metrics)
  File "/home/s2240084/conFEDential/src/training/Server.py", line 124, in _capture_aggregates
    aggregated_parameters = parameters_to_ndarrays(aggregated_parameters)
  File "/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/flwr/common/parameter.py", line 34, in parameters_to_ndarrays
    return [bytes_to_ndarray(tensor) for tensor in parameters.tensors]
AttributeError: 'NoneType' object has no attribute 'tensors'

ERROR flwr 2024-06-11 04:18:24,287 | app.py:315 | Your simulation crashed :(. This could be because of several reasons. The most common are: 
	 > Sometimes, issues in the simulation code itself can cause crashes. It's always a good idea to double-check your code for any potential bugs or inconsistencies that might be contributing to the problem. For example: 
		 - You might be using a class attribute in your clients that hasn't been defined.
		 - There could be an incorrect method call to a 3rd party library (e.g., PyTorch).
		 - The return types of methods in your clients/strategies might be incorrect.
	 > Your system couldn't fit a single VirtualClient: try lowering `client_resources`.
	 > All the actors in your pool crashed. This could be because: 
		 - You clients hit an out-of-memory (OOM) error and actors couldn't recover from it. Try launching your simulation with more generous `client_resources` setting (i.e. it seems {'num_cpus': 2, 'num_gpus': 1.0, 'memory': 17179869184} is not enough for your run). Use fewer concurrent actors. 
		 - You were running a multi-node simulation and all worker nodes disconnected. The head node might still be alive but cannot accommodate any actor with resources: {'num_cpus': 2, 'num_gpus': 1.0, 'memory': 17179869184}.
Take a look at the Flower simulation examples for guidance <https://flower.dev/docs/framework/how-to-run-simulations.html>.
ERROR flwr 2024-06-11 04:18:24,288 | Simulation.py:185 | Simulation crashed.
wandb: - 0.000 MB of 0.000 MB uploadedwandb:                                                                                
wandb: 
wandb: Run summary:
wandb: accuracy 0.0132
wandb:     loss 4.74826
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /home/s2240084/conFEDential/wandb/offline-run-20240611_035126-r2wtslii
wandb: Find logs at: ./wandb/offline-run-20240611_035126-r2wtslii/logs
[2m[1m[33m(autoscaler +22m1s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +22m28s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +22m41s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +23m3s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +23m15s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +23m43s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +23m51s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +24m18s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +24m54s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +25m1s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
[2m[1m[33m(autoscaler +25m29s)[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 2.0, 'memory': 17179869184.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
2024-06-11 04:19:33,785	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --raylet_socket_name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/raylet --store_socket_name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/plasma_store --object_manager_port=0 --min_worker_port=10002 --max_worker_port=19999 --node_manager_port=0 --node_ip_address=10.20.240.18 --maximum_startup_concurrency=2 --static_resource_list=node:10.20.240.18,1.0,node:__internal_head__,1.0,accelerator_type:G,1,CPU,2,GPU,1,memory,17179869184,object_store_memory,18160365158 "--python_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/default_worker.py --node-ip-address=10.20.240.18 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/plasma_store --raylet-name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/raylet --redis-address=None --temp-dir=/local/ray --metrics-agent-port=64393 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=10.20.240.18:6379 --session-name=session_2024-06-10_16-23-33_569321_2905328 --temp-dir=/local/ray --webui= RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER" "--java_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py -Dray.address=10.20.240.18:6379 -Dray.raylet.node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER -Dray.object-store.socket-name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/plasma_store -Dray.raylet.socket-name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/raylet -Dray.redis.password= -Dray.node-ip=10.20.240.18 -Dray.home=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/../.. -Dray.logging.dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328/logs -Dray.session-dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328 RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER io.ray.runtime.runner.worker.DefaultWorker" --cpp_worker_command= --native_library_path=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/cpp/lib --temp_dir=/local/ray --session_dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328 --log_dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328/logs --resource_dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328/runtime_resources --metrics-agent-port=64393 --metrics_export_port=64179 --object_store_memory=18160365158 --plasma_directory=/dev/shm --ray-debugger-external=0 --gcs-address=10.20.240.18:6379 --session-name=session_2024-06-10_16-23-33_569321_2905328 --labels= --head --num_prestart_python_workers=2 "--agent_command=/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/dashboard/agent.py --node-ip-address=10.20.240.18 --metrics-export-port=64179 --dashboard-agent-port=64393 --listen-port=52365 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/plasma_store --raylet-name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/raylet --temp-dir=/local/ray --session-dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328 --runtime-env-dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328/runtime_resources --log-dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --session-name=session_2024-06-10_16-23-33_569321_2905328 --gcs-address=10.20.240.18:6379 --minimal"` (via SIGTERM)
2024-06-11 04:19:33,786	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --raylet_socket_name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/raylet --store_socket_name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/plasma_store --object_manager_port=0 --min_worker_port=10002 --max_worker_port=19999 --node_manager_port=0 --node_ip_address=10.20.240.18 --maximum_startup_concurrency=2 --static_resource_list=node:10.20.240.18,1.0,node:__internal_head__,1.0,accelerator_type:G,1,CPU,2,GPU,1,memory,17179869184,object_store_memory,18155721523 "--python_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/default_worker.py --node-ip-address=10.20.240.18 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/plasma_store --raylet-name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/raylet --redis-address=None --temp-dir=/local/ray --metrics-agent-port=56428 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=10.20.240.18:6379 --session-name=session_2024-06-10_16-23-33_611315_2905329 --temp-dir=/local/ray --webui= RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER" "--java_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py -Dray.address=10.20.240.18:6379 -Dray.raylet.node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER -Dray.object-store.socket-name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/plasma_store -Dray.raylet.socket-name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/raylet -Dray.redis.password= -Dray.node-ip=10.20.240.18 -Dray.home=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/../.. -Dray.logging.dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329/logs -Dray.session-dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329 RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER io.ray.runtime.runner.worker.DefaultWorker" --cpp_worker_command= --native_library_path=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/cpp/lib --temp_dir=/local/ray --session_dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329 --log_dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329/logs --resource_dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329/runtime_resources --metrics-agent-port=56428 --metrics_export_port=56932 --object_store_memory=18155721523 --plasma_directory=/dev/shm --ray-debugger-external=0 --gcs-address=10.20.240.18:6379 --session-name=session_2024-06-10_16-23-33_611315_2905329 --labels= --head --num_prestart_python_workers=2 "--agent_command=/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/dashboard/agent.py --node-ip-address=10.20.240.18 --metrics-export-port=56932 --dashboard-agent-port=56428 --listen-port=52365 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/plasma_store --raylet-name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/raylet --temp-dir=/local/ray --session-dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329 --runtime-env-dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329/runtime_resources --log-dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --session-name=session_2024-06-10_16-23-33_611315_2905329 --gcs-address=10.20.240.18:6379 --minimal"` (via SIGTERM)
2024-06-11 04:19:33,790	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/autoscaler/_private/monitor.py --logs-dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=10.20.240.18:6379 --monitor-ip=10.20.240.18` (via SIGTERM)
2024-06-11 04:19:33,791	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/autoscaler/_private/monitor.py --logs-dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=10.20.240.18:6379 --monitor-ip=10.20.240.18` (via SIGTERM)
2024-06-11 04:19:33,791	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/log_monitor.py --logs-dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328/logs --gcs-address=10.20.240.18:6379 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5` (via SIGTERM)
2024-06-11 04:19:33,791	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/log_monitor.py --logs-dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329/logs --gcs-address=10.20.240.18:6379 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5` (via SIGTERM)
2024-06-11 04:19:33,798	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/bin/python -m ray.util.client.server --address=10.20.240.18:6379 --host=0.0.0.0 --port=10001 --mode=proxy --metrics-agent-port=64393` (via SIGTERM)
2024-06-11 04:19:33,799	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/bin/python -m ray.util.client.server --address=10.20.240.18:6379 --host=0.0.0.0 --port=10001 --mode=proxy --metrics-agent-port=56428` (via SIGTERM)
2024-06-11 04:19:33,807	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --raylet_socket_name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/raylet --store_socket_name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/plasma_store --object_manager_port=0 --min_worker_port=10002 --max_worker_port=19999 --node_manager_port=0 --node_ip_address=10.20.240.18 --maximum_startup_concurrency=2 --static_resource_list=node:10.20.240.18,1.0,node:__internal_head__,1.0,accelerator_type:G,1,CPU,2,GPU,1,memory,17179869184,object_store_memory,18160365158 "--python_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/default_worker.py --node-ip-address=10.20.240.18 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/plasma_store --raylet-name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/raylet --redis-address=None --temp-dir=/local/ray --metrics-agent-port=64393 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=10.20.240.18:6379 --session-name=session_2024-06-10_16-23-33_569321_2905328 --temp-dir=/local/ray --webui= RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER" "--java_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py -Dray.address=10.20.240.18:6379 -Dray.raylet.node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER -Dray.object-store.socket-name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/plasma_store -Dray.raylet.socket-name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/raylet -Dray.redis.password= -Dray.node-ip=10.20.240.18 -Dray.home=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/../.. -Dray.logging.dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328/logs -Dray.session-dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328 RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER io.ray.runtime.runner.worker.DefaultWorker" --cpp_worker_command= --native_library_path=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/cpp/lib --temp_dir=/local/ray --session_dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328 --log_dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328/logs --resource_dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328/runtime_resources --metrics-agent-port=64393 --metrics_export_port=64179 --object_store_memory=18160365158 --plasma_directory=/dev/shm --ray-debugger-external=0 --gcs-address=10.20.240.18:6379 --session-name=session_2024-06-10_16-23-33_569321_2905328 --labels= --head --num_prestart_python_workers=2 "--agent_command=/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/dashboard/agent.py --node-ip-address=10.20.240.18 --metrics-export-port=64179 --dashboard-agent-port=64393 --listen-port=52365 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/plasma_store --raylet-name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/raylet --temp-dir=/local/ray --session-dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328 --runtime-env-dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328/runtime_resources --log-dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --session-name=session_2024-06-10_16-23-33_569321_2905328 --gcs-address=10.20.240.18:6379 --minimal"` (via SIGTERM)
2024-06-11 04:19:33,809	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --raylet_socket_name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/raylet --store_socket_name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/plasma_store --object_manager_port=0 --min_worker_port=10002 --max_worker_port=19999 --node_manager_port=0 --node_ip_address=10.20.240.18 --maximum_startup_concurrency=2 --static_resource_list=node:10.20.240.18,1.0,node:__internal_head__,1.0,accelerator_type:G,1,CPU,2,GPU,1,memory,17179869184,object_store_memory,18155721523 "--python_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/default_worker.py --node-ip-address=10.20.240.18 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/plasma_store --raylet-name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/raylet --redis-address=None --temp-dir=/local/ray --metrics-agent-port=56428 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=10.20.240.18:6379 --session-name=session_2024-06-10_16-23-33_611315_2905329 --temp-dir=/local/ray --webui= RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER" "--java_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py -Dray.address=10.20.240.18:6379 -Dray.raylet.node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER -Dray.object-store.socket-name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/plasma_store -Dray.raylet.socket-name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/raylet -Dray.redis.password= -Dray.node-ip=10.20.240.18 -Dray.home=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/../.. -Dray.logging.dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329/logs -Dray.session-dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329 RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER io.ray.runtime.runner.worker.DefaultWorker" --cpp_worker_command= --native_library_path=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/cpp/lib --temp_dir=/local/ray --session_dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329 --log_dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329/logs --resource_dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329/runtime_resources --metrics-agent-port=56428 --metrics_export_port=56932 --object_store_memory=18155721523 --plasma_directory=/dev/shm --ray-debugger-external=0 --gcs-address=10.20.240.18:6379 --session-name=session_2024-06-10_16-23-33_611315_2905329 --labels= --head --num_prestart_python_workers=2 "--agent_command=/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/dashboard/agent.py --node-ip-address=10.20.240.18 --metrics-export-port=56932 --dashboard-agent-port=56428 --listen-port=52365 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/plasma_store --raylet-name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/raylet --temp-dir=/local/ray --session-dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329 --runtime-env-dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329/runtime_resources --log-dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --session-name=session_2024-06-10_16-23-33_611315_2905329 --gcs-address=10.20.240.18:6379 --minimal"` (via SIGTERM)
2024-06-11 04:19:33,817	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --raylet_socket_name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/raylet --store_socket_name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/plasma_store --object_manager_port=0 --min_worker_port=10002 --max_worker_port=19999 --node_manager_port=0 --node_ip_address=10.20.240.18 --maximum_startup_concurrency=2 --static_resource_list=node:10.20.240.18,1.0,node:__internal_head__,1.0,accelerator_type:G,1,CPU,2,GPU,1,memory,17179869184,object_store_memory,18160365158 "--python_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/default_worker.py --node-ip-address=10.20.240.18 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/plasma_store --raylet-name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/raylet --redis-address=None --temp-dir=/local/ray --metrics-agent-port=64393 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=10.20.240.18:6379 --session-name=session_2024-06-10_16-23-33_569321_2905328 --temp-dir=/local/ray --webui= RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER" "--java_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py -Dray.address=10.20.240.18:6379 -Dray.raylet.node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER -Dray.object-store.socket-name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/plasma_store -Dray.raylet.socket-name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/raylet -Dray.redis.password= -Dray.node-ip=10.20.240.18 -Dray.home=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/../.. -Dray.logging.dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328/logs -Dray.session-dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328 RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER io.ray.runtime.runner.worker.DefaultWorker" --cpp_worker_command= --native_library_path=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/cpp/lib --temp_dir=/local/ray --session_dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328 --log_dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328/logs --resource_dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328/runtime_resources --metrics-agent-port=64393 --metrics_export_port=64179 --object_store_memory=18160365158 --plasma_directory=/dev/shm --ray-debugger-external=0 --gcs-address=10.20.240.18:6379 --session-name=session_2024-06-10_16-23-33_569321_2905328 --labels= --head --num_prestart_python_workers=2 "--agent_command=/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/dashboard/agent.py --node-ip-address=10.20.240.18 --metrics-export-port=64179 --dashboard-agent-port=64393 --listen-port=52365 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/plasma_store --raylet-name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/raylet --temp-dir=/local/ray --session-dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328 --runtime-env-dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328/runtime_resources --log-dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --session-name=session_2024-06-10_16-23-33_569321_2905328 --gcs-address=10.20.240.18:6379 --minimal"` (via SIGTERM)
2024-06-11 04:19:33,819	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --raylet_socket_name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/raylet --store_socket_name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/plasma_store --object_manager_port=0 --min_worker_port=10002 --max_worker_port=19999 --node_manager_port=0 --node_ip_address=10.20.240.18 --maximum_startup_concurrency=2 --static_resource_list=node:10.20.240.18,1.0,node:__internal_head__,1.0,accelerator_type:G,1,CPU,2,GPU,1,memory,17179869184,object_store_memory,18155721523 "--python_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/default_worker.py --node-ip-address=10.20.240.18 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/plasma_store --raylet-name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/raylet --redis-address=None --temp-dir=/local/ray --metrics-agent-port=56428 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=10.20.240.18:6379 --session-name=session_2024-06-10_16-23-33_611315_2905329 --temp-dir=/local/ray --webui= RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER" "--java_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py -Dray.address=10.20.240.18:6379 -Dray.raylet.node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER -Dray.object-store.socket-name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/plasma_store -Dray.raylet.socket-name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/raylet -Dray.redis.password= -Dray.node-ip=10.20.240.18 -Dray.home=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/../.. -Dray.logging.dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329/logs -Dray.session-dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329 RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER io.ray.runtime.runner.worker.DefaultWorker" --cpp_worker_command= --native_library_path=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/cpp/lib --temp_dir=/local/ray --session_dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329 --log_dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329/logs --resource_dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329/runtime_resources --metrics-agent-port=56428 --metrics_export_port=56932 --object_store_memory=18155721523 --plasma_directory=/dev/shm --ray-debugger-external=0 --gcs-address=10.20.240.18:6379 --session-name=session_2024-06-10_16-23-33_611315_2905329 --labels= --head --num_prestart_python_workers=2 "--agent_command=/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/dashboard/agent.py --node-ip-address=10.20.240.18 --metrics-export-port=56932 --dashboard-agent-port=56428 --listen-port=52365 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/plasma_store --raylet-name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/raylet --temp-dir=/local/ray --session-dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329 --runtime-env-dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329/runtime_resources --log-dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --session-name=session_2024-06-10_16-23-33_611315_2905329 --gcs-address=10.20.240.18:6379 --minimal"` (via SIGTERM)
2024-06-11 04:19:33,820	VINFO scripts.py:1068 -- Send termination request to `ray::DefaultActor "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" "" ""` (via SIGTERM)
2024-06-11 04:19:33,828	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --raylet_socket_name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/raylet --store_socket_name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/plasma_store --object_manager_port=0 --min_worker_port=10002 --max_worker_port=19999 --node_manager_port=0 --node_ip_address=10.20.240.18 --maximum_startup_concurrency=2 --static_resource_list=node:10.20.240.18,1.0,node:__internal_head__,1.0,accelerator_type:G,1,CPU,2,GPU,1,memory,17179869184,object_store_memory,18160365158 "--python_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/default_worker.py --node-ip-address=10.20.240.18 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/plasma_store --raylet-name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/raylet --redis-address=None --temp-dir=/local/ray --metrics-agent-port=64393 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=10.20.240.18:6379 --session-name=session_2024-06-10_16-23-33_569321_2905328 --temp-dir=/local/ray --webui= RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER" "--java_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py -Dray.address=10.20.240.18:6379 -Dray.raylet.node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER -Dray.object-store.socket-name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/plasma_store -Dray.raylet.socket-name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/raylet -Dray.redis.password= -Dray.node-ip=10.20.240.18 -Dray.home=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/../.. -Dray.logging.dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328/logs -Dray.session-dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328 RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER io.ray.runtime.runner.worker.DefaultWorker" --cpp_worker_command= --native_library_path=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/cpp/lib --temp_dir=/local/ray --session_dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328 --log_dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328/logs --resource_dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328/runtime_resources --metrics-agent-port=64393 --metrics_export_port=64179 --object_store_memory=18160365158 --plasma_directory=/dev/shm --ray-debugger-external=0 --gcs-address=10.20.240.18:6379 --session-name=session_2024-06-10_16-23-33_569321_2905328 --labels= --head --num_prestart_python_workers=2 "--agent_command=/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/dashboard/agent.py --node-ip-address=10.20.240.18 --metrics-export-port=64179 --dashboard-agent-port=64393 --listen-port=52365 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/plasma_store --raylet-name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/raylet --temp-dir=/local/ray --session-dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328 --runtime-env-dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328/runtime_resources --log-dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --session-name=session_2024-06-10_16-23-33_569321_2905328 --gcs-address=10.20.240.18:6379 --minimal"` (via SIGTERM)
2024-06-11 04:19:33,830	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --raylet_socket_name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/raylet --store_socket_name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/plasma_store --object_manager_port=0 --min_worker_port=10002 --max_worker_port=19999 --node_manager_port=0 --node_ip_address=10.20.240.18 --maximum_startup_concurrency=2 --static_resource_list=node:10.20.240.18,1.0,node:__internal_head__,1.0,accelerator_type:G,1,CPU,2,GPU,1,memory,17179869184,object_store_memory,18155721523 "--python_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/default_worker.py --node-ip-address=10.20.240.18 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/plasma_store --raylet-name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/raylet --redis-address=None --temp-dir=/local/ray --metrics-agent-port=56428 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=10.20.240.18:6379 --session-name=session_2024-06-10_16-23-33_611315_2905329 --temp-dir=/local/ray --webui= RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER" "--java_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py -Dray.address=10.20.240.18:6379 -Dray.raylet.node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER -Dray.object-store.socket-name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/plasma_store -Dray.raylet.socket-name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/raylet -Dray.redis.password= -Dray.node-ip=10.20.240.18 -Dray.home=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/../.. -Dray.logging.dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329/logs -Dray.session-dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329 RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER io.ray.runtime.runner.worker.DefaultWorker" --cpp_worker_command= --native_library_path=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/cpp/lib --temp_dir=/local/ray --session_dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329 --log_dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329/logs --resource_dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329/runtime_resources --metrics-agent-port=56428 --metrics_export_port=56932 --object_store_memory=18155721523 --plasma_directory=/dev/shm --ray-debugger-external=0 --gcs-address=10.20.240.18:6379 --session-name=session_2024-06-10_16-23-33_611315_2905329 --labels= --head --num_prestart_python_workers=2 "--agent_command=/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/dashboard/agent.py --node-ip-address=10.20.240.18 --metrics-export-port=56932 --dashboard-agent-port=56428 --listen-port=52365 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/plasma_store --raylet-name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/raylet --temp-dir=/local/ray --session-dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329 --runtime-env-dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329/runtime_resources --log-dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --session-name=session_2024-06-10_16-23-33_611315_2905329 --gcs-address=10.20.240.18:6379 --minimal"` (via SIGTERM)
2024-06-11 04:19:33,836	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/log_monitor.py --logs-dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328/logs --gcs-address=10.20.240.18:6379 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5` (via SIGTERM)
2024-06-11 04:19:33,836	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/log_monitor.py --logs-dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329/logs --gcs-address=10.20.240.18:6379 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5` (via SIGTERM)
2024-06-11 04:19:33,850	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --raylet_socket_name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/raylet --store_socket_name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/plasma_store --object_manager_port=0 --min_worker_port=10002 --max_worker_port=19999 --node_manager_port=0 --node_ip_address=10.20.240.18 --maximum_startup_concurrency=2 --static_resource_list=node:10.20.240.18,1.0,node:__internal_head__,1.0,accelerator_type:G,1,CPU,2,GPU,1,memory,17179869184,object_store_memory,18160365158 "--python_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/default_worker.py --node-ip-address=10.20.240.18 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/plasma_store --raylet-name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/raylet --redis-address=None --temp-dir=/local/ray --metrics-agent-port=64393 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=10.20.240.18:6379 --session-name=session_2024-06-10_16-23-33_569321_2905328 --temp-dir=/local/ray --webui= RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER" "--java_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py -Dray.address=10.20.240.18:6379 -Dray.raylet.node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER -Dray.object-store.socket-name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/plasma_store -Dray.raylet.socket-name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/raylet -Dray.redis.password= -Dray.node-ip=10.20.240.18 -Dray.home=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/../.. -Dray.logging.dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328/logs -Dray.session-dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328 RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER io.ray.runtime.runner.worker.DefaultWorker" --cpp_worker_command= --native_library_path=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/cpp/lib --temp_dir=/local/ray --session_dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328 --log_dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328/logs --resource_dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328/runtime_resources --metrics-agent-port=64393 --metrics_export_port=64179 --object_store_memory=18160365158 --plasma_directory=/dev/shm --ray-debugger-external=0 --gcs-address=10.20.240.18:6379 --session-name=session_2024-06-10_16-23-33_569321_2905328 --labels= --head --num_prestart_python_workers=2 "--agent_command=/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/dashboard/agent.py --node-ip-address=10.20.240.18 --metrics-export-port=64179 --dashboard-agent-port=64393 --listen-port=52365 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/plasma_store --raylet-name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/raylet --temp-dir=/local/ray --session-dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328 --runtime-env-dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328/runtime_resources --log-dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --session-name=session_2024-06-10_16-23-33_569321_2905328 --gcs-address=10.20.240.18:6379 --minimal"` (via SIGTERM)
2024-06-11 04:19:33,851	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/raylet/raylet --raylet_socket_name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/raylet --store_socket_name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/plasma_store --object_manager_port=0 --min_worker_port=10002 --max_worker_port=19999 --node_manager_port=0 --node_ip_address=10.20.240.18 --maximum_startup_concurrency=2 --static_resource_list=node:10.20.240.18,1.0,node:__internal_head__,1.0,accelerator_type:G,1,CPU,2,GPU,1,memory,17179869184,object_store_memory,18155721523 "--python_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/default_worker.py --node-ip-address=10.20.240.18 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/plasma_store --raylet-name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/raylet --redis-address=None --temp-dir=/local/ray --metrics-agent-port=56428 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=10.20.240.18:6379 --session-name=session_2024-06-10_16-23-33_611315_2905329 --temp-dir=/local/ray --webui= RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER" "--java_worker_command=/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/_private/workers/setup_worker.py -Dray.address=10.20.240.18:6379 -Dray.raylet.node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER -Dray.object-store.socket-name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/plasma_store -Dray.raylet.socket-name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/raylet -Dray.redis.password= -Dray.node-ip=10.20.240.18 -Dray.home=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/../.. -Dray.logging.dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329/logs -Dray.session-dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329 RAY_WORKER_DYNAMIC_OPTION_PLACEHOLDER io.ray.runtime.runner.worker.DefaultWorker" --cpp_worker_command= --native_library_path=/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/cpp/lib --temp_dir=/local/ray --session_dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329 --log_dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329/logs --resource_dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329/runtime_resources --metrics-agent-port=56428 --metrics_export_port=56932 --object_store_memory=18155721523 --plasma_directory=/dev/shm --ray-debugger-external=0 --gcs-address=10.20.240.18:6379 --session-name=session_2024-06-10_16-23-33_611315_2905329 --labels= --head --num_prestart_python_workers=2 "--agent_command=/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/dashboard/agent.py --node-ip-address=10.20.240.18 --metrics-export-port=56932 --dashboard-agent-port=56428 --listen-port=52365 --node-manager-port=RAY_NODE_MANAGER_PORT_PLACEHOLDER --object-store-name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/plasma_store --raylet-name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/raylet --temp-dir=/local/ray --session-dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329 --runtime-env-dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329/runtime_resources --log-dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --session-name=session_2024-06-10_16-23-33_611315_2905329 --gcs-address=10.20.240.18:6379 --minimal"` (via SIGTERM)
2024-06-11 04:19:33,852	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/dashboard/agent.py --node-ip-address=10.20.240.18 --metrics-export-port=64179 --dashboard-agent-port=64393 --listen-port=52365 --node-manager-port=44303 --object-store-name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/plasma_store --raylet-name=/local/ray/session_2024-06-10_16-23-33_569321_2905328/sockets/raylet --temp-dir=/local/ray --session-dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328 --runtime-env-dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328/runtime_resources --log-dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --session-name=session_2024-06-10_16-23-33_569321_2905328 --gcs-address=10.20.240.18:6379 --minimal --agent-id 424238335` (via SIGTERM)
2024-06-11 04:19:33,853	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/bin/python -u /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/dashboard/agent.py --node-ip-address=10.20.240.18 --metrics-export-port=56932 --dashboard-agent-port=56428 --listen-port=52365 --node-manager-port=39717 --object-store-name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/plasma_store --raylet-name=/local/ray/session_2024-06-10_16-23-33_611315_2905329/sockets/raylet --temp-dir=/local/ray --session-dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329 --runtime-env-dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329/runtime_resources --log-dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329/logs --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --session-name=session_2024-06-10_16-23-33_611315_2905329 --gcs-address=10.20.240.18:6379 --minimal --agent-id 424238335` (via SIGTERM)
2024-06-11 04:19:33,859	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/dashboard/dashboard.py --host=127.0.0.1 --port=8265 --port-retries=0 --temp-dir=/local/ray --log-dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328/logs --session-dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=10.20.240.18:6379 --node-ip-address=10.20.240.18 --minimal` (via SIGTERM)
2024-06-11 04:19:33,861	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/bin/python /home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/dashboard/dashboard.py --host=127.0.0.1 --port=8265 --port-retries=0 --temp-dir=/local/ray --log-dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329/logs --session-dir=/local/ray/session_2024-06-10_16-23-33_611315_2905329 --logging-rotate-bytes=536870912 --logging-rotate-backup-count=5 --gcs-address=10.20.240.18:6379 --node-ip-address=10.20.240.18 --minimal` (via SIGTERM)
2024-06-11 04:19:33,868	INFO scripts.py:1098 -- 1/13 stopped.2024-06-11 04:19:33,967	INFO scripts.py:1098 -- 2/13 stopped.2024-06-11 04:19:34,168	INFO scripts.py:1098 -- 3/13 stopped.2024-06-11 04:19:34,220	INFO scripts.py:1098 -- 4/13 stopped.2024-06-11 04:19:34,221	INFO scripts.py:1098 -- 5/13 stopped.2024-06-11 04:19:34,221	INFO scripts.py:1098 -- 6/13 stopped.2024-06-11 04:19:34,221	INFO scripts.py:1098 -- 7/13 stopped.2024-06-11 04:19:34,315	INFO scripts.py:1098 -- 8/13 stopped.2024-06-11 04:19:34,621	INFO scripts.py:1098 -- 9/13 stopped.2024-06-11 04:19:34,842	INFO scripts.py:1098 -- 10/13 stopped.2024-06-11 04:19:34,843	INFO scripts.py:1098 -- 11/13 stopped.2024-06-11 04:19:34,895	INFO scripts.py:1098 -- 12/13 stopped.2024-06-11 04:19:34,895	INFO scripts.py:1098 -- 13/13 stopped.2024-06-11 04:19:35,050	VINFO scripts.py:1068 -- Send termination request to `/home/s2240084/conFEDential/venv/lib/python3.10/site-packages/ray/core/src/ray/gcs/gcs_server --log_dir=/local/ray/session_2024-06-10_16-23-33_569321_2905328/logs --config_list=eyJvYmplY3Rfc3BpbGxpbmdfY29uZmlnIjogIntcInR5cGVcIjogXCJmaWxlc3lzdGVtXCIsIFwicGFyYW1zXCI6IHtcImRpcmVjdG9yeV9wYXRoXCI6IFwiL2xvY2FsL3JheS9zZXNzaW9uXzIwMjQtMDYtMTBfMTYtMjMtMzNfNTY5MzIxXzI5MDUzMjhcIn19IiwgImlzX2V4dGVybmFsX3N0b3JhZ2VfdHlwZV9mcyI6IHRydWV9 --gcs_server_port=6379 --metrics-agent-port=64393 --node-ip-address=10.20.240.18 --session-name=session_2024-06-10_16-23-33_569321_2905328` (via SIGTERM)
2024-06-11 04:19:36,361	INFO scripts.py:1098 -- 1/1 stopped.2024-06-11 04:19:36,361	SUCC scripts.py:1142 -- Stopped all 14 Ray processes.
